[{"title":"诺瓦星云一面","path":"/2023/09/07/诺瓦星云一面/","content":"09.07 诺瓦星云一面 自我介绍； 选一个项目介绍一下； 项目中用户模块是怎么设计的？ 项目是怎么鉴权的？ 用户用了token之后能访问所有功能吗？ 说说面向对象的特征； 面向对象的七大原则； 这里确实忘了，只记得一个开闭原则。 单一职责原则：一个类只负责一个功能领域中的对应职责； 开闭原则：软件实体应对扩展开放，修改关闭； 里氏替换原则：所以引用基类（父类）的地方能够透明地使用其子类对象； 依赖倒转原则：抽象不应该依赖于细节，细节应该依赖于抽象； 接口隔离原则：使用多个专门的接口，而不使用单一的总接口； 合成复用原则：尽量使用对象组合，而不是继承来达到复用的目的； 迪米特法则：软件实体应尽可能少地与其他实体发生相互作用。 构造方法可以重载和重写吗？ 项目里用到了什么数据结构？具体怎么用的？ 项目里的延迟队列是怎么用的？ Socket了解吗？项目里有用到吗？ 说说输入一个网址到页面出现这个过程中经历过什么？ MAC地址是什么？和IP地址有什么区别？ 项目有用到多线程吗？ 线程通信的方式有哪些？进程呢？ 你刚刚提到volatile关键字，那你解释一下volatile的作用和原理 如果项目出现偶现问题该怎么定位？怎么解决？ 压根不知道偶现问题是啥，没听过，就说可以通过日志和记录来解决。 后面下来查了一下： 尝试，尝试，尝试去在一种可控的方式下重现这个 bug。如果你不能重现它，用日志系统给它设置一个圈套，来在你需要的时候，在它真的发生的时候，记录你猜想的，需要的东西。重新设计这个圈套，如果这个bug只发生在产品中，且不在你的猜想中的话，这可能是一个漫长的过程。你从日志中得到的（信息）可能不能提供解决方案，但可能给你足够的信息去优化这个日志。优化后的日志系统可能花很长时间才能被放入产品中使用。然后，你必须等待 bug 重新出现以获得更多的信息。这个循环可能会继续好几次。 反问环节。","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"多益一面","path":"/2023/09/07/多益一面/","content":"09.07 多益一面 自我介绍； 介绍一下你最得意的项目 那你为什么想投游戏开发岗位？ 你说说为什么这么关注《黑神话·悟空》这个游戏？ 你自己平常喜欢什么类型的游戏？ 玩过多益什么游戏吗？ 说说面向对象思想 平时有了解过什么数据结构吗？ 那你说说数组和链表的区别是什么？ 知道递归吗？说说递归的优缺点和使用场景？ 如果不用递归的话有什么其他的方法呢？ 现在让你设计一个扫雷游戏，你会怎么设计？ 这里我说先划定n*n区域的大小和边界，然后每点开一个格子会出现一个数字，表示这个数组周围8个内有多少个炸弹，然后就被打断了，说不用考虑这么多。 然后我继续说，简单实现的话就用随机数生成m个坐标，表示地雷的位置。 那如何保证随机生成的不会重复呢？ 这里我说可以用HashSet来实现去重，避免生成重复的地雷位置。 如果用Set来做的话生成的那就不是真随机了，概率肯定就不一样，要保证随机的概率一样 我说可以把n*n大小的区域划分为m个区域，然后每个区域再生成一个随机位置，这样也相当于是生成了随机地雷。然后面试官说用这种方法的话其实也不是真随机，会导致炸弹分布的很均匀。 你知道洗牌算法吗？ 我说我没有了解过，他说其实就是用洗牌算法来实现的。 洗牌算法是用来打乱一个有序序列的算法，常用于随机排序数组或集合中的元素。 以下是洗牌算法的一种常见思路，通常称为 Fisher-Yates 洗牌算法： 从要打乱的序列中选择最后一个元素，即最后一个位置的元素。 随机生成一个介于 0 和当前位置（包括当前位置）之间的随机数，可以使用随机数生成函数来实现。 将当前位置的元素与随机选择的位置的元素进行交换。 接着从当前位置的前一个位置开始，重复步骤 2 和 3，直到第一个位置。 然后从未被选择的元素中随机选择一个元素，将其与第一个位置的元素进行交换。 重复步骤 2 到 5，直到所有位置都被处理完毕。 这个算法确保了每个元素在最后的洗牌结果中具有相等的概率，并且生成的排列是随机的。 你平时日常的时间是怎么分配的呢？ 手撕代码：二分查找； 手撕代码：非递归方法生成斐波那契数列； 反问环节。","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"中科创达一面","path":"/2023/09/05/中科创达一面/","content":"9.05 中科创达一面 自我介绍； Java基本数据类型有哪些？介绍一下装箱拆箱？ Java为什么要设计包装类？ 抽象类和接口的区别？ 了解过设计模式吗？介绍一下单例模式 你刚刚介绍的两种单例模式是线程安全的吗？为什么？ HashMap和HashTable的区别？ ArrayList和Array的区别？ 有没有学习其他语言的经验？ 介绍一下你的论文。 你对你未来工作的方向有什么偏好吗？前端还是后端？后端的话是想走什么方向呢？ 反问环节。","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"得物一面","path":"/2023/09/02/得物一面/","content":"09.02 得物一面 自我介绍 数据库为什么用B+树作为索引？ 现在SSD的IO这么快，对数据库而言有什么比B+树更好的索引数据结构吗？ 这里我答了前缀树，但是说了一下我并没有去对比前缀树与B+树具体的优劣，面试官说没事，他也只是问一下，想探讨一下。 如果虚拟机发生了Full GC，该怎么排查问题？ 这里我答了Full GC的触发条件、内存溢出怎么排查、虚拟机参数设置不对导致Full GC。 讲一讲TCP三次握手 如果程序发生死锁该怎么办？ 这里我讲了讲死锁产生的原因和四个条件，然后分别讲了破坏其中三个条件就可以避免死锁。 如果用户下单时出现网络异常，导致由多个下单请求或生成多个订单号该怎么办？ 这里我介绍了一下我项目里这种问题是用RabbitMQ来做，将订单放到消息队列里，然后balablaba。。。。 怎么保证唯一ID呢？ 我回答的是用UUID或者雪花算法生成唯一标识ID。 那如果以时间戳来生成唯一ID，项目里如何区分用户是误触多次下单还是真的想要下单呢？ 我介绍了我项目里用时间段来作为唯一表示ID，面试官说我这是提前设置好了下单的规则，如果是淘宝呢？该怎么办？ 然后面试官说可以慢慢想想，看看有没有什么思路？ 我后面又说了可以通过加锁，来控制用户下单时操作的唯一性，然后说了一下思路。。。。。 面试官说对，他就是想考锁相关的知识。 现在有10亿条数据，但是处理的内存只有400MB，如何找出其中第10000到11000条数据？ 这个就是很经典的处理海量数据的题目，没啥多说的。 直接分治法 + 小根堆排序就能解决。","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"多益HR面","path":"/2023/08/30/多益HR面/","content":"08.30 多益HR面 自我介绍； 平时怎么学习的？ 讲讲大学和研究生期间的时间分配； 未来的职业规划是什么？ 目前有没有其他公司的offer？面了哪些公司？ 你的期望薪资是多少？ 对当下互联网行业的加班情况怎么看？接受周末加班吗？ 找工作更看重公司什么？ 我看你使用的是Java语言，那你有了解过其他语言吗？Pyhton呢？ 我看你投的城市是成都，为什么想去成都？武汉和广州有没有考虑呢？ 你以后如果去成都工作，那家里人是什么意见？ 父母的职业？家人对你找工作的期望是什么？ 你平时有什么兴趣爱好？ 我看你玩游戏玩的挺多的，那你平时玩什么游戏？一天大概玩多少小时？ 你填简历的时候这些问题是自己写的吗？ 你觉得这个世界是公平的吗？为什么？ 如果没有一胎二胎三胎限制你愿意生多少孩子？ 我看你主观题写的是xxxx，为什么？ 反问环节。","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"腾讯一面","path":"/2023/08/28/腾讯一面/","content":"08.28 腾讯一面全程40min，因为投的是测开方向，所以面试的问题大部分以测试的内容为主，测试部分答得非常不行，因为确实没怎么具体了解过，认栽了。 自我介绍 说一说开发的整个流程吧 你对测试是怎么看的？ 如果你让你来测试接口，但是后端并没有把接口给你，你该怎么测试？ 如果你有一个好朋友是后端那边的，告诉你他们自己已经自测完了，不用我再进行测试了，你该怎么办？ 有了解过Linux吗？说一说查看网络状态的命令？ 这里我详细问了一下：具体是网络的什么状态？ 查看网络ip地址？查看网络端口？这些 ifconfig：查看IP地址； netstat -tuln：查看网络端口； -t：显示 TCP 端口 -u：显示 UDP 端口 -l：仅显示监听的端口 -n：以数字形式显示端口号，而不是解析为服务名 iftop ：用于实时监测网络流量。它可以显示网络连接的信息，包括每个连接的源和目标 IP 地址、端口以及传输速率等； ip ：用于管理和配置网络连接的工具，也可以用于查看网络状态。 怎么查看内存呢？ 我答了可以用top命令，但是感觉面试官不太满意，下来后查了一下，可以用下面四条命令查看： free命令： free 命令可以用于显示系统内存的使用情况，包括物理内存和交换空间的使用情况。 top命令： top 命令是一个实时系统监视器，可以显示系统的各种性能指标，包括内存使用情况。 htop命令： htop 命令也是一个交互式的系统监视器，类似于 top，但提供了更多的信息和功能。 vmstat命令： vmstat 命令可以用于显示系统的虚拟内存、进程、IO 等信息，也包括内存使用情况。 HTTP的方法有哪些呢？介绍一下 我说了Get和Post， Get是。。。。 Post是。。。。 Get和Post的区别是。。。。 说说什么是反向代理？ 如果现在数据传输过程中出现丢包该怎么排查？怎么测试？ 这里我回答的是TCP有保证可靠性的机制，比如说滑动窗口、拥塞控制、超时重传等机制，然后说了一下具体内容。 但是面试官说不要说这些宽泛的内容，她问的是具体实际开发场景下，出现了丢包问题，该怎么排查？ 这里我就卡住了，不知道该回答什么。 那我提示你一下吧，有抓过包吗？用过抓包工具吗？ 这个问题我确实不知道，因为真没用过抓包工具，只是了解过一点点，就如实说我不太了解。 面试结束后去查了一下，应该这么回答： 选择抓包工具： 选择适合的抓包工具，常用的抓包工具包括 Wireshark、tcpdump、Fiddler 等。Wireshark 是一个功能强大的图形化抓包工具，而 tcpdump 是命令行抓包工具。 设置过滤条件： 在抓包工具中设置过滤条件，以便只捕获相关的数据包。比如可以设置过滤条件来捕获特定的协议、IP 地址、端口等。 开始抓包： 启动抓包工具，并开始捕获数据包。根据具体传输场景，可以在数据传输期间或问题发生时开始抓包。 观察数据包流： 在抓包工具中观察数据包的流动情况。检查是否有丢包、延迟、重传等现象。 分析数据包： 仔细分析捕获的数据包。查看数据包的源、目标、协议、大小、时间戳等信息。特别关注重传的数据包，看是否有丢失的数据包。 查找丢包原因： 在数据包中查找可能导致丢包的原因。可能的原因包括网络拥塞、路由问题、设备故障等。 比较发送和接收端： 如果有发送和接收两端，比较两端的数据包流。看是否存在不一致，例如发送端发出的数据包是否在接收端能够捕获到。 观察重传情况： 如果有重传现象，分析重传的原因。重传可能是由于丢包引起的。 检查网络设备： 如果可能，检查网络设备的状态。查看路由器、交换机等网络设备的日志，确认是否有异常。 收集数据： 如果你需要进一步分析或与其他人协商，可以将捕获的数据包保存下来，以供后续分析。 测试解决方案： 如果你认为找到了问题的原因，可以尝试实施解决方案并重新测试，看是否解决了丢包问题。 你说说MySQL的存储引擎吧 我说了我知道的InnoDB和MyISAM两个存储引擎。 MyISAM是。。。。 InnoDB是。。。。 InnoDB和MyISAM的区别是。。。。 说说什么是平衡二叉树吧 这里我答得不是很好，很久没看数据结构的基础了，只是说了一下平衡二叉树的左右子树高度差不超过1。 其实这里我应该继续展开说说的： 比如平衡二叉树插入、删除所引起的自旋操作； 比如平衡二叉树的优点是什么，缺点是什么。 说说快速排序的思想 说说Java反射是什么，有什么优缺点？ 说说Java中泛型是什么？ 这里答的也不好，并没有说清楚，只是简单的举了个泛型的例子。 可以从以下几个方面回答： 泛型是。。。。 泛型的优缺点是。。。。 泛型中类型擦除是。。。。 手撕：输出一个数组中最大且出现频率最多的数，并输出出现的次数。 说一说你写的代码实现的思路 针对你写的这个代码写一写测试用例","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"场景题","path":"/2023/08/26/场景题/","content":"1. 如何设计一个高并发高可用的Web系统？这个问题我觉得可以从下面五个点回答： 微服务模块拆分 缓存 MQ 分库分表 读写分离 1.1 模块拆分通过Spring Cloud将一个系统拆分为多个子系统，也即微服务模块，然后每个微服务模块连接一个数据库，这样就有多个数据库同时处理并发业务。 同时通过微服务拆分业务模块有以下优点： 不同的微服务之间可以使用不同的技术； 隔离性。一个服务不可用不会导致其他服务不可用； 可扩展性。某个服务出现性能瓶颈，只需对此服务进行升级即可； 简化部署。服务的部署是独立的，哪个服务出现问题，只需对此服务进行修改重新部署； 1.2 缓存这也是常见的一种优化方式，在数据库层之上加一层缓存，减少对数据库的访问压力。 因为缓存中的数据都是存储在内存里的，而数据库中的数据是写在磁盘上的，所以访问内存肯定是比访问磁盘快的可不止一个数量级。 大部分的高并发场景，都是读多写少，那完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存。毕竟 Redis 轻轻松松单机几万的并发。 所以那些主要请求是读多写少的高并发场景下，可以采用缓存来抗高并发。 1.3 MQ用Redis可以解决读多写少的情况，那么大量写操作的情况下可以采用MQ解决，因为MQ的优点就是可以：流量削峰、异步处理。 当大量的写请求灌入 MQ 里，让这些请求一个一个排队慢慢玩儿，后台系统根据实际情况觉得消费速度，然后慢慢写，将并发量控制在 MySQL 承载范围的之内。 所以高并发场景下那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性，MQ 单机抗几万并发也是 ok 的。 1.4 分库分表当数据量达到某个阀值时，数据库拆分就会成为一个紧急的需求。 一般从业务上进行垂直拆分，也即按照业务类型进行拆分。但如果业务单一，也可从水平上进行拆分。 拆分的原则一般要避免跨数据库事务。跨数据库事务可以选择在前期调研时把同一事务中的表放在一个数据库中。 将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 SQL的性能。 1.5 读写分离读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上，可以搞个主从模式，主库写入，从库读取，搞一个读写分离。 当读流量太多的时候，还可以加更多的从库。 2.如何设计一个日志管理平台？持久层（数据库层）设计： 数据库选择： 选择适合的数据库管理系统，如关系型数据库（如MySQL、PostgreSQL）或非关系型数据库（如MongoDB、Elasticsearch）等，根据日志数据的特性和需求来选择。 表设计： 设计适合存储日志数据的数据表结构，可以考虑分表、分区等策略，以提高查询性能。常见的字段包括时间戳、日志级别、模块、内容等。 索引优化： 根据常见的查询需求，添加合适的索引以提高查询效率。例如，根据时间范围、模块、关键字等查询。 数据清理： 定期清理过期的日志数据，避免数据库过大影响性能。 缓存设计： 缓存类型： 可以考虑使用缓存来加速频繁查询的数据。常见的缓存系统有Redis等。 缓存策略： 根据访问模式和数据更新频率，选择合适的缓存策略，如LRU（最近最少使用）、TTL（过期时间）、缓存预热等。 数据同步： 如果涉及到数据更新，需要考虑缓存和数据库之间的数据同步机制，以保持数据的一致性。 控制层（应用程序）设计： 日志收集： 设计日志收集模块，能够从不同的应用、模块收集日志，并进行标准化、分类。 日志级别和分类： 设计合适的日志级别（如DEBUG、INFO、ERROR等），根据不同的级别分类存储和展示。 日志展示： 设计用户界面以展示日志数据，可以实现按时间、级别、模块等过滤和查询。 权限管理： 考虑日志的访问权限，确保只有授权的用户可以访问相应的日志数据。 实时监控： 如果需要实时监控系统运行情况，可以设计实时监控面板，显示实时的日志信息和系统状态。 告警和通知： 根据日志的内容和级别，设计告警和通知机制，及时通知管理员发现问题。 2.1 采集的过程要怎么做才能不影响其他的服务？通过Spring AOP来实现，因为AOP能够将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑（例如事务处理、日志管理、权限控制等）抽取公共模块复用，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 创建切面类： 首先，你需要创建一个切面类，该类将包含日志采集的逻辑。这个类应该继承自 org.aspectj.lang.annotation.Aspect，并使用 @Aspect 注解进行标记。在切面类中，你可以定义通知（Advice）来拦截指定的方法。 定义切点： 在切面类中，你需要定义切点，切点是指在哪些方法上应用切面逻辑。可以使用 @Pointcut 注解来定义切点表达式，以匹配要拦截的方法。 编写通知： 通知是在切点方法执行前、执行后、出现异常时等特定时机执行的逻辑。Spring AOP 支持多种类型的通知，如 @Before、@After、@AfterReturning 和 @AfterThrowing。 配置切面： 在 Spring 配置文件（如 XML 配置文件或 Java 配置类）中，将切面类和切点配置为 Spring Bean，并将通知与切点关联起来。 1234567891011121314151617181920212223242526272829import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.stereotype.Component;@Aspect@Componentpublic class LoggingAspect &#123; @Pointcut(&quot;execution(* com.example.myapp.service.*.*(..))&quot;) private void serviceMethods() &#123;&#125; @Before(&quot;serviceMethods()&quot;) public void beforeMethod(JoinPoint joinPoint) &#123; String methodName = joinPoint.getSignature().getName(); System.out.println(&quot;Before method: &quot; + methodName); &#125; @AfterReturning(pointcut = &quot;serviceMethods()&quot;, returning = &quot;result&quot;) public void afterReturningMethod(JoinPoint joinPoint, Object result) &#123; String methodName = joinPoint.getSignature().getName(); System.out.println(&quot;After returning method: &quot; + methodName + &quot;, Result: &quot; + result); &#125; @AfterThrowing(pointcut = &quot;serviceMethods()&quot;, throwing = &quot;exception&quot;) public void afterThrowingMethod(JoinPoint joinPoint, Exception exception) &#123; String methodName = joinPoint.getSignature().getName(); System.out.println(&quot;After throwing method: &quot; + methodName + &quot;, Exception: &quot; + exception.getMessage()); &#125;&#125; 在上面的示例中创建了一个名为 LoggingAspect 的切面类，定义了 serviceMethods() 切点用于匹配位于 com.example.myapp.service 包下的所有方法。然后，我们编写了 @Before、@AfterReturning 和 @AfterThrowing 通知，分别用于在方法执行前、执行后（包括返回结果）和出现异常时执行相应的日志记录。 最后，将切面类配置为 Spring Bean，可以通过 XML 配置文件或者使用 @ComponentScan 注解扫描到该类。这样，当匹配的方法被调用时，切面逻辑会自动触发。 2.2 采集下来的日志数据用什么存储？数据量大了怎么办？日志基本都是以文件形式采集的，所以可以采用文本类型的数据库进行存储，比如MongoDB数据库，该数据库更适合存储大量文本类型的数据。 当日志数据量过大时，有几种解决办法： 数据清理和归档： 定期清理过期的日志数据，将数据归档到硬盘中，以保持数据库的性能。 数据压缩和索引优化：可以使用数据压缩技术和适当的索引优化来减少存储空间和提高查询性能。 分布式计算和存储： 对于大数据量，可以考虑使用分布式计算和存储解决方案，如Hadoop、Spark等，以实现高性能的数据处理和分析。 流式处理： 如果日志数据是实时产生的，可以考虑使用流式处理平台，如Apache Kafka，将日志数据以流的形式进行处理和存储。 2.3 如何高效的搜索已经存储的日志？ 索引： 为日志数据建立合适的索引，索引可以显著提高查询性能。索引字段应该基于查询的频率和条件来选择，例如时间戳、关键字、日志级别等。对于文本搜索，全文索引技术可以帮助搜索非结构化的日志数据。 合理的查询语句： 编写优化的查询语句，避免不必要的全表扫描。使用适当的条件、操作符和逻辑连接符来缩小查询范围，提高查询效率。 分区和分表： 对于关系型数据库，可以使用分区和分表策略，将数据分散存储在多个物理存储位置上，以减少每次查询的数据量。","tags":["Java","面试","面经","场景题"],"categories":["Java八股","扩展内容"]},{"title":"测试基础","path":"/2023/08/17/测试基础/","content":"1. 什么是软件测试？使用某些技术手段对软件进行操作，发现软件缺陷，判断软件是否满足用户使用的需求。 2. 什么是黑盒测试？黑盒测试：在进行测试时，我们看不见程序的源代码，只对程序的功能进行测试。 就号像一个黑色的盒子一样，看不到内部有什么东西。 在黑盒测试的过程中主要关注输入与输出以及输出是否符合预期，并不关注具体代码的实现。 3. 什么是白盒测试？白盒测试：在测试的过程中能看到程序的源代码，主要是对程序的源代码进行测试。 测试人员检查程序的内部结构，根据内部逻辑来设计测试用例，比如单元测试就是一种白盒测试。 白盒测试根据软件的内部逻辑设计测试用例，常用的技术是逻辑覆盖，即考察用测试数据运行被测程序时对程序逻辑的覆盖程度。 主要的覆盖标准有 6 种：语句覆盖、判定覆盖、条件覆盖、判定&#x2F;条件覆盖、组合条件覆盖和路径覆盖。 4. 什么是灰盒测试？灰盒测试：是介于白盒测试和黑盒测试之间的一种测试方法，它能看见程序的部分源码，主要是对程序的接口进行测试。 在我们执行测试的过程中，一般是先进行单元测试 -&gt; 集成测试 -&gt; 系统测试。 在我们测试完成单个模块运行正确之后，还需要去验证单个模块与模块组合在一起时是否会出现问题，这个测试方式就是灰盒测试。 5. 为什么进行了白盒测试之后还要进行黑盒测试？白盒测试不仅仅关注输入与输出的结果是否正确，同时还关注程序是如何处理的。而黑盒测试在整个测试过程中只关注输入和输出，如果输入一个测试数据，输出的结果是正确的，我们就认为这个功能是正确的。虽然从某种角度来看，白盒测试比黑盒测试更为全面。但是有一些黑盒测试的内容是白盒测试不能做到的。比如黑盒测试是更接近于用户角度使用的测试，因此我们还会关注程序的易用性、界面展示、业务流程等，而白盒测试时并不考虑这些。 6. 测试基本流程是什么？ 需求分析：阅读需求文档，联合前端、后端、测试、产品等部门，确保各部门对需求理解一致，了解软件需要的具体功能； 计划编写：确定测试的目标和范围，对人力、物力进行分配，确定哪些人要具体做哪些事情，对进度进行安排，确定要使用哪些测试工具、测试策略； 用例设计：分析需求，从需求中提取测试点，用来设计测试用例； 用例执行，提交缺陷，回归测试：当进行测试后，会发现软件的缺陷。确定缺陷后，将缺陷提交给开发人员，开发人员修改后进行回归测试； 测试报告：编写测试的总结报告。 7. 常见的测试方法有哪些？7.1 等价类划分法适用于穷举场景下 具体内容：在所有的测试数据中，对具有某种共同特征的数据集合进行划分，然后从每一个子集中选取少数具有代表性的数据作为测试用例。 比如：验证6-10位自然数QQ号的合法性 按照等价类划分法： 有效等价类：6-10位自然数； 无效等价类：小于6位，大于10位自然数，以及6-10位非自然数 7.2 边界值分析法适用于有边界的范围 具体内容：对输入、输出的边界值进行测试，在边界值分析法中规范了要选择的边界值，上点、离点、内点。 上点：正好等于； 离点：刚好大于或刚好小于； 内点：范围内的点； image-20230827164118183 7.3 判定表法以表格的形式表达多条件依赖逻辑判断的工具。 比如：验证“若用户欠费或者关机，则不允许主被叫”功能的测试。 条件桩：列出问题中的所有条件，列出条件的次序无关紧要； 动作桩：列出问题中可能采取的操作，操作的排列顺序没有约束； 条件项：列出条件对应的取值，所有可能情况下的真假值； 动作项：列出条件项的、各种取值情况下应该采取的动作结果 image-20230827164544031 7.4 因果图分析法利用图解法分析输入的各种组合情况，从而设计测试用例。 7.5 错误推测法根据测试者以往的测试经验对可能出现的错误进行测试。 8 为什么要进行自动化测试？自动化测试是指使用自动化测试工具来执行测试用例。 通过采用自动化测试，可以替代大量重复性的工作，提高测试效率； 保证每次测试的一致性和可重复性。由于每次自动化测试执行时脚本都是相同的，所以每次执行的测试具有一致性，同时也可以提高回归测试的效率； 可以更好的利用非工作时间。由于自动化测试能按计划自动执行，因此就可以利用非工作时间使用自动化测试来执行测试。","tags":["Java","八股","基础","面试","测试"],"categories":["Java八股","基础"]},{"title":"快手二面","path":"/2023/08/10/快手二面/","content":"08.10 快手二面 自我介绍 介绍论文 说一说在项目里Redis的作用？怎么用的？ 那详细说一说项目里短信验证登录的流程？ 如果存验证码到Redis时，Redis没有返回存成功的结果，或者Redis直接超时，该怎么办？ 这里我说可以重试解决，但是面试官又继续问：“那一直没有返回消息或者说一直超时，难道要一直重试吗？重试无数次？” 然后我以为他问的是验证码已经存进去了，只是没有返回结果，我又说了Redis会对数据进行持久化，说了说持久化机制。 但是面试官说我没有理解他的意思，不过确实没有明白他到底要问的是啥，然后他让我回去好好想想。 后面回去想了想，结合后面问的问题，这个问题可能他要的答案是用主从模式+哨兵来解决，因为主节点负责读写，而从节点只负责读，所以在存取验证码的时候，如果主节点长时间没有返回结果或者超时，那么说明这个主节点已经失联了，哨兵就会推举出一个新的主节点与用户相连，继续支持用户写数据，然后与其他从节点之间进行数据同步。 Redis集群了解过吗？怎么保证主节点和从节点数据一致？ 如果主节点失联，那主节点和从节点数据还一致吗？ 你提到了哨兵模式，那哨兵是怎么知道有多少主节点多少从节点的？ 通过哨兵的自动发现机制实现的，一般情况下，哨兵节点每10秒向主从节点发送INFO命令，以此获取主从节点的信息。第一次执行的时候，哨兵仅知道我们给出的主节点信息，通过对主节点执行INFO命令就可以获取其从节点列表。这样周期性的循环，就可以不断地发现新加入的节点。 那哨兵之间是如何保持连接呢的？它们之间是怎么发现对方的呢？ 因为哨兵可以通过INFO命令发现主节点和从节点的信息，而Redis提供了一种发布订阅的消息通信模式，哨兵们就是通过一个约定好的频道发布&#x2F;订阅信息进行通信： 每隔2秒，每个哨兵就会通过它监控的主节点、从节点向频道发送一条hello消息； 每个哨兵会通过它监控的主节点、从节点订阅频道的消息，以此来接收其他哨兵发布的消息。 简单来说就有点类似于广播的方式，实现哨兵之间发现。 MySQL的原子性和持久性是怎么实现的？ 那MySQL一致性的底层是怎么实现的呢？ 这个我说了一致性是通过原子性、持久性、隔离性来实现的，然后又详细介绍了其他三个性质的底层实现，通过实现这三个性质来保证最后事务的一致性。 但是面试官又说：“没有理解我的意思，下去好好再想想”。 ？？？这个我是真的不知道他想问我什么了？？？ 难道是想问我主从模式之间实现的数据一致性？如果是的话也太逆天了，自己都没有说清楚问题。 说一说对象创建的过程吧 具体说说对象内存分配的过程 为什么大对象要直接移到老年代？ 那具体介绍一下垃圾回收机制和垃圾回收器 为什么要Full GC？什么时候触发Full GC？ 前面半个问题还算正常，后面半个问题是最逆天的。 我回答的是当新生代没有足够空间存放新对象，或老年代空间不足，或永久代空间不足等情况下才会触发Full GC。 然后面试官说：“我当然知道空间不足的时候会进行Full GC，我问的是什么时候触发Full GC？” 给我整蒙了，这我是真不知道该怎么回答了。 后面我详细查了一下，除了上面回答的空间不足会触发Full GC外，还有一种情况也会触发Full GC。 也就是Minor GC也会引发Full GC，这是因为JVM的空间担保机制引起的。 空间担保机制：在发生Minor GC之间，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间（是所有对象，并不仅仅是存活的对象，为什么？因为使用全部对象总和来判断，相对消耗的资源更小，速度更快，不用去判断哪些对象是存活的）。 当老年代剩余连续空间 &gt; 新生代所有对象总空间 &gt; 历次晋升到老年代的对象平均大小，这就是正常情况，会执行Minor GC； 当新生代所有对象总空间 &gt; 老年代剩余连续空间 &gt; 历次晋升到老年代的对象平均大小，这里又分为三种情况： Minor GC后，剩余的存活对象大小 &lt; Survivor区大小，这个时候存活的对象进入Survivor区； Minor GC后，Survivor区大小 &lt; 剩余的存活对象大小 &lt; 老年代可用内存大小，这个时候存活的对象进入老年代； Minor GC后，剩余的存活对象大小 &gt; 老年代可用内存大小，这时候连老年代都放不下，就会触发Full GC，如果Full GC之后仍然放不下，就会OOM； 当新生代所有对象总空间 &gt; 历次晋升到老年代的对象平均大小 &gt; 老年代剩余连续空间，就会直接触发Full GC。 最长回文子串","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"快手一面","path":"/2023/08/07/快手一面/","content":"08.07 快手一面 自我介绍 研究生期间学了哪些课程？ 介绍一下项目，说一下你负责的部分 项目怎么识别用户登录的状态的呢？ 项目用到了微服务，微服务有什么好处？ 项目里Redis做什么用？ 向Redis中存短信验证码的命令是什么？设置过期时间的命令是什么？可以一条命令解决吗？ 存储命令：set phoneNumber code 过期命令：expire phoneNumber 120 一条命令：set phoneNumber code ex 120 如果执行存储命令后，设置过期命令失效了，该怎么办？ Redis中有内存淘汰策略LRU和LFU，可以解决这个问题。 LRU是：。。。。 LFU是：。。。。 你还用了RabbitMQ，说说是怎么用的？解决了什么问题？ 说一说项目里面微信支付的流程 微信支付返回的结果是给前端还是后台？ String是不可变的，那么StringBuffer和StringBuilder是如何实现可变的呢？底层是什么？ StringBuffer和StringBuilder的底层是没有加final的char[]数组，默认长度是16，每次扩容大小为原长度 * 2 + 2； 通过含参构造添加元素时。 直接添加一个长度。数组的初始长度为该传入的长度； 直接添加一个字符串。数组的初始长度为该字符串的长度+16（str.length+16）。每次扩容为数组原长度 * 2 + 2； 突然自己想到一个问题：StringBuffer是怎么实现线程安全的呢？ 因为StringBuffer中很多方法上都是用synchronized关键字修饰的。 如果让你来实现StringBuffer和StringBuilder，你会怎么实现？ 介绍一下HashMap HashMap为什么线程不安全？ 那ConcurrentHashMap是怎么实现线程安全的？ 1.8之前ConcurrentHashMap支持多少线程同时操作？ 你提到了synchronized和ReentrantLock，那说一说这两个具体的实现？ 你说ReentrantLock是可重入的，那synchronized是可重入的吗？为什么？ synchronized是可重入锁，每个可重入锁都会关联一个线程ID和一个锁状态status。 当一个线程请求方法时，会去检查锁状态。 如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。 如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，且是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。 在释放锁时， 如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。 如果非可重入锁的，线程退出方法，直接就会释放该锁。 如果发生异常，synchronized会释放锁吗？为什么？ 如果发生异常，并且没有捕获异常，整个执行流程会立即终止，退出代码块，并释放锁。 知道ThreadLocal吗？介绍一下ThreadLocal的结构 ThreadLocal为什么会引起内存泄漏问题？怎么解决？ 反转链表 最长递增子序列","tags":["Java","八股","基础","面试","面经"],"categories":["面经"]},{"title":"常见智力题","path":"/2023/07/27/常见智力题/","content":"1、三人三鬼过桥有三个人跟三个鬼要过河,河上没桥只有条小船，船一次只能渡一个人和一个鬼或两个鬼或两个人。 无论在哪边岸上，只要是人比鬼少的情况下(如两鬼一人,三鬼两人,三鬼一人)人会被鬼吃，船又一定需要人或鬼操作才能航行(要有人或鬼划船)。 问：如何安全的把三人三鬼渡过河对岸? 参考回答 先两鬼过去，再一鬼回来。对面有一鬼，这边有三人两鬼。 再两鬼过去，再一鬼回来。对面有两鬼，这边有三人一鬼。 再两人过去，一人一鬼回来。对面一人一鬼，这边两人两鬼。 最后两人过去，一鬼回来。对面三人，这边三鬼。 剩下的就三个鬼，二个过去，一个回来，再接另外一个鬼。 2、赛马找最快的马匹（腾讯高频题）一般有这么几种问法： 25匹马5条跑道找最快的3匹马，需要跑几次？参考回答：7 64匹马8条跑道找最快的4匹马，需要跑几次？参考回答：11 25匹马5条跑道找最快的5匹马，需要跑几次？参考回答：最少8次最多9次 建议画图表来看，将问题简单化一点，将大问题化成小问题即可，同时B站有个讲解视频还不错：https://www.bilibili.com/video/BV1KJ411g78y 详细解法： 1、25匹马5条跑道找最快的3匹马，需要跑几次？ 将25匹马分成ABCDE5组，假设每组的排名就是A1&gt;A2&gt;A3&gt;A4&gt;A5,用边相连，这里比赛5次 第6次，每组的第一名进行比赛，可以找出最快的马，这里假设A1&gt;B1&gt;C1&gt;D1&gt;E1 D1，E1肯定进不了前3，直接排除掉 第7次，B1 C1 A2 B2 A3比赛，可以找出第二，第三名 所以最少比赛需要7次 2、64匹马8条跑道找最快的4匹马，需要跑几次？ 全部马分为8组，每组8匹，每组各跑一次，然后淘汰掉每组的后四名，需要比赛8场 取每组第一名进行一次比赛，然后淘汰最后四名所在组的所有马，需要比赛1场，这个时候总冠军已经诞生，它就是A1。而其他可能跑得最快的三匹马只可能是A2,A3,A4,B1,B2,B3,C1,C2,D1，共9匹马。 只要从上面的9匹马中找出跑得最快的三匹马就可以了，但是现在只要8个跑道，怎么办？那就随机选出8匹马进行一次比赛吧，需要比赛一场。 上面比赛完，选出了前三名，但是9匹马中还有一匹马没跑呢，它可能是一个潜力股啊，那就和前三名比一比吧，这四匹马比一场，选出前三名。 最后加上总冠军，跑得最快的四匹马诞生了！！！（需要一场比赛） 所以一共需要比赛的场次：8 + 1 + 1 + 1 &#x3D; 11 场 3、25匹马5条跑道找最快的5匹马，需要跑几次？ (1) 首先将25匹马分成5组，并分别进行5场比赛之后得到的名次排列如下： A组： [A1 A2 A3 A4 A5] B组： [B1 B2 B3 B4 B5] C组： [C1 C2 C3 C4 C5] D组： [D1 D2 D3 D4 D5] E组： [E1 E2 E3 E4 E5] 其中，每个小组最快的马为[A1、B1、C1、D1、E1]。 (2) 将[A1、B1、C1、D1、E1]进行第6场，选出第1名的马，不妨设 A1&gt;B1&gt;C1&gt;D1&gt;E1. 此时第1名的马为A1。 (3) 将[A2、B1、C1、D1、E1]进行第7场，此时选择出来的必定是第2名的马，不妨假设为B1。因为这5匹马是除去A1之外每个小组当前最快的马。 (3) 进行第8场，选择[A2、B2、C1、D1、E1]角逐出第3名的马。 (4) 依次类推，第9，10场可以分别决出第4，5名的吗。 因此，依照这种竞标赛排序思想，需要10场比赛是一定可以取出前5名的。 仔细想一下，如果需要减少比赛场次，就一定需要在某一次比赛中同时决出2个名次，而且每一场比赛之后，有一些不可能进入前5名的马可以提前出局。 当然要做到这一点，就必须小心选择每一场比赛的马匹。我们在上面的方法基础上进一步思考这个问题，希望能够得到解决。 (1) 首先利用5场比赛角逐出每个小组的排名次序是绝对必要的。 (2) 第6场比赛选出第1名的马也是必不可少的。假如仍然是A1马(A1&gt;B1&gt;C1&gt;D1&gt;E1)。那么此时我们可以得到一个重要的结论：有一些马在前6场比赛之后就决定出局的命运了(下面粉色字体标志出局)。 A组： [A1 A2 A3 A4 A5] B组： [B1 B2 B3 B4 B5 ] C组： [C1 C2 C3 C4 C5 ] D组： [D1 D2 D3 D4 D5 ] E组： [E1 E2 E3 E4 E5 ] (3) 第7场比赛是关键，能否同时决出第2，3名的马呢？我们首先做下分析： 在上面的方法中，第7场比赛[A2、B1、C1、D1、E1]是为了决定第2名的马。但是在第6场比赛中我们已经得到(B1&gt;C1&gt;D1&gt;E1)，试问？有B1在的比赛，C1、D1、E1还有可能争夺第2名吗？ 当然不可能，也就是说第2名只能在A2、B1中出现。实际上只需要2条跑道就可以决出第2名，剩下C1、D1、E1的3条跑道都只能用来凑热闹的吗？ 能够优化的关键出来了，我们是否能够通过剩下的3个跑道来决出第3名呢？当然可以，我们来进一步分析第3名的情况？ ● 如果A2&gt;B1(即第2名为A2)，那么根据第6场比赛中的(B1&gt;C1&gt;D1&gt;E1)。 可以断定第3名只能在A3和B1中产生。 ● 如果B1&gt;A2(即第2名为B1)，那么可以断定的第3名只能在A2, B2,C1 中产生。 好了，结论也出来了，只要我们把[A2、B1、A3、B2、C1]作为第7场比赛的马，那么这场比赛的第2，3名一定是整个25匹马中的第2，3名。 我们在这里列举出第7场的2，3名次的所有可能情况： ① 第2名&#x3D;A2，第3名&#x3D;A3 ② 第2名&#x3D;A2，第3名&#x3D;B1 ③ 第2名&#x3D;B1，第3名&#x3D;A2 ④ 第2名&#x3D;B1，第3名&#x3D;B2 ⑤ 第2名&#x3D;B1，第3名&#x3D;C1 (4) 第8场比赛很复杂，我们要根据第7场的所有可能的比赛情况进行分析。 ① 第2名&#x3D;A2，第3名&#x3D;A3。那么此种情况下第4名只能在A4和B1中产生。 ● 如果第4名&#x3D;A4，那么第5名只能在A5、B1中产生。 ● 如果第4名&#x3D;B1，那么第5名只能在A4、B2、C1中产生。 不管结果如何，此种情况下，第4、5名都可以在第8场比赛中决出。其中比赛马匹为[A4、A5、B1、B2、C1] ② 第2名&#x3D;A2，第3名&#x3D;B1。那么此种情况下第4名只能在A3、B2、C1中产生。 ● 如果第4名&#x3D;A3，那么第5名只能在A4、B2、C1中产生。 ● 如果第4名&#x3D;B2，那么第5名只能在A3、B3、C1中产生。 ● 如果第4名&#x3D;C1，那么第5名只能在A3、B2、C2、D1中产生。 那么，第4、5名需要在马匹[A3、B2、B3、C1、A4、C2、D1]七匹马中产生，则必须比赛两场才行，也就是到第9场角逐出全部的前5名。 ③ 第2名&#x3D;B1，第3名&#x3D;A2。那么此种情况下第4名只能在A3、B2、C1中产生。 情况和②一样，必须角逐第9场 ④ 第2名&#x3D;B1，第3名&#x3D;B2。 那么此种情况下第4名只能在A2、B3、C1中产生。 ● 如果第4名&#x3D;A2，那么第5名只能在A3、B3、C1中产生。 ● 如果第4名&#x3D;B3，那么第5名只能在A2、B4、C1中产生。 ● 如果第4名&#x3D;C1，那么第5名只能在A2、B3、C2、D1中产生。 那么，第4、5名需要在马匹[A2、B3、B4、C1、A3、C2、D1]七匹马中产 生，则必须比赛两场才行，也就是到第9场角逐出全部的前5名。 ⑤ 第2名&#x3D;B1，第3名&#x3D;C1。那么此种情况下第4名只能在A2、B2、C2、D1中产生。 ● 如果第4名&#x3D;A2，那么第5名只能在A3、B2、C2、D1中产生。 ● 如果第4名&#x3D;B2，那么第5名只能在A2、B3、C2、D1中产生。 ● 如果第4名&#x3D;C2，那么第5名只能在A2、B2、C3、D1中产生。 ● 如果第4名&#x3D;D1，那么第5名只能在A2、B2、C2、D2、E2中产生。 那么，第4、5名需要在马匹[A2、B2、C2、D1、A3、B3、C3、D2、E1]九匹马中 产 生，因此也必须比赛两场，也就是到第9长决出胜负。 总结：最好情况可以在第8场角逐出前5名，最差也可以在第9场搞定。 3、给定随机函数，生成别的随机数给定生成1到5的随机数Rand5()，如何得到生成1到7的随机数函数Rand7()？ 思路： 由大的生成小的容易，比如由Rand7()生成Rand5()，所以我们先构造一个大于7（1-21）的随机数生成函数。 记住下面这个式子： 12RandNN= N(RandN()-1) + RandN() ;// 生成1到N^2之间的随机数RandN()-1的目的是生成0到N-1的数，是跳数。后面+RandN()的目的是填满中间的空隙 比如Rand25= 5(Rand5()-1) + Rand5()可以生成1到25之间的随机数。我们可以只要1到21（3*7）之间的数字，所以可以这么写 1234567int rand7()&#123; int x=INT_MAX; while(x&gt;21)&#123; x=5*(rand5()-1)+rand5(); &#125; return x%7+1;&#125; 思路：rand5() -&gt; rand25() -&gt; rand21() -&gt;rand7() 4、砝码称轻重，找出最轻的其实这都是一类题，这里列举几个经典的： 1、有一个天平，九个砝码，其中一个砝码比另八个要轻一些，问至少要用天平称几次才能将轻的那个找出来？ 参考回答：至少2次。第一次，一边3个，哪边轻就在哪边，一样重就是剩余的3个； 第二次，一边1个，哪边轻就是哪个，一样重就是剩余的那个；至少称2次． 2、十组砝码每组十个，每个砝码都是10g重，但是现在其中有一组砝码每个都只有9g重，现有一个能显示克数的秤，最少称几次能找到轻的那组？ 参考回答：1次 参考回答：至少1次。 将砝码分组1~10，第一组拿一个，第二组拿两个以此类推。。第十组拿十个放到秤上称出克数x，则y &#x3D; 550 - x，第y组就是轻的那组。 5、利用空瓶换饮料，最多喝几瓶1000瓶饮料，3个空瓶子能够换1瓶饮料，问最多能喝几瓶？ 拿走3瓶，换回1瓶，相当于减少2瓶。但是最后剩下4瓶的时候例外，这时只能换1瓶。所以我们计算1000减2能减多少次，直到剩下4.（1000-4&#x3D;996，996&#x2F;2&#x3D;498）所以1000减2能减498次直到剩下4瓶，最后剩下的4瓶还可以换一瓶，所以总共是1000+498+1&#x3D;1499瓶。 6、毒药毒白鼠，找出哪个瓶子中是毒药有1000个一模一样的瓶子，其中有999瓶是普通的水，有1瓶是毒药。任何喝下毒药的生命都会在一星期之后死亡。现在你只有10只小白鼠和1个星期的时间，如何检验出哪个瓶子有毒药？ 答：二进制为1，则让指定的老鼠喝。 7、利用烧绳子计算时间（15 30 45 75）现有若干不均匀的绳子，烧完这根绳子需要一个小时，问如何准确计时15分钟，30分钟，45分钟，75分钟 计算15分钟：先同时烧烧一半，然后两头烧得到15分钟。 计算30分钟：两头烧 计算45分钟：两根，一根两头烧一根一头烧，两头烧完过了30分钟，立即将第二根另一头点燃，到烧完又过15分钟，加起来45分钟 计算75分钟：将30和45分钟的方式加起来就可以了 其余类似。 8、在24小时里面时针分针秒针可以重合几次（22）24小时中时针走2圈，而分针走24圈，时针和分针重合24-2&#x3D;22次，而只要时针和分针重合，秒针一定有机会重合，所以总共重合22次 9、100个奴隶猜帽子颜色一百个奴隶站成一纵列，每人头上随机带上黑色或白色的帽子，各人不知道自己帽子的颜色，但是能看见自己前面所有人帽子的颜色． 然后从最后一个奴隶开始，每人只能用同一种声调和音量说一个字：”黑”或”白”， 如果说中了自己帽子的颜色，就存活，说错了就拉出去斩了，说的参考回答所有奴隶都能听见。 是否说对，其他奴隶不知道。 在这之前，所有奴隶可以聚在一起商量策略，问如果奴隶都足够聪明而且反应足够快，100个人最大存活率是多少？ 参考回答：这是一道经典推理题 1、最后一个人如果看到奇数顶黑帽子报“黑”否则报“白”，他可能死 2、其他人记住这个值（实际是黑帽奇偶数），在此之后当再听到黑时，黑帽数量减一 3、从倒数第二人开始，就有两个信息：记住的值与看到的值，相同报“白”，不同报“黑” 99人能100%存活，1人50%能活 另外，此题还有变种：每个奴隶只能看见前面一个人帽子颜色又能最多存活多少人？ 参考回答：增加限制条件后，上面的方法就失效了，此时只能约定偶数位奴隶说他前一个人的帽子颜色，奇数奴隶获取信息100%存活，偶数奴隶50几率存活。 10、 小猴子搬香蕉（16根）一个小猴子边上有100根香蕉，它要走过50米才能到家，每次它最多搬50根香蕉，（多了就被压死了），它每走 1米就要吃掉一根，请问它最多能把多少根香蕉搬到家里？ （提示：他可以把香蕉放下往返的走，但是必须保证它每走一米都能有香蕉吃。也可以走到n米时，放下一些香蕉，拿着n根香蕉走回去重新搬50根。） 参考回答：这种试题通常有一个迷惑点，让人看不懂题目的意图。此题迷惑点在于：走一米吃一根香蕉，一共走50米，那不是把50根香蕉吃完了吗？如果要回去搬另外50根香蕉，则往回走的时候也要吃香蕉，这样每走一米需要吃掉三根香蕉，走50米岂不是需要150根香蕉？ 其实不然，本题关键点在于：猴子搬箱子的过程其实分为两个阶段，第一阶段：来回搬，当香蕉数目大于50根时，猴子每搬一米需要吃掉三根香蕉。第二阶段：香蕉数《&#x3D;50，直接搬回去。每走一米吃掉1根。 我们分析第一阶段：假如把100根香蕉分为两箱。一箱50根。 第一步，把A箱搬一米，吃一根。 第二步，往回走一米，吃一根。 第三步，把B箱搬一米，吃一根。 这样，把所有香蕉搬走一米需要吃掉三根香蕉。 这样走到第几米的时候，香蕉数刚好小于50呢？ 100-(n*3)&lt;50 &amp;&amp; 100-(n-1*3)&gt;50 走到16米的时候，吃掉48根香蕉，剩52根香蕉。这步很有意思，它可以直接搬50往前走，也可以再来回搬一次，但结果都是一样的。 到17米的时候，猴子还有49根香蕉。这时猴子就轻松啦，直接背着走就行。 第二阶段： 走一米吃一根。 把剩下的50-17&#x3D;33米走完。还剩49-33&#x3D;16根香蕉。 11、高楼扔鸡蛋（暴力100 二分50 均匀法18）有2个鸡蛋，从100层楼上往下扔，以此来测试鸡蛋的硬度。比如鸡蛋在第9层没有摔碎，在第10层摔碎了，那么鸡蛋不会摔碎的临界点就是9层。 问：如何用最少的尝试次数，测试出鸡蛋不会摔碎的临界点？ 1、暴力法举个例子，最笨的测试方法，是什么样的呢？把其中一个鸡蛋，从第1层开始往下扔。如果在第1层没碎，换到第2层扔；如果在第2层没碎，换到第3层扔…….如果第59层没碎，换到第60层扔；如果第60层碎了，说明不会摔碎的临界点是第59层。 在最坏情况下，这个方法需要扔100次。 2、二分法（50-&gt;75）采用类似于二分查找的方法，把鸡蛋从一半楼层（50层）往下扔。 如果第一枚鸡蛋，在50层碎了，第二枚鸡蛋，就从第1层开始扔，一层一层增长，一直扔到第49层。 如果第一枚鸡蛋在50层没碎了，则继续使用二分法，在剩余楼层的一半（75层）往下扔…… 这个方法在最坏情况下，需要尝试50次。 3、均匀法如何让第一枚鸡蛋和第二枚鸡蛋的尝试次数，尽可能均衡呢？ 很简单，做一个平方根运算，100的平方根是10。 因此，我们尝试每10层扔一次，第一次从10层扔，第二次从20层扔，第三次从30层……一直扔到100层。 这样的最好情况是在第10层碎掉，尝试次数为 1 + 9 &#x3D; 10次。 最坏的情况是在第100层碎掉，尝试次数为 10 + 9 &#x3D; 19次。 不过，这里有一个小小的优化点，我们可以从15层开始扔，接下来从25层、35层扔……一直到95层。 这样最坏情况是在第95层碎掉，尝试次数为 9 + 9 &#x3D; 18次。 4、最优解法最优解法是反向思考的经典：如果最优解法在最坏情况下需要扔X次，那第一次在第几层扔最好呢？ 参考回答是：从X层扔 假设最优的尝试次数的x次，为什么第一次扔就要选择第x层呢？ 这里的解释会有些烧脑，请小伙伴们坐稳扶好： 假设第一次扔在第x+1层： 如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x层。 这样一来，我们总共尝试了x+1次，和假设尝试x次相悖。由此可见，第一次扔的楼层必须小于x+1层。 假设第一次扔在第x-1层： 如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-2层。 这样一来，我们总共尝试了x-2+1 &#x3D; x-1次，虽然没有超出假设次数，但似乎有些过于保守。 假设第一次扔在第x层： 如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-1层。 这样一来，我们总共尝试了x-1+1 &#x3D; x次，刚刚好没有超出假设次数。 因此，要想尽量楼层跨度大一些，又要保证不超过假设的尝试次数x，那么第一次扔鸡蛋的最优选择就是第x层。 那么算最坏情况，第二次你只剩下x-1次机会，按照上面的说法，你第二次尝试的位置必然是X+（X-1）； 以此类推我们可得： x + (x-1) + (x-2) + … + 1 &#x3D; 100 这个方程式不难理解： 左边的多项式是各次扔鸡蛋的楼层跨度之和。由于假设尝试x次，所以这个多项式共有x项。 右边是总的楼层数100。 下面我们来解这个方程： x + (x-1) + (x-2) + … + 1 &#x3D; 100 转化为 (x+1)*x&#x2F;2 &#x3D; 100 最终x向上取整，得到 x &#x3D; 14 因此，最优解在最坏情况的尝试次数是14次，第一次扔鸡蛋的楼层也是14层。 最后，让我们把第一个鸡蛋没碎的情况下，所尝试的楼层数完整列举出来： 14，27， 39， 50， 60， 69， 77， 84， 90， 95， 99， 100 举个例子验证下： 假如鸡蛋不会碎的临界点是65层，那么第一个鸡蛋扔出的楼层是14，27，50，60，69。这时候啪的一声碎了。 第二个鸡蛋继续，从61层开始，61，62，63，64，65，66，啪的一声碎了。 因此得到不会碎的临界点65层，总尝试次数是 6 + 6 &#x3D; 12 &lt; 14 。 13、5个强盗分配100个金币，求方案使得自己分配最多（97，0，1，2，0）或（97，0，1，0，2）5个海盗抢到了100枚金币，每一颗都一样的大小和价值。 他们决定这么分： 抽签决定自己的号码（1，2，3，4，5） 首先，由1号提出分配方案，然后大家5人进行表决，当半数以上的人同意时（ 不包括半数，这是重点），按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 如果1号死后，再由2号提出分配方案，然后大家4人进行表决，当且仅当半超过半数的人同意时，按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 依次类推…… 假设每一位海盗都足够聪明，并且利益至上，能多分一枚金币绝不少分，那么1号海盗该怎么分金币才能使自己分到最多的金币呢？ 参考回答 从后向前推，如果1至3号强盗都喂了鲨鱼，只剩4号和5号的话，5号一定投反对票让4号喂鲨鱼，以独吞全部金币。所以，4号惟有支持3号才能保命。 3号知道这一点，就会提出“100，0，0”的分配方案，对4号、5号一毛不拔而将全部金币归为已有，因为他知道4号一无所获但还是会投赞成票，再加上自己一票，他的方案即可通过。 不过，2号推知3号的方案，就会提出“98，0，1，1”的方案，即放弃3号，而给予4号和5号各一枚金币。由于该方案对于4号和5号来说比在3号分配时更为有利，他们将支持他而不希望他出局而由3号来分配。这样，2号将拿走98枚金币。 同样，2号的方案也会被1号所洞悉，1号并将提出（97，0，1，2，0）或（97，0，1，0，2）的方案，即放弃2号，而给3号一枚金币，同时给4号（或5号）2枚金币。由于1号的这一方案对于3号和4号（或5号）来说，相比2号分配时更优，他们将投1号的赞成票，再加上1号自己的票，1号的方案可获通过，97枚金币可轻松落入囊中。这无疑是1号能够获取最大收益的方案了！参考回答是：1号强盗分给3号1枚金币，分给4号或5号强盗2枚，自己独得97枚。分配方案可写成（97，0，1，2，0）或（97，0，1，0，2）。 14、火枪手决斗，谁活下来的概率大？问题：彼此痛恨的甲、乙、丙三个枪手准备决斗。甲枪法最好，十发八中；乙枪法次之，十发六中；丙枪法最差，十发四中。如果三人同时开枪，并且每人每轮只发一枪；那么枪战后，谁活下来的机会大一些？ 参考回答 一般人认为甲的枪法好，活下来的可能性大一些。但合乎推理的结论是，枪法最糟糕的丙活下来的几率最大。 那么我们先来分析一下各个枪手的策略。 如同田忌赛马一般，枪手甲一定要对枪手乙先。因为乙对甲的威胁要比丙对甲的威胁更大，甲应该首先干掉乙，这是甲的最佳策略。 同样的道理，枪手乙的最佳策略是第一枪瞄准甲。乙一旦将甲干掉，乙和丙进行对决，乙胜算的概率自然大很多。 枪手丙的最佳策略也是先对甲。乙的枪法毕竟比甲差一些，丙先把甲干掉再与乙进行对决，丙的存活概率还是要高一些。 我们根据分析来计算一下三个枪手在上述情况下的存活几率： 第一轮：甲射乙，乙射甲，丙射甲。 甲的活率为24%（40% X 60%） 乙的活率为20%(100% - 80%) 丙的活率为100%（无人射丙）。 由于丙100％存活率，因此根据上轮甲乙存活的情况来计算三人第二轮的存活几率： 情况1：甲活乙死（24% X 80% &#x3D; 19.2%） 甲射丙，丙射甲：甲的活率为60%，丙的活率为20%。 情况2：乙活甲死（20% X 76% &#x3D; 15.2%） 乙射丙，丙射乙：乙的活率为60%，丙的活率为40%。 情况3：甲乙同活（24% X 20% &#x3D; 4.8%） 重复第一轮。 情况4：甲乙同死（76% X 80% &#x3D; 60.8%） 枪战结束。 据此来计算三人活率： 甲的活率为(19.2% X 60%) + (4.8% X 24%) &#x3D; 12.672% 乙的活率为(15.2% X 60%) + (4.8% X 20%) &#x3D; 10.08% 丙的活率为(19.2% X 20%) + (15.2% X 40%) + (4.8% X 100%) + (60.8% X 100%) &#x3D; 75.52% 通过对两轮枪战的详细概率计算，我们发现枪法最差的丙存活的几率最大，枪法较好的甲和乙的存活几率却远低于丙的存活几率。 15、先手必胜的问题（100本，一次1-5本，如何拿保证最后你拿）100本书，每次能够拿1-5本，怎么拿能保证最后一次是你拿？ 参考回答 寻找每个回合固定的拿取模式，最后一次是我拿，那么上个回合最少剩下6本。那么只要保持每个回合结束后都剩下6的倍数，并且在这个回合中我拿的和对方拿的加起来为6（这样这个回合结束后剩下的还是6的倍数），就必胜。 关键是第一次我必须先手拿（100%6&#x3D;4）本（这不算在第一回合里面）。 16、掰巧克力问题或者参加辩论赛1、掰巧克力问题 N * M块巧克力，每次掰一块的一行或一列，掰成11的巧克力需要多少次？*（N * M - 1） 2、1000个人参加辩论赛，1V1，输了就退出，需要安排多少场比赛？**(1000 -1 &#x3D; 999)** 17、N只蚂蚁走树枝，问总距离或者总时间问题：放N只蚂蚁在一条长度为M树枝上，蚂蚁与蚂蚁之间碰到就各自往反方向走，问总距离或者时间为多少？ 参考回答：这个其实就一个诀窍：蚂蚁相碰就往反方向走，可以直接看做没有发生任何事：大家都相当于独立的 A蚂蚁与B蚂蚁相碰后你可以看做没有发生这次碰撞，这样无论是求时间还是距离都很简单了。","tags":["Java","八股","面试","智力题"],"categories":["Java八股","扩展内容"]},{"title":"常考手撕代码","path":"/2023/07/20/常考手撕代码/","content":"一、排序算法下图是十大经典的排序算法 十大经典的排序算法 1.1 冒泡排序1.1.1 算法思想重复遍历要排序的序列，依次比较两个元素，如果顺序错误，就交换位置。 冒泡排序 1.1.2 算法步骤 比较相邻元素。如果第一个比第二个大，就换位置； 对每一对相邻元素做同样的工作，从开始第一队到结尾的最后一对，这样每次都能找出最大的一个； 针对所有元素重复以上步骤； 重复1-3步，直到排序完成。 1.1.3 代码实现1234567891011121314151617/** * 冒泡排序，从小到大 * nums = [1,8,6,7,9,2]; * @param nums */public static int[] bubbleSort(int[] nums)&#123; for(int i = nums.length - 1; i &gt; 0; i--)&#123; for (int j = 0; j &lt; i; j++) &#123; if (nums[j] &gt; nums[j + 1])&#123; int temp = nums[j]; nums[j] = nums[j + 1]; nums[j + 1] = temp; &#125; &#125; &#125; return nums;&#125; 1.1.4 算法分析 稳定性：稳定 时间复杂度：最佳：O(n) ，最差：O(n^2)， 平均：O(n^2) 空间复杂度：O(1) 排序方式：占用常数内存，不占用额外内存 1.2 选择排序1.2.1 算法思想在未排序的序列中找到最小的元素，然后存放在最开始的位置，然后继续从未排序的元素中找最小的，以此类推。 特点就是不论什么顺序的数据，时间复杂度都是O(n^2)。 Selection Sort 1.2.2 算法步骤 首先在未排序的序列中找最小的元素，放到序列最开始的位置； 然后在剩下的未排序序列中找最小的元素，放到已排序的序列末尾； 重复第二步，直到排序结束。 1.2.3 代码实现1234567891011121314151617181920/** * 选择排序，从小到大 * @param nums * @return */public static int[] selectionSort(int[] nums)&#123; for (int i = 0; i &lt; nums.length; i++) &#123; int min = Integer.MAX_VALUE, index = 0; for (int j = i; j &lt; nums.length; j++)&#123; if (nums[j] &lt; min)&#123; min = nums[j]; index = j; &#125; &#125; int temp = nums[index]; nums[index] = nums[i]; nums[i] = temp; &#125; return nums;&#125; 1.2.4 算法分析 稳定性：不稳定 时间复杂度：最佳：O(n^2) ，最差：O(n^2)， 平均：O(n^2) 空间复杂度：O(1) 排序方式：不需要额外空间 1.3 快速排序1.3.1 算法思想用到了分治思想，将问题划分为子问题，然后排序子串，最后合并。 通过一趟排序将待排序列分为独立的两部分，其中一部分记录的元素均比另一部分的元素小，则可分别对这两部分子序列继续进行排序，以达到整体有序。 RandomQuickSort 1.3.2 算法步骤 从序列中随机挑选一个元素，作为基准(pivot)； 重新排序，将所有比基准值小的元素摆放在基准前面，比基准值大的元素摆放在基准的后面。基准就位于中间位置，这就是分区（partition）。 递归地把小于基准元素的子序列和大于基准元素的子序列进行快排。 1.3.3 代码实现123456789101112131415161718192021222324252627282930313233343536373839/** * 快排，递归 * @param nums * @param low * @param high */private static void quickSort(int[] nums, int low, int high) &#123; if (low &lt; high)&#123; int position = partition(nums, low, high); quickSort(nums, low, position - 1); quickSort(nums, position + 1, high); &#125;&#125;/** * 分区，返回每次分区的基值 * @param nums * @param low * @param high * @return */private static int partition(int[] nums, int low, int high) &#123; int pivot = nums[high]; int index = low; for (int i = low; i &lt; high; i++) &#123; if (nums[i] &lt;= pivot)&#123; swap(nums, i, index); index++; &#125; &#125; swap(nums, index, high); return index;&#125;public static void swap(int[] num, int i, int j)&#123; int temp = num[i]; num[i] = num[j]; num[j] = temp;&#125; 1.3.4 算法分析 稳定性：不稳定 时间复杂度：最佳：O(nlogn)， 最差：O(nlogn)，平均：O(nlogn) 空间复杂度：O(nlogn) 1.3.5 优化快排在快排的基础上加了随机和去重。 123456789101112131415161718192021222324252627282930313233343536373839private static void quickSort(int[] nums, int low, int high)&#123; if (low &lt; high)&#123; int position = partition(nums, low, high); int leftPosition = position - 1; int rightPosition = position + 1; //去重 while (leftPosition &gt; low &amp;&amp; nums[leftPosition] == nums[position])&#123; leftPosition--; &#125; //去重 while (rightPosition &lt; high &amp;&amp; nums[rightPosition] == nums[position])&#123; rightPosition++; &#125; quickSort(nums, low, leftPosition); quickSort(nums, rightPosition, high); &#125;&#125;private static int partition(int[] nums, int low, int high) &#123; //随机 int randomIndex = low + (int)Math.random() *(high - low + 1); swap(nums, high, randomIndex); int pivot = nums[high]; int index = low; for (int i = low; i &lt; high; i++)&#123; if (nums[i] &lt;= pivot)&#123; swap(nums, i, index); index++; &#125; &#125; swap(nums, index, high); return index;&#125;private static void swap(int[] nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp;&#125; 1.4 堆排序1.4.1 算法思想利用堆的数据结构特性，即子节点的值总是小于（或大于）其父节点。 HeapSort 1.4.2 算法步骤 将初始待排序列构建成大顶堆，次堆为初始的无序区。 将堆顶元素 R[1] 与最后一个元素 R[n] 交换，此时得到新的无序区 (R1, R2, ……, Rn-1) 和新的有序区 (Rn), 且满足 R[1, 2, ……, n-1]&lt;=R[n]； 由于交换后的新堆R[1]可能违反堆的性质，因此需要对当前无序区重新调整，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区和有序区。不断重复，直到排序过程完成。 1.4.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 全局变量，用来记录当前堆的长度public static int heapLen;/*** 堆排序* @param nums* @return*/public static int[] heapSort(int[] nums) &#123; heapLen = nums.length; buildMaxHeap(nums); for (int i = nums.length - 1; i &gt; 0; i--) &#123; swap(nums, 0, i); heapLen--; heapify(nums, 0); &#125; return nums;&#125;/*** 建立大顶堆* @param nums*/private static void buildMaxHeap(int[] nums) &#123; for (int i = nums.length / 2 - 1; i &gt;= 0; i--) &#123; heapify(nums, i); &#125;&#125;/*** 调整大顶堆* @param nums* @param i*/private static void heapify(int[] nums, int i) &#123; int left = 2 * i + 1; int right = 2 * i + 2; int largest = i; if (left &lt; heapLen &amp;&amp; nums[left] &gt; nums[largest])&#123; largest = left; &#125; if (right &lt; heapLen &amp;&amp; nums[right] &gt; nums[largest])&#123; largest = right; &#125; if (largest != i)&#123; swap(nums, i, largest); heapify(nums, largest); &#125;&#125;private static void swap(int[] nums, int i, int j) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp;&#125; 1.4.4 算法分析 稳定性：不稳定 时间复杂度：最佳：O(nlogn)， 最差：O(nlogn)， 平均：O(nlogn) 空间复杂度：O(1) 1.5 归并排序1.5.1 算法思想也是采用分治算法的典型，将已有序的子序列合并，得到完全有序的序列，也称为2路归并。代价是需要额外的内存空间。 MergeSort 1.5.2 算法步骤 如果输入只有一个元素，则直接返回，否则将长度为n的输入序列分为两个长度为n&#x2F;2的子序列； 分别对这两个子序列进行归并排序，使子序列变为有序状态； 设定两个指针，分别指向两个已经排序子序列的起始位置； 比较两个指针所指向的元素，选择相对较小的放入到合并空间，并移动指针； 重复第3步和第4步，直到全部有序 1.5.3 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 /** * 归并排序 * @param nums * @return */ private static void mergeSort(int[] nums, int low, int high) &#123; if (low &lt; high)&#123; int mid = (low + high) / 2; //归并左边 mergeSort(nums, low, mid); //归并右边 mergeSort(nums, mid + 1, high); //合并两边的数组 merge(nums, low, mid, high); &#125; &#125; /** * 合并两个数组 * @param nums * @param low * @param mid * @param high */ private static void merge(int[] nums, int low, int mid, int high) &#123; int[] arr = new int[high - low + 1]; int index = 0; int left = low, right = mid + 1; //看谁小，谁就先放前面 while(left &lt;= mid &amp;&amp; right &lt;= high)&#123; if (nums[left] &lt; nums[right])&#123; arr[index++] = nums[left++]; &#125;else&#123; arr[index++] = nums[right++]; &#125; &#125; //如果左边还没合并完 while(left &lt;= mid)&#123; arr[index++] = nums[left++]; &#125; //如果右边还没合并完 while (right &lt;= high)&#123; arr[index++] = nums[right++]; &#125; //将合并好的结果放回原来的数组 for (int i = 0; i &lt; arr.length; i++) &#123; nums[i + low] = arr[i]; &#125; &#125;&#125; 1.5.4 算法分析 稳定性：稳定 时间复杂度：最佳：O(nlogn)， 最差：O(nlogn)， 平均：O(nlogn) 空间复杂度：O(n) 二、红黑树2.1 红黑树性质红黑树是一种近似平衡的二叉查找树，但并非绝对平衡，但是可以保证任何一个节点的左右子树的高度差不会超过二者中较低的那个的一倍。 特点： 每个节点要么是黑色，要么是红色。 根节点是黑色。 每个叶子节点（NULL）是黑色。 每个红色结点的两个子结点一定都是黑色。 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 img 红黑树为什么能自平衡？ 红黑树总是通过旋转和变色达到自平衡。 左旋：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。 右旋：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。 变色：结点的颜色由红变黑或由黑变红。 img img 左旋只影响旋转结点和其右子树的结构，把右子树的结点往左子树挪了。右旋只影响旋转结点和其左子树的结构，把左子树的结点往右子树挪了。 2.2 红黑树查找 从根结点开始查找，把根结点设置为当前结点； 若当前结点为空，返回null； 若当前结点不为空，用当前结点的key跟查找key作比较； 若当前结点key等于查找key，那么该key就是查找目标，返回当前结点； 若当前结点key大于查找key，把当前结点的左子结点设置为当前结点，重复步骤2； 若当前结点key小于查找key，把当前结点的右子结点设置为当前结点，重复步骤2； 2.3 红黑树插入首先找插入的位置，然后再自平衡。 从根结点开始查找； 若根结点为空，那么插入结点作为根结点，结束。 若根结点不为空，那么把根结点作为当前结点； 若当前结点为null，返回当前结点的父结点，结束。 若当前结点key等于查找key，那么该key所在结点就是插入结点，更新结点的值，结束。 若当前结点key大于查找key，把当前结点的左子结点设置为当前结点，重复步骤4； 若当前结点key小于查找key，把当前结点的右子结点设置为当前结点，重复步骤4； 情况1：红黑树为空树直接把插入的节点作为根节点，并把该节点设为黑色。 情况2：插入节点的key已经存在 把I设为当前节点的颜色 更新当前结点的值为插入节点的值 情况3：插入节点的父节点为黑节点这种情况不会影响红黑树平衡，直接插入即可。 情况4：插入节点的父节点为红节点情况4.1：叔叔节点存在且为红节点因为其祖父节点肯定存在，且肯定为黑色，所以此时颜色的情况为：黑红红 那么最简单的处理方法就是改为：红黑红 img 情况4.2：叔叔节点不存在或为黑色节点，且父节点是祖父节点的左子节点 插入节点是其父节点的左子节点 将P设为黑色 将PP设为红色 对PP进行右旋 img 插入节点是其父节点的右子节点 对P进行左旋 把P设置为插入结点，得到情景4.2.1 进行情景4.2.1的处理 img 情况4.3：叔叔节点不存在或为黑色节点，且父节点是祖父节点的右子节点 插入节点是父节点的右子节点 将P设为黑色 将PP设为红色 对PP进行左旋 img 插入节点是父节点的左子节点 对P进行右旋 把P设置为插入结点，得到情景4.3.1 进行情景4.3.1的处理 img 2.4 红黑树删除情况1：替换节点是红色颜色变为删除节点的颜色 情况2：替换节点是黑色情况2.1：替换节点是其父节点的左子节点 替换节点的兄弟节点是红节点 将S设为黑色 将P设为红色 对P进行左旋，得到情景2.1.2.3 进行情景2.1.2.3的处理 img 替换节点的兄弟节点是黑节点 替换节点的兄弟节点的右子节点是红节点，左子节点任意颜色 直接向右子树“借”个红结点来补充黑结点 将S的颜色设为P的颜色 将P设为黑色 将SR设为黑色 对P进行左旋 img 替换节点的兄弟节点的右子节点为黑色，左子节点为红色 向兄弟子树借个红结点过来 将S设为红色 将SL设为黑色 对S进行右旋，得到情景2.1.2.1 进行情景2.1.2.1的处理 img 替换节点的兄弟节点的子节点都为黑色 把兄弟结点设为红色，再把父结点当作替代结点，自底向上处理，去找父结点的兄弟结点去“借” 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 img 情况2.2 替换节点是其父节点的右子节点 替换节点的兄弟节点是红节点 将S设为黑色 将P设为红色 对P进行右旋，得到情景2.2.2.3 进行情景2.2.2.3的处理 img 替换节点的兄弟节点是黑节点 替换节点的兄弟节点的左子节点是红节点，右子节点任意颜色 将S的颜色设为P的颜色 将P设为黑色 将SL设为黑色 对P进行右旋 img 替换节点的兄弟节点的左子节点是黑节点，右子节点是红节点 将S设为红色 将SR设为黑色 对S进行左旋，得到情景2.2.2.1 进行情景2.2.2.1的处理 img 替换节点的兄弟节点的子节点都是黑色 将S设为红色 把P作为新的替换结点 重新进行删除结点情景处理 img 综上，红黑树删除后自平衡的处理可以总结为： 自己能搞定的自消化（情景1） 自己不能搞定的叫兄弟帮忙（除了情景1、情景2.1.2.3和情景2.2.2.3） 兄弟都帮忙不了的，通过父母，找远方亲戚（情景2.1.2.3和情景2.2.2.3） 三、常考手撕直接看这个网站CodeTop企业题库 3.1 无重复字符的最长子串3. 无重复字符的最长子串 - 力扣（Leetcode） 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 123输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。 3.1.1 方法一：HashSet+滑动窗口1234567891011121314151617181920212223class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; if(s.length() &lt;= 1)&#123; return s.length(); &#125; int ans = 0, index = 0; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); for(int i = 0; i &lt; s.length(); i++)&#123; char c = s.charAt(i); if(set.contains(c))&#123; ans = Math.max(ans, set.size()); while(s.charAt(index) != c)&#123; set.remove(s.charAt(index)); index++; &#125; set.remove(s.charAt(index)); index++; &#125; set.add(c); &#125; return Math.max(ans, set.size()); &#125;&#125; 3.1.2 方法二：双指针+滑动窗口+字典123456789101112131415class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int ans = 0, index = 0; int[] dict = new int[128]; for(int i = 0; i &lt; 128; i++)&#123; dict[i] = -1; &#125; for(int i = 0; i &lt; s.length(); i++)&#123; index = Math.max(index, dict[s.charAt(i)] + 1); ans = Math.max(ans, i - index + 1); dict[s.charAt(i)] = i; &#125; return ans; &#125;&#125; 3.2 反转链表206. 反转链表 - 力扣（Leetcode） 给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。 img 12输入：head = [1,2,3,4,5]输出：[5,4,3,2,1] 3.2.1 方法一：迭代法 123456789101112131415class Solution &#123; public ListNode reverseList(ListNode head) &#123; if(head == null)&#123; return null; &#125; ListNode p = head, q = null; while(p != null)&#123; ListNode temp = p.next; p.next = q; q = p; p = temp; &#125; return q; &#125;&#125; 3.2.2 方法二：递归法 1234567891011class Solution &#123; public ListNode reverseList(ListNode head) &#123; if(head == null || head.next == null)&#123; return head; &#125; ListNode newHead = reverseList(head.next); head.next.next = head; head.next = null; return newHead; &#125;&#125; 3.2.3 方法三：头插法（优化迭代）该方法比常规的迭代法内存消耗要低很多，属于优化版的迭代法。 12345678910111213141516class Solution &#123; public ListNode reverseList(ListNode head) &#123; if(head == null || head.next == null)&#123; return head; &#125; ListNode newHead = new ListNode(0); ListNode p = head, q = null; while(p != null)&#123; q = p.next; p.next = newHead.next; newHead.next = p; p = q; &#125; return newHead.next; &#125;&#125; 3.3 LRU缓存146. LRU 缓存 - 力扣（Leetcode） 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。 实现 LRUCache 类： LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 1234567891011121314151617输入[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;][[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]输出[null, null, null, 1, null, -1, null, -1, 3, 4]解释LRUCache lRUCache = new LRUCache(2);lRUCache.put(1, 1); // 缓存是 &#123;1=1&#125;lRUCache.put(2, 2); // 缓存是 &#123;1=1, 2=2&#125;lRUCache.get(1); // 返回 1lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 &#123;1=1, 3=3&#125;lRUCache.get(2); // 返回 -1 (未找到)lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 &#123;4=4, 3=3&#125;lRUCache.get(1); // 返回 -1 (未找到)lRUCache.get(3); // 返回 3lRUCache.get(4); // 返回 4 3.3.1 方法一：LinkedHashMap(不推荐)如果实在不记得怎么写，可以取巧用LinkedHashMap来实现，因为LinkedHashMap的特性就是双向链表+HashMap，但是面试官想考的并不是LinkedHashMap。 12345678910111213141516171819202122232425262728293031323334class LRUCache &#123; private int cap; private Map&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;&gt;(); public LRUCache(int capacity) &#123; this.cap = capacity; &#125; public int get(int key) &#123; if(map.keySet().contains(key))&#123; int value = map.get(key); //保证每次查询，都在最后 map.remove(key, value); map.put(key, value); return value; &#125; return -1; &#125; public void put(int key, int value) &#123; if(map.keySet().contains(key))&#123; map.remove(key, map.get(key)); &#125;else if(map.size() == cap)&#123; // 使用Iterator遍历并删除第一个元素 Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; iterator = map.entrySet().iterator(); if (iterator.hasNext()) &#123; iterator.next(); iterator.remove(); &#125; &#125; map.put(key, value); &#125;&#125; 3.3.2 方法二：双向链表+HashMap(推荐)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091class LRUCache &#123; // 手写双向链表 class DLinkedNode&#123; public int key; public int value; public DLinkedNode pre; public DLinkedNode next; public DLinkedNode()&#123;&#125; public DLinkedNode(int key, int value)&#123; this.key = key; this.value = value; &#125; &#125; //删除节点 public void removeNode(DLinkedNode node)&#123; node.next.pre = node.pre; node.pre.next = node.next; &#125; //将节点添加到最前面 public void addToHead(DLinkedNode node)&#123; head.next.pre = node; node.next = head.next; head.next = node; node.pre = head; &#125; //将指定节点移动到最前面 public void moveToHead(DLinkedNode node)&#123; removeNode(node); addToHead(node); &#125; //删除最后面节点，并返回该节点 public DLinkedNode removeLastNode()&#123; DLinkedNode resNode = tail.pre; removeNode(resNode); return resNode; &#125; public HashMap&lt;Integer, DLinkedNode&gt; map = new HashMap&lt;&gt;(); public int mapCap; public int size;\t//记录链表中节点个数 public DLinkedNode head, tail; public LRUCache(int capacity) &#123; this.size = 0; this.mapCap = capacity; head = new DLinkedNode(); tail = new DLinkedNode(); head.next = tail; tail.pre = head; &#125; public int get(int key) &#123; DLinkedNode node = map.get(key); //如果节点存在，那么就将节点移到最前面，并返回value if(node != null)&#123; moveToHead(node); return node.value; &#125;else&#123; return -1; &#125; &#125; public void put(int key, int value) &#123; DLinkedNode node = map.get(key); //如果节点不存在 if(node == null)&#123; //新建一个节点，添加到最前面，并使得size++ node = new DLinkedNode(key, value); map.put(key, node); addToHead(node); size++; //如果链表中节点个数大于定义的最大容量，就移除链表中最后一个元素 if(size &gt; mapCap)&#123; DLinkedNode lastNode = removeLastNode(); //并在map中也删除这个节点 map.remove(lastNode.key); size--; &#125; &#125;else&#123; //如果节点存在，那么把节点移动到最前面，然后更新节点的value moveToHead(node); node.value = value; &#125; &#125;&#125; 3.4 数组中第k大的元素215. 数组中的第K个最大元素 - 力扣（Leetcode） 给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。 请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。 你必须设计并实现时间复杂度为 O(n) 的算法解决此问题。 12输入: [3,2,1,5,6,4], k = 2输出: 5 3.4.1 方法一：随机快排快排的时间复杂度不符合要求的O(n)，必须得用随机快排。 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; quickSort(nums, 0, nums.length - 1); return nums[nums.length - k]; &#125; public void quickSort(int[] nums, int low, int high)&#123; if(low &lt; high)&#123; int position = partition(nums, low, high); quickSort(nums, low, position - 1); quickSort(nums, position + 1, high); &#125; &#125; public int partition(int[] nums, int low, int high)&#123; int randomIndex = low + (int)Math.random()*(high - low + 1); swap(nums, randomIndex, high); int povit = nums[high]; int index = low; for(int i = low; i &lt; high; i++)&#123; if(nums[i] &lt;= povit)&#123; swap(nums, i, index); index++; &#125; &#125; swap(nums, high, index); return index; &#125; public void swap(int[] nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 3.4.2 方法二：堆排序堆排序其实不符合题中要求的O(n)，但是面试官经常会问一句如果用堆排序该怎么做。可以维护一个只有k个元素的小根堆，堆顶元素就是答案。 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; //维护一个只有k个元素的小根堆 int[] arr = new int[k]; for (int i = 0; i &lt; k; i++) &#123; arr[i] = nums[i]; &#125; buildHeap(arr, k - 1); for (int i = k; i &lt; nums.length; i++) &#123; if (nums[i] &gt; arr[0]) &#123; arr[0] = nums[i]; heapify(arr, k - 1, 0); &#125; &#125; return arr[0]; &#125; private void buildHeap(int[] nums, int n) &#123; for (int i = n / 2; i &gt;= 0; i--) &#123; heapify(nums, n, i); &#125; &#125; private void heapify(int[] nums, int n, int i) &#123; while (true) &#123; int minPos = i; int left = 2 * i + 1; int right = left + 1; if (left &lt;= n &amp;&amp; nums[minPos] &gt; nums[left])&#123; minPos = left; &#125; if (right &lt;= n &amp;&amp; nums[minPos] &gt; nums[right])&#123; minPos = right; &#125; if (minPos == i)&#123; break; &#125; swap(nums, i, minPos); i = minPos; &#125; &#125; private void swap(int[] nums, int i, int j) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 3.4.3 方法三：优先队列其实本质上还是小根堆。 12345678910111213141516class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; //创建一个优先队列 PriorityQueue&lt;Integer&gt; minTree = new PriorityQueue&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++)&#123; //将每一个元素都加入到优先队列中 minTree.add(nums[i]); //维护优先队列中元素为k个，大于k的就弹出 if(minTree.size() &gt; k)&#123; minTree.poll(); &#125; &#125; //最后弹出的那个一定是第k大的元素 return minTree.peek(); &#125;&#125; 3.5 K个一组翻转链表25. K 个一组翻转链表 - 力扣（Leetcode） 给你链表的头节点 head ，每 k 个节点一组进行翻转，请你返回修改后的链表。 k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。 你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。 img 12输入：head = [1,2,3,4,5], k = 2输出：[2,1,4,3,5] 3.5.1 方法一：尾插法先统计链表长度，然后第一重循环看一共要翻转几次，第二重循环控制每次翻转要翻转k-1次。 1234567891011121314151617181920212223242526class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; int listLength = 0; ListNode newHead = new ListNode(0), p = newHead, q = head, temp; newHead.next = head; //统计链表长度 while(head != null)&#123; listLength++; head = head.next; &#125; head = newHead.next; //要翻转listLength/k组 for(int i = 0; i &lt; listLength / k; i++)&#123; //每组内要翻转k - 1次 for(int j = 0; j &lt; k - 1; j++)&#123; temp = q.next; q.next = temp.next; temp.next = p.next; p.next = temp; &#125; p = q; q = p.next; &#125; return newHead.next; &#125;&#125; 3.5.2 方法二：栈因为栈的特性就是先进后出，每次压入k个节点，那么弹出的顺序就是翻转后的顺序。 只不过需要注意，如果最后不足k个节点，就不翻转链表。 12345678910111213141516171819202122232425262728293031class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; Deque&lt;ListNode&gt; stack = new ArrayDeque&lt;&gt;(); ListNode newHead = new ListNode(0); ListNode p = newHead; while(true)&#123; //用count记录stack中节点个数 int count = 0; ListNode q = head; //使得k个一组节点陆续入栈 while(q != null &amp;&amp; count &lt; k)&#123; stack.add(q); q = q.next; count++; &#125; //当节点个数不足k个时，说明stack中的节点就不需要翻转了，直接连接上就可以跳出循环 if(count != k)&#123; p.next = head; break; &#125; //将节点出栈，也即翻转k个节点 while(!stack.isEmpty())&#123; p.next = stack.pollLast(); p = p.next; &#125; p.next = q; head = q; &#125; return newHead.next; &#125;&#125; 3.5.3 方法三：递归法 找到待翻转的k个节点（如果结点数少于k的话就不用翻转）； 对k个节点进行翻转操作，并返回反转后的头结点（反转的区间为左开右闭，所以本轮操作的尾结点就是下一轮操作的头结点）； 对下一轮k个节点同样进行翻转操作； 将上一轮翻转后的尾结点指向下一轮翻转后的头结点。 1234567891011121314151617181920212223242526272829class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; ListNode tail = head; for (int i = 0; i &lt; k; i++) &#123; //剩余数量小于k的话，则不需要反转。 if (tail == null) &#123; return head; &#125; tail = tail.next; &#125; // 反转前 k 个元素 ListNode newHead = reverse(head, tail); //下一轮的开始的地方就是tail head.next = reverseKGroup(tail, k); return newHead; &#125; private ListNode reverse(ListNode head, ListNode tail) &#123; ListNode pre = null; ListNode next = null; while (head != tail) &#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; 3.6 三数之和15. 三数之和 - 力扣（Leetcode） 给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请 你返回所有和为 0 且不重复的三元组。 注意：答案中不可以包含重复的三元组。 12345678输入：nums = [-1,0,1,2,-1,-4]输出：[[-1,-1,2],[-1,0,1]]解释：nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0 。nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0 。nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0 。不同的三元组是 [-1,0,1] 和 [-1,-1,2] 。注意，输出的顺序和三元组的顺序并不重要。 3.6.1 方法一：双指针+内部去重这题想法不难，难的是如何去重。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; ansList = new ArrayList&lt;&gt;(); Arrays.sort(nums); //判断排序后的开始和结尾元素是否符合要求，不符合的话直接退出即可 if(nums[0] &gt; 0 || nums[nums.length - 1] &lt; 0)&#123; return ansList; &#125; for(int i = 0; i &lt; nums.length - 2; i++)&#123; //如果第一个都不符合要求，那后面肯定都不行 if(nums[i] &gt; 0)&#123; return ansList; &#125; //去重，如果前面一个元素和当前元素相同，直接跳过，不然肯定添加的是相通的 if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1])&#123; continue; &#125; int left = i + 1, right = nums.length - 1; while(left &lt; right)&#123; int target = nums[i] + nums[left] + nums[right]; if(target &lt; 0)&#123; left++; &#125;else if(target &gt; 0)&#123; right--; &#125;else&#123; List&lt;Integer&gt; temp = new ArrayList&lt;&gt;(); temp.add(nums[i]); temp.add(nums[left]); temp.add(nums[right]); ansList.add(temp); //去重，同样是找相邻是否有相同的元素，有的话就跳过 while(left &lt; right &amp;&amp; nums[left] == nums[left + 1])&#123; left++; &#125; //去重 while(left &lt; right &amp;&amp; nums[right] == nums[right - 1])&#123; right--; &#125; left++; right--; &#125; &#125; &#125; return ansList; &#125;&#125; 3.6.2 方法二：双指针+HashSet去重思路是一样的，只不过使用HashSet去重，时间复杂度和空间复杂度要差很多，就不写代码了。 3.7 手撕快排912. 排序数组 - 力扣（Leetcode） 给你一个整数数组 nums，请你将该数组升序排列。 优化过的快排：随机选取基准元素+去重 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123; public int[] sortArray(int[] nums) &#123; quickSort(nums, 0, nums.length - 1); return nums; &#125; public void quickSort(int[] nums, int low, int high)&#123; if(low &lt; high)&#123; int position = partition(nums, low, high); int leftPosition = position - 1; int rightPosition = position + 1; //去掉重复的元素 while(leftPosition &gt; low &amp;&amp; nums[position] == nums[leftPosition])&#123; leftPosition--; &#125; while(rightPosition &lt; high &amp;&amp; nums[position] == nums[rightPosition])&#123; rightPosition++; &#125; quickSort(nums, low, leftPosition); quickSort(nums, rightPosition, high); &#125; &#125; public int partition(int[] nums, int low, int high)&#123; //随机选取基准元素 int randomIndex = low + (int)Math.random() * (high - low + 1); swap(nums, randomIndex, high); int pivot = nums[high]; int index = low; for(int i = low; i &lt; high; i++)&#123; if(nums[i] &lt;= pivot)&#123; swap(nums, index, i); index++; &#125; &#125; swap(nums, high, index); return index; &#125; public void swap(int[] nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 3.8 最大子数组和53. 最大子数组和 - 力扣（Leetcode） 给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 子数组 是数组中的一个连续部分。 123输入：nums = [-2,1,-3,4,-1,2,1,-5,4]输出：6解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。 3.8.1 方法一：DP法每次操作有两种可能： 前面所求最大元素max加上当前元素nums[i]； 不带前面玩，只用当前元素nums[i]。 然后每次完毕之后，用ans保存最大的结果。 1234567891011121314class Solution &#123; public int maxSubArray(int[] nums) &#123; if(nums.length == 1)&#123; return nums[0]; &#125; int max = 0; int ans = Integer.MIN_VALUE; for(int i = 0; i &lt; nums.length; i++)&#123; max = Math.max(nums[i] + max, nums[i]); ans = Math.max(max, ans); &#125; return ans; &#125;&#125; 3.8.2 方法二：贪心法相当于把所有结果加起来，如果sum小于0，那说明前面的都不作数，重新将sum置为0。 123456789101112131415161718class Solution&#123; public int maxSubAray(int[] nums)&#123; //类似寻找最大最小值的题目,初始值一定要定义成理论上的最小最大值 int result = Integer.MIN_VALUE; int numsSize = nums.length; int sum = 0; for (int i = 0; i &lt; numsSize; i++)&#123; sum += nums[i]; result = Math.max(result, sum); //如果sum &lt; 0,重新开始找子序串 if (sum &lt; 0)&#123; sum = 0; &#125; &#125; return result; &#125;&#125; 3.8.3 方法三：分治法img 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public int maxSubAray(int[] nums) &#123; if (nums == null || nums.length &lt;= 0)// 输入校验 return 0; int len = nums.length;// 获取输入长度 return getInfo(nums, 0, len - 1).mSum; &#125; class wtevTree &#123; //线段树 int lSum;// 以左区间为端点的最大子段和 int rSum;// 以右区间为端点的最大子段和 int iSum;// 区间所有数的和 int mSum;// 该区间的最大子段和 wtevTree(int l, int r, int i, int m) &#123; // 构造函数 lSum = l; rSum = r; iSum = i; mSum = m; &#125; &#125; // 通过既有的属性,计算上一层的属性,一步步往上返回,获得线段树 wtevTree pushUp(wtevTree leftT, wtevTree rightT) &#123; // 新子段的lSum等于左区间的lSum或者左区间的 区间和 加上右区间的lSum int l = Math.max(leftT.lSum, leftT.iSum + rightT.lSum); // 新子段的rSum等于右区间的rSum或者右区间的 区间和 加上左区间的rSum int r = Math.max(leftT.rSum + rightT.iSum, rightT.rSum); // 新子段的区间和等于左右区间的区间和之和 int i = leftT.iSum + rightT.iSum; // 新子段的最大子段和,其子段有可能穿过左右区间,或左区间,或右区间 int m = Math.max(leftT.rSum + rightT.lSum, Math.max(leftT.mSum, rightT.mSum)); return new wtevTree(l, r, i, m); &#125; // 递归建立和获得输入区间所有子段的结构 wtevTree getInfo(int[] nums, int left, int right) &#123; if (left == right) // 若区间长度为1,其四个子段均为其值 return new wtevTree(nums[left], nums[left], nums[left], nums[left]); int mid = (left + right) &gt;&gt; 1;// 获得中间点mid,右移一位相当于除以2,运算更快 wtevTree leftT = getInfo(nums, left, mid); wtevTree rightT = getInfo(nums, mid + 1, right);//mid+1,左右区间没有交集。 return pushUp(leftT, rightT);//递归结束后,做最后一次合并 &#125;&#125; 3.9 合并两个有序链表21. 合并两个有序链表 - 力扣（Leetcode） 将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 img 12输入：l1 = [1,2,4], l2 = [1,3,4]输出：[1,1,2,3,4,4] 3.9.1 方法一：迭代法没什么说的，创建一个新节点head，然后连接上就行。 12345678910111213141516171819202122class Solution &#123; public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; ListNode head = new ListNode(0); ListNode p = head; while(list1 != null &amp;&amp; list2 != null)&#123; if(list1.val &lt;= list2.val)&#123; p.next = list1; list1 = list1.next; &#125;else&#123; p.next = list2; list2 = list2.next; &#125; p = p.next; &#125; if(list1 == null)&#123; p.next = list2; &#125;else&#123; p.next = list1; &#125; return head.next; &#125;&#125; 3.9.2 方法二：递归法递归连接 12345678910111213141516171819class Solution &#123; public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; //终止条件 if(list1 == null)&#123; return list2; &#125; //终止条件 if(list2 == null)&#123; return list1; &#125; if(list1.val &lt;= list2.val)&#123; list1.next = mergeTwoLists(list1.next, list2); return list1; &#125;else&#123; list2.next = mergeTwoLists(list1, list2.next); return list2; &#125; &#125;&#125; 3.10 两数之和1. 两数之和 - 力扣（Leetcode） 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 你可以按任意顺序返回答案。 进阶：你可以想出一个时间复杂度小于 O($n^2$)的算法吗？ 123输入：nums = [2,7,11,15], target = 9输出：[0,1]解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。 3.10.1 方法一：暴力双循环没什么好说的，暴力双循环，时间复杂度O($n^2$)。 1234567891011121314class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; int[] ans = new int[2]; for(int i = 0; i &lt; nums.length; i++)&#123; for(int j = i + 1; j &lt; nums.length; j++)&#123; if(nums[i] + nums[j] == target)&#123; ans[0] = i; ans[1] = j; &#125; &#125; &#125; return ans; &#125;&#125; 3.10.2 方法二：HashMap因为结果要求返回的是下标，所以不能用排序改变元素位置。 只能通过HashMap来保存值和索引位置，map的key用来保存target - nums[i]的值，这样一来，只需要看后面的元素是否有等于这个差值的。 如果有的话，那就说明找到了这两个值的位置。 1234567891011121314151617class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; int[] ans = new int[2]; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++)&#123; int temp = target - nums[i]; if(!map.containsKey(nums[i]))&#123; map.put(temp, i); &#125;else&#123; ans[0] = i; ans[1] = map.get(nums[i]); break; &#125; &#125; return ans; &#125;&#125; 时间复杂度为O(n)。 四、单例模式4.1 懒汉式单例特点：当需要使用对象的时候才进行实例化，需要考虑线程安全的问题，因此要加锁，用时间换空间。 传统实现： 1234567891011121314class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; private static Singleton LazyMan; // 加锁保证LazyMan只实例化一次，时间换空间 public static synchronized Singleton getInstance()&#123; if (LazyMan == null) &#123; LazyMan = new Singleton(); &#125; return LazyMan; &#125;&#125; 优化实现： 传统实现方式中，每次获取实例都要被synchronized关键字串行化（即使已经生成了实例）。 而我们加锁的目的是为了防止生成多个实例，因此只需对生成实例的代码加锁，生成实例后，可支持并发访问，提高了性能。 1234567891011121314151617181920class Singleton &#123; // 私有构造函数 private Singleton() &#123;&#125; // volatile关键字禁止指令重排，如果不加，可能会出现return为null的情况 private volatile static Singleton LazyMan; public static Singleton getInstance()&#123; // 已有实例则直接返回，不走锁 if (LazyMan == null) &#123; // 仅在没生成实例时加锁控制，使并发访问串行化 synchronized (Singleton.class) &#123; // 多个线程会按序执行到此处，需要再次检查是否已实例化 if (LazyMan == null) &#123; LazyMan = new Singleton(); &#125; &#125; &#125; return LazyMan; &#125;&#125; 由于检查了两次对象是否已实例化，该方法又称“双检锁”，能够同时保证性能及线程安全。 4.2 饿汉式单例特点：类加载时便实例化对象，拿空间换时间。 传统实现： 12345678910class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; // 类加载时就实例化对象 private static Singleton Hungry = new Singleton(); public static Singleton getInstance()&#123; return Hungry; &#125;&#125; 优化实现： 传统实现方式中，由于类加载时就实例化对象，因此当我们调用静态方法时，也会进行实例化，从而导致空间的浪费。 由于静态内部类中的对象不会默认加载，直到调用了该内部类的方法，因此可用静态内部类封装静态实例变量。 123456789101112class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; // 静态内部类 private static class SingletonHolder &#123; private static Singleton Hungry = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.Hungry; &#125;&#125; 五、多线程异步打印ABC5.1 synchronized + wait&#x2F;notify5.1.1 三个线程轮流打印A、B、C，1次1234567891011121314151617181920212223242526272829303132public class Main &#123; private int num; private static Object Lock = new Object(); private void printABC(String name, int targetNum)&#123; synchronized (Lock)&#123; while (num % 3 != targetNum)&#123; try &#123; Lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; num++; System.out.print(name); Lock.notifyAll(); &#125; &#125; public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(&quot;A&quot;, 0); &#125;, &quot;ThreadA&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;B&quot;, 1); &#125;, &quot;ThreadB&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;C&quot;, 2); &#125;, &quot;ThreadC&quot;).start(); &#125;&#125; 基本思路： 让A、B、C三个线程同时启动，因为num的初始值是0，所以线程B、C拿到Lock之后会进入循环； 然后B、C线程调用wait()方法进入等待； A线程不会进入循环，所以可以让num++，并且打印A； 打印完后，执行notifyAll()方法，让其他阻塞的线程苏醒，然后继续循环打印。 5.1.2 三个线程轮流打印A、B、C，10次整体思路与上面一样，只不过在外面加了个循环而已。 12345678910111213141516171819202122232425262728293031323334public class Main &#123; private int num; private static Object Lock = new Object(); private void printABC(String threadName, int targetNum)&#123; for (int i = 0; i &lt; 10; i++) &#123; synchronized (Lock)&#123; while (num % 3 != targetNum)&#123; try &#123; Lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; num++; System.out.print(threadName); Lock.notifyAll(); &#125; &#125; &#125; public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(&quot;A&quot;, 0); &#125;, &quot;ThreadA&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;B&quot;, 1); &#125;, &quot;ThreadB&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;C&quot;, 2); &#125;, &quot;ThreadC&quot;).start(); &#125;&#125; 5.1.3 两个线程轮流打印1-20内的奇偶数123456789101112131415161718192021222324252627282930313233public class Main &#123; private int num = 1; private static Object Lock = new Object(); private void printOddEven()&#123; synchronized (Lock)&#123; while (num &lt;= 20)&#123; //线程Odd先拿到锁 System.out.print(Thread.currentThread().getName() + &quot;:&quot;); System.out.println(num++); try &#123; Lock.notifyAll(); //唤醒Even线程 Lock.wait(); //阻塞Odd线程 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; Lock.notifyAll(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printOddEven(); &#125;, &quot;Odd&quot;).start(); //确保Odd线程比Even线程先拿到锁 Thread.sleep(10); new Thread(() -&gt; &#123; main.printOddEven(); &#125;, &quot;Even&quot;).start(); &#125;&#125; 5.1.4 N个线程轮流打印1-maxNum内的数123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Main &#123; private int num; private static Object Lock = new Object(); private int maxNum = 20; private int N = 4; private void printMaxNum(int targetNum)&#123; while (true)&#123; synchronized (Lock)&#123; while (num % N != targetNum)&#123; if (num &gt;= maxNum)&#123; break; &#125; try &#123; Lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; if (num &gt;= maxNum)&#123; break; &#125; num++; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + num); Lock.notifyAll(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printMaxNum(0); &#125;, &quot;T1&quot;).start(); new Thread(() -&gt; &#123; main.printMaxNum(1); &#125;, &quot;T2&quot;).start(); new Thread(() -&gt; &#123; main.printMaxNum(2); &#125;, &quot;T3&quot;).start(); new Thread(() -&gt; &#123; main.printMaxNum(3); &#125;, &quot;T4&quot;).start(); &#125;&#125; 5.2 join()join()方法可以指定线程执行的顺序，无论谁先执行，最后的顺序都是1-2-3。 还是那道题，三个线程轮流打印ABC十次 123456789101112131415161718192021222324252627282930313233public class Main &#123; static class printABC implements Runnable&#123; private Thread beforeThread; public printABC(Thread beforeThread)&#123; this.beforeThread = beforeThread; &#125; @Override public void run() &#123; //判断前面是否有线程 if (beforeThread != null)&#123; try &#123; beforeThread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10; i++) &#123; Thread T1 = new Thread(new printABC(null), &quot;A&quot;); Thread T2 = new Thread(new printABC(T1), &quot;B&quot;); Thread T3 = new Thread(new printABC(T2), &quot;C&quot;); T1.start(); T2.start(); T3.start(); Thread.sleep(10); //保证三个为一组 &#125; &#125;&#125; 5.3 Lock该方法更容易理解，不管哪个线程拿到锁，只有符合条件的才能打印。 1234567891011121314151617181920212223242526272829public class Main &#123; private static int num; private Lock lock = new ReentrantLock(); private void printABC(int targetNum)&#123; for (int i = 0; i &lt; 10; ) &#123; lock.lock(); if (num % 3 == targetNum)&#123; System.out.print(Thread.currentThread().getName()); num++; i++; &#125; lock.unlock(); &#125; &#125; public static void main(String[] args)&#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(0); &#125;, &quot;A&quot;).start(); new Thread(() -&gt; &#123; main.printABC(1); &#125;, &quot;B&quot;).start(); new Thread(() -&gt; &#123; main.printABC(2); &#125;, &quot;C&quot;).start(); &#125;&#125; 六、AMC模式输入代码6.1 数组建链表 第一行输入n，表示链表中的元素个数； 第二行输入n个元素，表示链表中节点的值； 123456789101112131415161718192021222324252627282930313233343536class ListNode&#123; int value; ListNode next; public ListNode()&#123;&#125;; public ListNode(int value)&#123; this.value = value; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] nums = new int[n]; for (int i = 0; i &lt; n; i++) &#123; nums[i] = sc.nextInt(); &#125; ListNode head = buildList(nums); //打印链表 while (head != null)&#123; System.out.print(head.value); head = head.next; &#125; &#125; //根据数组建立链表 public static ListNode buildList(int[] arr)&#123; ListNode head = new ListNode(-1); ListNode p = head; for (int i = 0; i &lt; arr.length; i++) &#123; ListNode q = new ListNode(arr[i]); p.next = q; p = p.next; &#125; return head.next; &#125;&#125; 6.2 数组建二叉树 第一行输入n，二叉树中一共有多少个节点； 第二行输入n个元素，表示层序遍历二叉树的结果，-1表示节点为空； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class TreeNode&#123; int value; TreeNode left; TreeNode right; public TreeNode(int value)&#123; this.value = value; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] nums = new int[n]; for (int i = 0; i &lt; n; i++) &#123; nums[i] = sc.nextInt(); &#125; TreeNode root = buildTree(nums); &#125; //输入数组建立二叉树 public static TreeNode buildTree(int[] arr)&#123; if (arr == null || arr.length == 0)&#123; return null; &#125; TreeNode root = new TreeNode(arr[0]); //借助队列来实现 Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); //从数组中两个两个一读，代表该节点的左右节点 for (int i = 1; i &lt; arr.length; i += 2) &#123; //从队列中出队，拼接该节点的左右子节点 TreeNode node = queue.poll(); //连上该节点的左子节点 if (arr[i] != -1)&#123; node.left = new TreeNode(arr[i]); //将新加的节点入队 queue.offer(node.left); &#125; //连上该节点的右子节点，这里一定要先保证i + 1不会越界 if (i + 1 &lt; arr.length &amp;&amp; arr[i + 1] != -1)&#123; node.right = new TreeNode(arr[i + 1]); queue.offer(node.right); &#125; &#125; return root; &#125;&#125; 6.3 输入边建二叉树 第一行输入一个正整数n，代表节点的数量； 接下来的n - 1行，每行输入两个正整数a，b，代表节点a和节点b有一条边连接; 1234567891011121314151617181920212223242526272829303132class TreeNode&#123; int val; TreeNode left; TreeNode right; public TreeNode(int val)&#123; this.val = val; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); // 创建一个数组来保存每个节点的引用 TreeNode[] nodes = new TreeNode[n + 1]; for (int i = 1; i &lt;= n; i++) &#123; nodes[i] = new TreeNode(i); &#125; for (int i = 0; i &lt; n - 1; i++) &#123; int u = scanner.nextInt(); int v = scanner.nextInt(); // 根据输入的边关系连接节点 if (nodes[u].left == null) &#123; nodes[u].left = nodes[v]; &#125; else &#123; nodes[u].right = nodes[v]; &#125; &#125; // 假设根节点是节点1 TreeNode root = nodes[1]; &#125;&#125; 6.4 输入边建二叉树（以链表形式存储）这种方式存的是边，并没有真的建立二叉树。 第一行输入一个正整数n，代表节点的数量； 接下来的n - 1行，每行输入两个正整数a，b，代表节点a和节点b有一条边连接; 123456789101112131415161718192021222324252627import java.util.*;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); List&lt;List&lt;Integer&gt;&gt; edge = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;= n; i++) &#123; edge.add(new ArrayList&lt;&gt;()); &#125; for (int i = 0; i &lt; n - 1; i++) &#123; int a = sc.nextInt(); int b = sc.nextInt(); edge.get(a).add(b); edge.get(b).add(a); &#125; for (int i = 0; i &lt; edge.size(); i++) &#123; for (int j = 0; j &lt; edge.get(i).size(); j++) &#123; System.out.print(edge.get(i).get(j) + &quot; &quot;); &#125; System.out.println(); &#125; &#125;&#125;","tags":["Java","八股","基础","面试","代码"],"categories":["Java八股","扩展内容"]},{"title":"10.中间技术","path":"/2023/07/10/10-中间技术/","content":"一、MyBatisMyBatis内部封装了JDBC，开发时程序员只需要关注SQL语句本身，而不需要花费时间精力去处理加载驱动、创建链接、创建Statement等繁琐的过程。 优点： 基于SQL语句编程，相当灵活，SQL语句卸载XML中，解除了SQL与程序代码的耦合，方便统一管理，支持动态SQL； 与JDBC相比，减少了代码量，消除了大量冗余代码； 能很好地与各种数据库相兼容，只要JDBC支持的数据库MyBatis都支持； 提供映射标签，支持对象与数据库的字段关系映射。 缺点： SQL语句的编写工作量大，尤其是当字段多、关联表多时； SQL语句依赖与数据库，导致不可以随意更换数据库。 1.1 #{}和${}区别是什么？ #&#123;&#125;是占位符，预编译时会处理；$&#123;&#125;是拼接符，字符串替换，没有预编译处理。 MyBatis在处理#&#123;&#125;时，会将sql中的#&#123;&#125;替换为？号；MyBatis在处理$&#123;&#125;时，是把$&#123;&#125;替换成变量的值。 #&#123;&#125;可以有效防止SQL注入，提高系统安全性；$&#123;&#125;不能防止SQL注入。 1.1.1 为什么#{}能有效防止SQL注入？因为#{}在SQL执行前，会将SQL语句发送给数据库进行编译，在执行的时候，直接使用编译好的SQL语句，替换占位符。因为SQL注入只能对编译过程起作用，所以#{}能很好的避免SQL注入问题。 1.2 xml映射文件中有哪些常见的标签？select、insert、update、delete、resultMap、parameterMap、sql、include、selectKey，再加上动态sql的9个标签。 1.3 Dao接口的工作原理是什么？Dao接口的工作原理是JDK动态代理，MyBatis运行的时候会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。 最佳实践中，通常一个xml映射文件都会写一个Dao接口与之对应。 Dao接口就是我们常说的Mapper接口， 接口的全限名，就是映射文件中的namespace的值； 接口的方法名，就是映射文件中MappedStatement的id值； 接口方法内的参数，就是传递给sql的参数。 Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement。 比如：com.mabatis3.mappers.StudentDao.findStudentById，可以唯一找到一个namespace为com.mabatis3.mappers.StudentDao下面id=findStudentById的MappedStatement。在MyBatis中，每个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签都会被解析为一个MappedStatement对象。 1.3.1 Dao接口里的方法在参数不同时可以重载吗？Dao接口里的方法可以重载，但是MyBatis的xml里面的ID不允许重复。 123456789/** * Mapper接口里面方法重载 */public interface StuMapper &#123; List&lt;Student&gt; getAllStu(); List&lt;Student&gt; getAllStu(@Param(&quot;id&quot;) Integer id);&#125; 然后在StuMapper.xml中利用MyBatis的动态sql就可以实现。 12345678&lt;select id=&quot;getAllStu&quot; resultType=&quot;com.pojo.Student&quot;&gt; select * from student &lt;where&gt; &lt;if test=&quot;id != null&quot;&gt; id = #&#123;id&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 能够正常运行，并得到相应的结果。 MyBatis的Dao接口可以有多个重载方法，但是多个接口对应的映射必须只有一个，否则启动会报错。 1.4 MyBatis是如何进行分页的？分页插件的原理是什么？ 使用MyBatis提供的RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页； 可以在sql内直接书写带有物理分页的参数来完成物理分页的功能，如offset和limit； 通过MyBatis中的Interceptor拦截器在select语句执行之前动态拼接分页关键字实现分页。 分页插件的基本原理是使用MyBatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，添加对应的物理分页语句和物理分页参数。 1.5 说一说MyBatis的执行流程MyBatis执行流程 读取MyBatis配置文件：mybatis-config.xml加载运行环境和映射文件； 构造SqlSessionFactory，一个项目只需要一个，单例的，一般由Spring管理； 工厂创建sqlSession对象，这里面就包含了执行SQL语句的所有方法； 操作数据库的接口，Executor执行器，同时负责查询缓存的维护； Executor接口的执行方法中有个MappedStatement类型的参数，封装了映射信息； 输入参数的映射； 输出结果的映射； 1.6 Mybatis的延迟加载了解吗？MyBatis支持延迟加载，即需要用到数据时才进行加载，不用的时候就不加载数据。 延迟加载默认是关闭的，如果需要使用，可以在配置文件中开启lazyLoadingEnabled=true|false。 1.6.1 延迟加载的底层原理 使用CGlib创建目标对象的代理对象，这里的目标对象就是开启了延迟加载的mapper； 当调用目标方法时，进入拦截器invoke方法，发现目标方法是null值，执行sql查询； 获取数据后，调用set方法设置属性值，再继续查询目标方法，就可以查到值。 1.7 MyBatis的一级、二级缓存用过吗？ 一级缓存：是基于PerpetualCache的HashMap本地缓存，其作用域是sqlSession，当进行flush或close后，该session中的所有缓存都清空，默认打开一级缓存； 二级缓存：是基于PerpetualCache的HashMap本地缓存，其作用域是namespace和mapper，可以跨sqlSession，需要单独开启缓存； 注：当某一个作用域进行了增、删、改操作后，默认该作用域下的所有缓存都将被清理。 1.7.1 为什么二级缓存默认不开启？因为二级缓存是跨sqlSession的，会存在严重的脏读问题，所以默认关闭二级缓存。 二、RabbitMQ2.1 RabbitMQ如何保证消息不丢失？ 开启生产者确认机制，确保生产者的消息能到达队列，如果报错可以先记录到日志中，再去修复数据。 开启持久化功能，确保消息未消费前，在队列中不会丢失，其中的交换机、队列和消息都要做持久化。 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack，也要设置一定的重试次数（一般是3次），如果重试之后仍然没有收到消息，就将失败后的消息投递到异常交换机。 2.2 RabbitMQ消息的重复消费问题如何解决？（如何保证消息的幂等性？） 每条消息设置一个唯一的标识id，通过id可以保证消息不会被重复消费； 通过幂等方案解决，比如分布式锁或者数据库锁。 2.3 RabbitMQ中死信交换机了解吗？（RabbitMQ的延迟队列了解吗？） 医院挂号管理系统中的订单模块就用到了延迟队列去解决超时订单的问题； 其中延迟队列其实就是基于死信交换机和TTL（消息存活时间）来实现的； 如果消息超时未消费就会变成死信，队列可以绑定一个死信交换机，在发送消息时可以按照要求指定TTL，这样超时未消费的死信就会通过死信交换机进入死信队列中，实现了延迟队列的功能。 2.4 如果有100w条消息堆积在MQ中，如何解决？（如何解决消息堆积的问题？） 增加更多的消费者，提高消费的速度； 在消费者内开启线程池，加快消息处理速度； 扩大队列容积，提高消息堆积的上限； 也可以使用惰性队列来解决， 接收到消息后存放在磁盘中，而不是内存； 消费者需要消费时，才会从磁盘中读取并加载到内存； 支持数百万条消息的存储； 2.5 RabbitMQ的高可用机制有了解过吗？可以通过镜像队列来实现高可用，其结构式一主多从，所有的操作都是主节点完成，然后同步给镜像节点。 如果主节点宕机后，镜像节点就会替代成为新的主节点。如果在主从同步完成之前主节点就已经宕机，可能会出现数据丢失问题。 2.5.1 出现数据丢失问题怎么解决的？可以使用仲裁队列，其与镜像队列一样，都是主从模式，支持主从数据同步，是强一致性。而且使用起来非常简单，不需要额外的配置。 2.6 消息队列的模型了解吗？消息队列一共有两种模型：队列模型和发布&#x2F;订阅模型。 队列模型：就是最经典的“发送-存放-接收”模型。生产者往队列里发消息，一个队列可以存储多个生产者的消息，一个队列也可以有多个消费者，但是消费者与消费者之间是竞争关系，一个消息只能被一个消费者消费。 队列模型 发布&#x2F;订阅模型：消息的发送方被称为发布者，接收方被称为订阅者，存放消息的容器叫主题。发布者将消息发到主题里，订阅者在接受消息之前需要先订阅主题，只有订阅了的订阅者，才能接收到所有消息。 发布/订阅模型 这两种模型的区别是什么？ 其实本质上没有什么区别，唯一不同的是：一份消息数据是否可以被多次消费。 2.7 Kafka和RabbitMQ有什么区别呢？ RabbitMQ用于实时的场景，对可靠性要求比较高的消息传递，而Kafka用于大数据量的处理； RabbitMQ有消息确认机制，而Kafka没有消息确认机制； RabbitMQ不支持批量操作，吞吐量较小，Kafka内部采用消息的批量处理，消息处理效率高，吞吐量高； 三、设计模式3.1 工厂模式在Java中创建对象时，需要用户自己去new对象，这种创建方式会使得该对象耦合严重，加入我们需要更换对象，那么多有new对象的地方都需要修改。 所以可以使用工厂模式来生产对象，而我们直接与工厂交互，彻底和对象解耦，如果需要更换对象，直接在工厂中更换对象即可，从而实现了与对象解耦的目的。 所以说工厂模式最大的优点就是：解耦。 工厂模式包含三种工厂： 简单工厂模式 工厂方法模式 抽象工厂模式 3.1.1 简单工厂模式简单工厂模式不是一种设计模式，更像是一种编程习惯。 其中包含三种角色： 抽象产品 ：定义了产品的规范，描述了产品的主要特性和功能； 具体产品 ：实现或者继承抽象产品的子类； 具体工厂 ：提供了创建产品的方法，调用者通过该方法来获取产品。 一旦有了工厂类，就可以在orderCoffee()中直接创建工厂对象，然后调用工厂对象的creatCoffee()方法并且传入参数就能获取对应的coffee了。 这种简单工厂模式虽然解除了Coffee和CoffeeStore之间的耦合，但是CoffeeStore对象和SimpleCoffeeFactory工厂对象之间又新产生了耦合。 后期如果要增加新的咖啡，仍然需要在工厂里面修改代码。 优点： 封装了创建对象的过程，可以通过参数直接获取对象； 将对象的创建和业务逻辑分开，可以避免修改客户代码； 缺点： 新增产品时，仍然需要在工厂类中修改代码，违背了“开闭原则”； 3.1.2 工厂方法模式定义一个用于创建对象的接口，让子类决定实例化哪个产品类对象； 其中包含四种角色： 抽象工厂：提供了创建产品的接口，调用者通过它访问抽象工厂的工厂方法来创建产品； 具体工厂：主要是实现抽象工厂中的抽象方法，完成具体产品的创建； 抽象产品：描述产品的主要特性和功能； 具体产品：实现了抽象产品所定义的接口，由具体工厂来创建。 虽然增加产品类时也要增加相应的工厂类，但是不需要修改工厂类的代码了，这样就解决了简单工厂模式的缺点。 工厂方法模式其实就是简单工厂模式的进一步抽象。由于使用了Java中多态的特性，工厂方法模式保持了简单工厂模式的优点，同时解决了它的缺点。 优点： 用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程； 在系统增加新的产品时只需要添加具体产品类和对应的具体工厂类，无须对 原工厂进行任何修改，满足开闭原则； 缺点： 每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加 了系统的复杂度。 3.1.3 抽象工厂模式抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。 一个超级工厂创建其他工厂，该超级工厂又称为其他工厂的工厂 抽象工厂模式与工厂方法模式一样，主要有四种角色：抽象工厂、具体工厂、抽象产品、具体产品。 加入现在咖啡店要求不仅仅只能点咖啡，还要求能点甜品。如果按照工厂方法模式，需要定义提拉米苏类、抹茶慕斯类、提拉米苏工厂、抹茶慕斯工厂、甜品工厂类，如果再增加其他功能，势必会导致添加的类更多，会发生类爆炸的问题。 所以这里就可以使用抽象工厂模式： 抽象工厂模式 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同 一个产品族中的对象。 缺点：当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。 使用场景： 当需要创建的对象是一系列相互关联或相互依赖的产品族时，比如电器工厂中的电视、洗衣机、冰箱、空调等； 系统中有多个产品族，但每次只使用其中的某一族产品，比如有人虽然有很多牌子的衣柜，但只喜欢穿某一个品牌的衣服和鞋； 系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。 3.1.4 简单工厂和抽象工厂的区别抽象工厂相当于抽象了两层，一层抽象层，一层是实现抽象层的具体层，这样后期的扩展和维护会很方便； 简单工厂直接抽取成了一层具体层，完全没有考虑后期的扩展和维护。 3.1.5 工厂方法和抽象工厂的区别两者最终都是创建对象，但是方法有所不同。 工厂方法采用的是继承，抽象工厂采用的是组合。 抽象工厂中蕴含着许多的工厂方法，所以抽象工厂的相比于工厂方法的另一个优点就是可以把一群相关的产品集合起来（之前提到的各种咖啡，各种甜品等），但是同时也带来了反作用，如果新增一个产品，那么接口将被修改，那是很严重的。所以抽象工厂需要一个很大的接口，因为抽象工厂是创建整个产品家族的，而工厂方法是创建单个产品的，所以说抽象工厂中蕴含着工厂方法。 3.2 策略模式该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。 策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。 比如我们去旅游选择出行模式有很多，可以骑自行车、可以坐汽车、可以坐火车、可以坐飞机等等，最终的目的就是出行，交通工具就相当于是不同的算法，使用哪个算法都可以实现出行的目的。 策略模式主要的角色： 抽象策略类：是一个抽象的角色，通常由一个接口或抽象类实现。此角色所给出所有的具体策略类所需的接口； 具体策略类：实现了抽象策略定义的接口，提供具体的算法实现或行为； 环境类：持有一个策略类的引用，最终给客户端调用。 最经典的例子就是登录问题，对于一个成熟的网站来说，登录方式是有多种的：账号密码登录、QQ登录、微信登录、短信验证码登录等。 所以这里就可以使用策略模式，因为对于用户来说最终的目的是登录网站，至于具体选择哪种登录方式，是用户自身决定的。 抽象策略类：UserGranter 具体的策略类：AccountGranter、SmsGranter、WeChatGranter 12345678910111213141516171819202122232425262728293031323334353637383940/*** 策略：账号登录**/@Componentpublic class AccountGranter implements UserGranter&#123;\t@Override\tpublic LoginResp login(LoginReq loginReq) &#123; System.out.println(&quot;登录方式为账号登录&quot; + loginReq); // TODO // 执行业务操作 return new LoginResp();\t&#125;&#125;/*** 策略:短信登录*/@Componentpublic class SmsGranter implements UserGranter&#123;\t@Override\tpublic LoginResp login(LoginReq loginReq) &#123; System.out.println(&quot;登录方式为短信登录&quot; + loginReq); // TODO // 执行业务操作 return new LoginResp();\t&#125;&#125;/*** 策略:微信登录*/@Componentpublic class WeChatGranter implements UserGranter&#123;\t@Override\tpublic LoginResp login(LoginReq loginReq) &#123; System.out.println(&quot;登录方式为微信登录&quot; + loginReq); // TODO // 执行业务操作 return new LoginResp();\t&#125;&#125; 环境类根据用户前端传来的登录类型，选择具体的登录策略。 其实实际开发中场景有很多： 支付策略： 支付宝支付 微信支付 银行卡支付 促销活动 满300打9折 满500打8折 满1000打7折 物流运费 5kg以下 5kg - 10kg 10kg - 20kg 20kg以上 一句话总结：只要代码中有冗长的if...else或switch分支判断的代码，都可以采用策略模式进行优化。 3.3 责任链模式为了避免请求发送者与多个请求处理器耦合在一起，将所有请求的处理者通过前一对象记录其下一个对象的引用，而形成一条链； 当有请求发生时，可将请求沿着这条链传递，知道有对象处理它为止。 比如生活中在学校里我们需要请假，但是批假的人有导师、辅导员、副院长、书记等。不同的领导能批的天数不同，我们必须要根据自己的请假天数去找不同的领导签字。 责任链模式主要包含以下角色： 抽象处理者（Handler）：定义一个处理请求的接口，包含抽象处理方法和一个后继连接； 具体处理者：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则就将该请求转给它的后继； 客户类：创建处理链，并向链头的具体处理者对象提交请求，它并不关心处理的细节和请求的传递过程。 代码实现： 抽象处理者： 12345678910111213141516/*** 抽象处理者*/public abstract class Handler &#123;\tprotected Handler handler; public void setNext(Handler handler) &#123; this.handler = handler;\t&#125; /** * 处理过程 * 需要子类进行实现 */ public abstract void process(OrderInfo order); &#125; 具体处理者： 12345678910111213141516171819202122232425262728293031323334353637383940/*** 订单校验*/public class OrderValidition extends Handler &#123; @Override public void process(OrderInfo order) &#123; System.out.println(&quot;校验订单基本信息&quot;); //校验 handler.process(order); &#125;&#125;/*** 补充订单信息*/public class OrderFill extends Handler &#123; @Override public void process(OrderInfo order) &#123; System.out.println(&quot;补充订单信息&quot;); handler.process(order); &#125;&#125;/*** 计算金额*/public class OrderAmountCalcuate extends Handler&#123; @Override public void process(OrderInfo order) &#123; System.out.println(&quot;计算金额-优惠券、VIP、活动打折&quot;); handler.process(order); &#125;&#125;/*** 订单入库*/public class OrderCreate extends Handler &#123; @Override public void process(OrderInfo order) &#123; System.out.println(&quot;订单入库&quot;); &#125;&#125; 客户类： 123456789101112131415161718public class Application &#123; public static void main(String[] args) &#123; //检验订单 Handler orderValidition = new OrderValidition(); //补充订单信息 Handler orderFill = new OrderFill(); //订单算价 Handler orderAmountCalcuate = new OrderAmountCalcuate(); //订单落库 Handler orderCreate = new OrderCreate(); //设置责任链路 orderValidition.setNext(orderFill); orderFill.setNext(orderAmountCalcuate); orderAmountCalcuate.setNext(orderCreate); //开始执行 orderValidition.process(new OrderInfo()); &#125;&#125; 优点： 降低了对象之间的耦合，降低了发送者和接收者的耦合度； 增强了可扩展性，可以根据需要增加新的请求处理类，满足开闭原则； 增强了给对象指派职责的灵活性，当工作流程发生变化时，可以动态改变流程顺序； 每个类只需要处理自己该处理的工作，不能处理的传给下一个对象，明确了格雷的责任范围； 缺点： 对于比较长的责任链，请求的处理可能涉及多个处理对象，性能会受到一定影响； 不能保证每一个请求一定被处理，由于一个请求没有明确的接受者，所以不能保证它一定会被处理； 责任链建立的合理性要考客户端来保证，增加了客户端的复杂性； 其实责任链模式实际的开发应用有很多： 内容审核； 订单创建； 简易流程审批； 3.2 单例模式这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 单例模式是一种创建型设计模式，它确保一个类只有一个实例，并提供了一个全局访问点来访问该实例。 注意： 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 应用实例： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I&#x2F;O 与数据库的连接等。 优点： 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 避免对资源的多重占用（比如写文件操作）。 缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 3.2.1 懒汉式单例特点：当需要使用对象的时候才进行实例化，需要考虑线程安全的问题，因此要加锁，用时间换空间。 是线程不安全的，不支持多线程。 传统实现： 1234567891011121314class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; private static Singleton LazyMan; // 加锁保证LazyMan只实例化一次，时间换空间 public static synchronized Singleton getInstance()&#123; if (LazyMan == null) &#123; LazyMan = new Singleton(); &#125; return LazyMan; &#125;&#125; 优化实现： 传统实现方式中，每次获取实例都要被synchronized关键字串行化（即使已经生成了实例）。 而我们加锁的目的是为了防止生成多个实例，因此只需对生成实例的代码加锁，生成实例后，可支持并发访问，提高了性能。 1234567891011121314151617181920class Singleton &#123; // 私有构造函数 private Singleton() &#123;&#125; // volatile关键字禁止指令重排，如果不加，可能会出现return为null的情况 private volatile static Singleton LazyMan; public static Singleton getInstance()&#123; // 已有实例则直接返回，不走锁 if (LazyMan == null) &#123; // 仅在没生成实例时加锁控制，使并发访问串行化 synchronized (Singleton.class) &#123; // 多个线程会按序执行到此处，需要再次检查是否已实例化 if (LazyMan == null) &#123; LazyMan = new Singleton(); &#125; &#125; &#125; return LazyMan; &#125;&#125; 由于检查了两次对象是否已实例化，该方法又称“双检锁”，能够同时保证性能及线程安全。 3.2.2 饿汉式单例特点：类加载时便实例化对象，拿空间换时间。 是线程安全的，但是容易产生垃圾对象。 传统实现： 12345678910class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; // 类加载时就实例化对象 private static Singleton Hungry = new Singleton(); public static Singleton getInstance()&#123; return Hungry; &#125;&#125; 优化实现： 传统实现方式中，由于类加载时就实例化对象，因此当我们调用静态方法时，也会进行实例化，从而导致空间的浪费。 由于静态内部类中的对象不会默认加载，直到调用了该内部类的方法，因此可用静态内部类封装静态实例变量。 123456789101112class Singleton&#123; // 私有构造函数 private Singleton() &#123;&#125; // 静态内部类 private static class SingletonHolder &#123; private static Singleton Hungry = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.Hungry; &#125;&#125; 3.2.3 反射可以破坏单例模式吗？为什么？反射可以破坏单例模式。虽然单例模式的构造器是私有的，单例类外部是不能随便调用的，但是通过反射还是可以获得构造器的访问权。 3.2.4 如何防止反射破坏单例模式？ 在构造器中做判断，如果对象已经被创建，那么再次创建则不允许创建。但是这种方式有个缺点，如果在常规调用之前就已经使用反射创建，还是不能防止反射破坏单例模式。 用枚举单例模式，无法被反射破坏。因为枚举类没有构造器，而且反射的newInstance()方法会判断是否被枚举修饰，如果被修饰，则会创建失败。","tags":["Java","八股","基础","面试","MyBatis","RabbitMQ","设计模式"],"categories":["Java八股","基础"]},{"title":"9.操作系统","path":"/2023/07/06/9-操作系统/","content":"一、操作系统基础1.1 什么是操作系统？ 操作系统是管理计算机硬件与软件资源的软件程序，是计算机的基石。 操作系统的内核（Kernel）是操作系统的核心部分，负责系统的内存管理、硬件设备管理、文件系统管理和应用程序管理。内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。 1.2 操作系统的内核和CPU有什么区别？ 操作系统的内核属于操作系统层面，而CPU属于硬件。 CPU主要提供运算，处理各种指令的能力。内核主要负责系统的管理。 下图是程序、内核、CPU三者的关系： Kernel_Layout 1.3 操作系统主要有哪些功能？ 进程和线程的管理，进程的创建、撤销、阻塞、唤醒，进程间的通信等。； 存储管理，内存的分配和管理、外存（磁盘等）的分配和管理等； 文件管理，文件的读、写、创建及删除等； 设备管理，完成设备（输入输出设备和外部存储设备等）的请求或释放，以及设备启动等功能； 网络管理，操作系统负责管理计算机网络的使用。； 安全管理，用户的身份认证、访问控制、文件加密等，以防止非法用户对系统资源的访问和操作； 1.4 什么是用户态和内核态？根据进程访问资源的特点，可以把进程在系统上的运行分为用户态和内核态： 用户态：用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。 内核态：内核态运行的进程几乎可以访问计算机的任何资源，包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。 用户态和内核态 总结：内核态相比用户态拥有更高的特权级别，因此能够执行更底层、更敏感的操作。不过，由于进入内核态需要付出较高的开销，应该尽量减少进入内核态的次数，以提高系统的性能和稳定性。 1.5 为什么要有用户态和内核态？只有一个内核态不行吗？ 在 CPU 的所有指令中，有一些指令是比较危险的比如内存分配、设置时钟、IO 处理等，如果所有的程序都能使用这些指令的话，会对系统的正常运行造成灾难性地影响。因此，我们需要限制这些危险指令只能内核态运行。这些只能由操作系统内核态执行的指令也被叫做 特权指令 。 如果计算机系统中只有一个内核态，那么所有程序或进程都必须共享系统资源，例如内存、CPU、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都具有相同的特权级别和访问权限。 1.6 用户态和内核态是如何切换的？用户态切换到内核态的 3 种方式 系统调用：用户态进程主动要求切换到内核态； 中断：当设备完成用户请求的操作后，会向CPU发出相应的中断信号。 异常：当CPU在执行运行在用户态的程序时，发生了某些事先不可知的异常，就会触发切换。 住：中断和异常类似，都是通过中断向量表来找到相应的处理程序进行处理。区别在于，中断来自处理器内部，异常是执行当前指令的结果。 1.7 系统调用的过程了解吗？ 用户态的程序发起系统调用，因为系统调用中涉及一些特权指令，用户态程序权限不足，就会中断执行。 发生中断后，当前CPU执行的程序就会中断，调转到中断处理程序。内核程序开始执行，也即开始处理系统调用。 内核处理完成后，主动触发Trap，再次发生中断，切换回用户态工作。 系统调用的过程 1.8 系统调用和库函数调用的区别？ 系统调用通常不可替换，而库函数通常可替换。 系统调用通常提供最小接口，而库函数通常提供较复杂功能。 系统调用运行在内核空间，而库函数运行在用户空间。 内核调用都返回一个整数值，而库函数并非一定如此。 系统调用开销相对库函数来说更大。 二、进程和线程2.1 什么是进程、线程和协程？ 进程：指计算机中正在运行的程序实例。比如，打开浏览器，就是一个进程。 线程：也被称为轻量级进程。多个线程可以在同一个进程中同时执行，并且共享进程的资源。比如内存空间、网络连接等。 协程：也被称为微线程，是一种用户态的轻量级线程，一个线程可以拥有多个协程，协程完全由程序所控制，能提升性能，不会像线程切换那样消耗资源。 2.2 进程和线程的区别是什么？从JVM的角度来说一说两者区别， 一个进程可以有多个线程，多个线程共享进程的堆和元空间的资源，但是每个线程有自己的程序计数器、虚拟机栈和本地方法栈。 线程是进程划分成的最小的运行单位，一个进程在其执行的过程中可以产生多个线程。 线程和进程最大的不同在于，各个进程是独立的，而各个线程则不一定，因为同一个进程中的线程极有可能会互相影响。 线程执行开销小，不利于资源的管理和保护；而进程则相反。 2.3 为什么要使用多线程？ 线程可以比作轻量化的进程，是执行程序的最小单位，线程间的切换和调度的成本远远小于进程。 现在的系统要求百万级甚至千万级并发量，而多线程并发编程正式开发高并发系统的基础，使用多线程能够大大提高系统整体的并发能力和性能。 2.4 线程间同步的方式有哪些？ 互斥锁：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 读写锁：允许多个线程读取共享资源，但是只有一个线程可以对共享资源进行写操作。 信号量：允许同一时刻多个线程访问同一资源，但是控制同一时刻可访问的最大线程数量。 屏障：用于等待多个线程到达某个点再一起继续执行。 事件：通过通知操作的方式保持多线程同步。 2.5 什么是PCB？PCB（Process Control Block） 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB。你可以将 PCB 视为进程的大脑。 PCB包括以下信息： 进程的描述信息； 进程的调度信息； 进程对资源的需求情况； 进程打开的文件信息； 2.6 进程有哪几种状态？进程状态图转换图 创建：进程正在被创建，尚未达到就绪状态。 就绪：进程处于准备运行状态，此时进程获得了除处理器之外的一切资源，一旦得到CPU分配的时间片即可运行。 运行：进程正在处理器上运行。 阻塞：又称等待，进程正在等待某一事件而暂停运行，比如等待某资源或等待IO操作完成。哪怕此时CPU空闲，该线程也不能运行。 结束：进程正在从系统中消失，退出运行。 2.7 进程间通信方式有哪些？ 管道&#x2F;匿名管道：仅用于具有亲缘关系的父子进程间、或兄弟进程间通信。 有名管道：遵循先进先出，以磁盘文件的方式存在，可以实现本机中任意两个进程通信。 信号：用于通知接收进程某个事件已经发生。 消息队列：是消息的链表，存放在内核中，可以实现消息的随机查询。克服了信号承载信息量少、管道只能承载无格式字节流以及缓冲区受限的缺点。 信号量：相当于一个计数器，用于多进程对共享数据的访问，主要用于进程间同步。 共享内存：使得多个进程可以访问同一块内存空间，不同进程之间可以及时看到其他进程对共享内存中数据的更新。 套接字：主要用于客户端和服务器之间通过网络进行通信。 2.7.1 管道有了解过吗？说一说管道主要用于实现两个或多个进程间的数据传输。可以将一个进程的输出连接到另一个进程的输入，从而实现数据的流动和共享。 管道主要分为两种类型：匿名管道和有名管道。 2.7.2 那分别说说匿名管道和有名管道 匿名管道：匿名管道是一种最简单的管道形式，只能用于父进程与其直接创建的子进程之间的通信。匿名管道是单向的，数据只能在一个方向上流动。它通过操作系统提供的缓冲区将数据从一个进程传递给另一个进程。 命名管道：命名管道是一种更通用的管道形式，可以用于不相关的进程之间的通信。命名管道是有名字的，可以被多个进程打开和使用。命名管道可以在不同的进程之间实现双向数据传输。 2.8 进程的调度算法有哪些？常见进程调度算法 先来先服务：从就绪队列中选择一个最先进入队列的进程分配资源。 短作业优先：从就绪队列中选择运行时间最短的进程分配资源。 时间片轮转：是一种最古老、最简单、最公平、使用最广的算法。每个进程被分配一个时间片。 优先级调度：给每个进程分配优先级，按优先级顺序执行进程。 多级反馈队列：既能使高优先级的作业得到响应，又能使短作业迅速完成，是一种公认的较好的进程调度算法。 2.9 什么是僵尸进程和孤儿进程？ 僵尸进程：子进程已经终止，但是父进程仍在运行，且父进程没有调用wait()系统调用来获取子进程的状态信息，释放子进程占用的资源，导致子进程的PCB仍然存在于系统中，但无法被进一步使用。 孤儿进程：一个进程的父进程已经终止或不存在，但该进程仍然在运行。 三、死锁3.1 什么是死锁多个进程或线程同时被阻塞，他们中的一个或全部都在等待某个资源被释放。由于进程或线程被无限期的阻塞，因此程序不可能正常终止。 比如，现在有两个进程A和B，以及两个资源X和Y，进程A占用X资源，现在需要Y资源，但是进程B此时占用Y资源，需要X资源。两个进程都在等对方释放各自的资源，无法继续往下执行，所以陷入了死锁状态。 3.2 产生死锁的必要条件是什么？ 互斥：资源必须处于非共享模式，即一次只有一个进程可以使用该资源。 占有并等待：一个进程至少应该占有一个资源，并等待另一个资源，而需要的资源被其他进程占有。 非抢占：进程所占有的资源不能被抢占，只有能进程执行完毕后才会释放。 循环等待：有一组进程P1、P2。。。Pn，P1所需的资源被P2占有，P2所需的资源被P3占有。。。Pn的所需资源被P1占有。 注：这四个条件是必要条件。也即只要发生死锁，这些条件必然成立，但是这些条件有一个不满足，就不会发生死锁。 3.3 写一个模拟产生死锁的代码线程死锁示意图 123456789101112131415161718192021222324252627282930313233343536public class Main&#123; private static Object resource1 = new Object();//资源1 private static Object resource2 = new Object();//资源2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1)&#123; System.out.println(Thread.currentThread() + &quot;获取资源1&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;等待资源2&quot;); synchronized (resource2)&#123; System.out.println(Thread.currentThread() + &quot;获取资源2&quot;); &#125; &#125; &#125;, &quot;线程1&quot;).start(); new Thread(() -&gt; &#123; synchronized (resource2)&#123; System.out.println(Thread.currentThread() + &quot;获取资源2&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;等待资源1&quot;); synchronized (resource1)&#123; System.out.println(Thread.currentThread() +&quot;获取资源1&quot;); &#125; &#125; &#125;, &quot;线程2&quot;).start(); &#125;&#125; 运行结果： 1234Thread[线程1,5,main]获取资源1Thread[线程2,5,main]获取资源2Thread[线程1,5,main]等待资源2Thread[线程2,5,main]等待资源1 线程 1 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000);让线程 1休眠 1s 为的是让线程 2 得到执行然后获取到 resource2 的监视器锁。线程1 和线程 2 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。 3.4 解决死锁的方法 预防：采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在系统执行的任何时间上都不满足。 避免：系统在分配资源时，根据资源使用情况提前做出预测，从而避免死锁的发生。 检测：系统设置专门的机构，当死锁发生时，该机构能检测死锁的发生，并精确地确定与死锁有关的进程和资源。 解除：将进程从死锁状态解脱出来。 3.4.1 死锁的预防 静态分配策略。可以破坏产生死锁的第二个条件，指一个进程必须在执行前就申请到它所需要的全部资源，得到所有资源后，才能开始执行。这种策略的逻辑很简单，但是缺点是严重降低了资源利用率。 层次分配策略。可以破坏产生死锁的第四个条件，所有资源被分成多个层次，一个进程得到某一层的一个资源后，只能再申请较高一层的资源；当一个进程要释放某一层的资源时，必须先释放所占用的较高层的资源，这样就避免了循环等待。 3.4.2 死锁的避免将系统的状态分为安全和不安全，每当未申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，那就拒绝分配，否则为它分配资源。 最具有代表性的算法就是银行家算法，用一句话描述就是：当一个进程申请使用资源的时候，银行家算法通过先试探分配给该进程资源，然后通过安全性算法判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若安全，则给该进程分配资源。 银行家算法改善了死锁预防中的资源利用率低的问题，但是缺点是需要不断地检测每个进程对各类资源的占用和申请，并进行安全性检查，需要花费较多时间。 3.4.3 死锁的检测操作系统中每个时刻的系统状态都可以用进程-资源分配图来表示，可以用于检测系统是否处于死锁状态。 用方框表示资源类，方框中的黑点表示资源类中的各个资源，圆圈表示进程，用有向边表示进程申请资源和资源被分配的情况。 进程-资源分配图 图2-21中共有三个资源类，每个进程的资源占有和申请情况已经可以清楚看到。在这个图中，由于存在占有和等待资源的环路，导致一组进程永远处于等待资源的状态，所以产生了死锁。 但是存在环路并不一定是发生了死锁。比如图2-22中，也存在环路，虽然进程 P1 和进程 P3 分别占用了一个资源 R1 和一个资源 R2，并且因为等待另一个资源 R2 和另一个资源 R1 形成了环路，但进程 P2 和进程 P4 分别占有了一个资源 R1 和一个资源 R2，它们申请的资源得到了满足，在有限的时间里会归还资源，于是进程 P1 或 P3 都能获得另一个所需的资源，环路自动解除，系统也就不存在死锁状态了。 所以可以通过以下步骤检测是否产生了死锁： 如果进程-资源分配图中无环路，则此时系统没有发生死锁。 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁。 如果进程-资源分配图中有环路，且涉及到的每个资源类由多个资源，此时系统未必会发生死锁。 3.4.4 死锁的解除 立即结束所有进程的执行，重新启动操作系统。这种方法简单，但是之前的所有工作全部作废，损失很大。 撤销涉及死锁的所有进程，解除死锁后继续运行。这种方法能彻底打破死锁的循环等待条件，但是付出的代价也很大。 逐个撤销涉及死锁的进程，回收其资源直至死锁解除。 抢占资源。从涉及死锁的几个进程中抢占资源，把获得的资源再分配给涉及死锁的进程，直至死锁解除。 四、内存管理4.1 内存管理主要是做什么？内存管理主要做的事情 内存分配与回收：对进程所需的内存进行分配和释放。 地址转换：将程序中的虚拟地址转换成为内存中的物理地址。 内存扩充：当没有足够的内存时，利用虚拟内存的技术或自动覆盖技术，从逻辑上扩充内存。 内存映射：将一个文件直接映射到进程的进程空间中，这样可以通过内存指针直接存取文件内容。 内存优化：通过调整内存分配策略和回收算法来优化内存使用效率。 内存安全：保证进程间使用内存互不干扰，避免恶意程序破坏系统安全性。 4.2 什么是内存碎片？内存碎片是内存的申请和释放产生的，通常分为以下两种： 内部内存碎片：已经分配给内存使用，但是还未使用的内存。 外部内存碎片：由于未分配的连续内存区域太小，以至于不能满足任何进程所需的内存需求，这些小片段且不连续的内存空间。 内存碎片 4.3 常见的内存管理方式有哪些？ 连续内存管理：为一个用户程序分配一个连续的内存空间，内存利用率一般不高。 非连续内存管理：允许一个程序使用的内存分布在离散或者说不连续的内存中，比较灵活。 4.3.1 连续内存管理 块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程。但是这种方法存在严重的内存碎片问题。 伙伴系统算法：Linux系统中连续内存分配算法，将内存按2的幂次划分，并将相邻的内存块组合成为一堆伙伴。当进行内存分配时，伙伴系统会尝试找到大小最合适的内存块。如果找到的内存块过大，就将其一分为二，分成两个大小相等的伙伴块。如果还是大的话，就继续切分，直到到达合适的大小为止。假设两块相邻的内存块都被释放，系统会将这两个内存块合并，进而形成一个更大的内存块，以便后续的内存分配。这样就可以减少内存碎片的问题，提高内存利用率 伙伴系统（Buddy System）内存管理 4.3.2 非连续内存管理 段式管理：以段的形式管理和分配内存。 页式管理：把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被分为连续等长的虚拟页。 段页式管理：结合了段式和页式管理的一种内存管理机制，把物理内存先分为若干段，每个段又继续分为若干大小的页。 4.4 什么是虚拟内存？有什么用？虚拟内存(Virtual Memory) 是计算机系统内存管理非常重要的一个技术，本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。 虚拟内存作为进程访问主存的桥梁 隔离进程：使进程间彼此隔离，一个进程无法更改另一个进程的物理内存。 提升物理内存的利用率。 简化内存管理。 多个进程共享物理内存。 提高内存使用安全性。 提供更大的可使用内存空间。 4.4.1 什么是虚拟地址和物理地址？物理地址是物理内存中的地址，也即内存地址寄存器中的地址。 虚拟地址是程序中访问的内存地址，也即开发时访问的地址。 操作系统中一般通过内存管理单元将虚拟地址转化为物理地址，这个过程被称为地址转换。 ### 4.4.2 虚拟地址和物理地址之间是怎么映射的？ 主要有三种方式： 1. 分段机制 2. 分页机制 3. 段页机制 现代操作系统中更多采用分页机制。 ### 4.4.3 为什么虚拟地址切换空间会比较费时？ 进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以加速页表查找。 这个 Cache 就是 TLB（translation Lookaside Buffer）， TLB 本质上就是一个 Cache，是用来加速页表查找的 地址翻译过程。 由于每个进程都有自己的虚拟地址空间，每个进程都有自己的页表记录虚拟地址与物理地址的转换关系， 那么当进程切换后页表也要进行切换，页表切换后 TLB 就失效了，Cache 失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢。而线程切换则不会导致 TLB 失效，因为线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。 4.5 分段机制分段机制以段的形式管理、分配物理内存。 4.5.1 段表有什么用？地址翻译过程是怎么样的？分段机制通过段表映射虚拟地址和物理地址。虚拟地址由两部分组成： 段号：标识着该虚拟地址属于整个虚拟地址空间中那一段。 段内偏移量：相当于该段起始地址的偏移量。 分段机制下的地址翻译过程 具体的地址翻译过程如下： 内存管理单元首先解析得到虚拟地址中的段号； 通过段号去段表中取出对应的段信息； 从段信息中取出该段的起始地址加上段内偏移量，最终得到物理地址。 4.5.2 通过段号一定能找到对应的段表项吗？不一定。段表项可能不存在： 段表项被删除。 段表项还未创建。如果内存不足或无法分配连续的物理内存块就会导致段表项无法被创建。 4.5.3 分段机制为什么会导致内存外部碎片？在分段机制中，每个段的大小可以不同，因此在分配内存时会留下不同大小的空闲空间，这些空闲空间可能无法被合并使用，从而导致外部碎片的产生。当内存分配器需要寻找一块足够大的连续内存块时，它可能会因为这些零散的空闲空间而无法找到合适的内存块，从而导致内存分配失败。 分段机制导致外部内存碎片 4.6 分页机制分页机制把物理内存分成连续等长的物理页。 4.6.1 页表有什么用？地址翻译过程是怎么样的？分页管理通过页表映射虚拟地址和物理地址。 每个应用程序都会有一个对应的页表。 分页机制下的地址翻译过程 虚拟地址由两部分组成： 页号：通过虚拟页号可以从页表中取出对应的物理页号。 页内偏移量：物理页起始地址+页内偏移量&#x3D;物理内存地址。 具体翻译过程如下： 内存管理单元首先解析得到虚拟地址中的虚拟页号； 通过虚拟页号找到页表，取出对应的物理页号； 通过物理页号对应的起始地址加上页内偏移量得到最终的物理地址。 4.6.2 通过页号一定能找到对应的物理页号吗？不一定！可能会存在页缺失。也即物理内存中没有对应的物理页，或者物理页与虚拟页之间未建立映射。 4.6.3 单级页表有什么问题？为什么需要多级页表？以32位操作系统为例，一个程序啥也不干，光页表大小就得占4MB。应用程序一旦多起来，页表的开销非常大。而且绝大多数应用程序可能只能用到页表中的几项，其他只能浪费。 所以为了解决这个问题，引入了多级页表，多级页表对应多个页表，每个页表与前一个页表相关联，可以极大节省空间占用。 多级页表 多级页表属于时间换空间的典型，利用增加页表查询次数减少页表占用的空间。 4.6.4 TLB有什么用？使用TLB之后的地址翻译流程是什么？TLB也称为快表，目的是提高虚拟地址到物理地址的转换速度。 加入 TLB 之后的地址翻译 TLB本质上属于内存管理单元，其实是一块高速缓存，缓存了虚拟页号到物理页号之间的映射关系。可以简单看作是哈希表，key是虚拟页号，value是物理页号。 使用了快表后翻译流程： 用虚拟地址中的虚拟页号作为key去快表中查询； 如果能查到对应的物理页，就不用去查询页表，这种情况被称为TLB命中； 如果查不到，再去也飙中查询，同时将页表中查到的项加入到快表中。 当快表被填满时，又要重新登记新页时，按淘汰策略淘汰掉一个页。 其实本质上相当于Redis缓存。 4.6.5 什么是页缺失？当软件试图访问已映射在虚拟空间中，但是未被加载在物理内存中的一个分页时，由内存管理单元发出的中断。 常见的页缺失有以下两种： 硬性页缺失：物理内存中没有对应的物理页。 软性页缺失：物理内存中有对应的物理页，但是虚拟页还未和物理页建立映射。 4.7 页面置换算法4.7.1 页面置换算法的作用当发生页缺失时，如果物理内存中没有空闲的物理页面可用的话。操作系统就必须将物理内存中的一个物理页淘汰出去，这个淘汰规则就是页面置换算法，这样就可以腾出空间来加载新页面了。 4.7.2 常见的页面置换算法常见的页面置换算法 最佳页面置换算法：优先选择淘汰的页面是以后永不使用的，或者长时间不再访问的页面，这样可以获取最低的缺页率。只存在于理论中，无法实现。 先进先出页面置换算法：总是淘汰先进入内存的页面，也即选择在内存中驻留时间最久的页面淘汰。 最近最久未使用页面置换算法：该算法赋予每个页面一个访问字段，用来记录该页面自上次访问以来经历的时间，淘汰最近最久未使用的页面。 最少使用页面置换算法：和最近最久未使用算法类似，不过该算法选择的是一段时间内使用最少的页面作为淘汰页。 时钟页面置换算法：也可以认为是最近未使用算法，也即淘汰的页面都是最近没有使用的。 4.7.3 先进先出页面置换算法性能为什么不好？ 经常访问或需要长期存在的页面会被频繁调入调出。 无法识别访问页面的频率和重要性，只考了页面进入的顺序。 4.8 分页机制和分段机制有哪些共同点和区别？4.8.1 共同点 都是非连续内存管理的方法； 都采用了地址映射的方法，将虚拟地址映射到物理地址。 4.8.2 区别 分页机制以页为单位，分段机制以段为单位。页的大小是固定的，通常为2的幂次方，而段的大小是不确定的，通常由运行的程序决定。 页是物理单位，段式逻辑单位。 分段机制容易出现外部内存碎片。分页机制解决了外部内存碎片的问题，但是可能会出现内部内存碎片问题。 分页机制采用了页表来完成虚拟地址到物理地址的映射，其中页表通过多级页表来实现多级映射。而分段机制则采用段表来完成，没有多级段表。 分页机制对程序没有任何要求，程序只需要按照虚拟地址进行访问即可。分段机制需要程序员主动将程序分为多个段，并显式的使用段寄存器来访问不同段。 4.9 局部性原理了解吗？在程序执行过程中，数据和指令的访问存在一定的空间和时间上的局部特点。 时间局部性：由于程序中存在一定的循环或者重复操作，因此会反复访问同一个页或一些特定的页，这就体现了时间局部性特点。为了利用时间局部性，分页机制中通常采用缓存机制来提高页面的命中率。 空间局部性：由于程序中数据和指令的访问通常是具有一定的空间连续性，因此访问某个页时，会顺带访问相邻的一些页。为了利用空间局部性，分页机制中通常采用预取技术来预先将相邻的一些页存入内存缓存中，以便未来能直接使用。 总之，局部性原理是计算机体系结构设计的重要原则之一，也是许多优化算法的基础。采用缓存和预取技术，可以提高页面的命中率，从而提高内存访问效率。 五、文件系统5.1 文件系统的功能？ 存储管理； 文件管理； 目录管理； 文件访问控制。 5.2 软连接和硬链接有什么区别？ 硬链接：是一个指向文件物理地址的链接，多个硬链接共享同一个物理文件。硬链接只有在同一个文件系统中才能使用，因为它们使用相同的索引节点标识文件。在删除一个硬链接时，文件本身不会被删除，只有当最后一个硬链接被删除时，文件才会被删除。 软链接：是一个指向文件名的链接，它是一个特殊类型的文件，它存储着另一个文件的路径名，相当于快捷方式。软链接可以跨文件系统，因为它们使用路径名标识文件。当删除一个软链接时，原始文件不受影响，只有软链接本身被删除。 总结：软链接更灵活，但是性能不如硬链接。硬链接的缺点是不能跨越文件系统，但是优点是可以减少磁盘空间占用，因为多个硬链接共享一个物理文件。 5.3 硬链接为什么不能跨文件系统？因为硬链接是通过索引节点建立连接的，然而每个文件系统都有自己的独立索引表，并且每个索引表只维护该文件系统内的索引。在不同的文件系统之间创建硬链接会导致索引节点之间冲突，所以硬链接不能跨文件系统。 5.4 提高文件系统性能的方式有哪些？ 优化硬件 选择合适的文件系统 运用缓存 避免磁盘过度使用 对磁盘进行合理分区 5.5 常见的磁盘调度算法有哪些？常见的磁盘调度算法 先来先服务算法：按照请求到达磁盘调度器的顺序处理。不过平均寻道时间较长，而且后到的请求可能需要等待很长时间。 最短寻道时间优先算法：优先选择距离当前磁头位置最近的请求进行服务。但远离磁头位置的请求可能长时间得不到响应。 **扫描算法(SCAN)**：磁头沿着一个方向扫描磁盘，如果有请求就处理，直到磁盘边界，然后改变方向，依次往复。 **循环扫描算法(C-SCAN)**：SCAN的变体，只在磁盘的一侧进行扫描，并且只按照一个方向扫描，直到到达磁盘边界，然后回到磁盘起点，重新开始循环。 **边扫描边观察算法(LOOK)**：SCAN是到了磁盘边界才改变移动方向，这样可能会做很多无用功，LOOK是移动方向上如果没有请求，就立即改变方向，依次往复。 **均衡循环扫描算法(C-LOOK)**：C-SCAN是到边界才改变方向，这样可能会做很多无用功，C-LOOK对C-SCAN做了改进，如果移动方向上没有请求了，就立即让磁头返回，而且不需要返回到起点，只需要返回到有磁道访问请求的位置即可。","tags":["Java","八股","基础","面试","操作系统"],"categories":["Java八股","基础"]},{"title":"8.计算机网络","path":"/2023/07/05/8-计算机网络/","content":"一、计算机网络基础1.1 网络分层模型1.1.1 OSI七层模型是什么？OSI 七层模型 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示： OSI 七层模型 OSI 的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，而且有些功能在多个层中重复出现。 1.1.2 TCP&#x2F;IP四层模型是什么？TCP&#x2F;IP 四层模型 是目前被广泛采用的一种模型,我们可以将 TCP &#x2F; IP 模型看作是 OSI 七层模型的精简版本，由以下 4 层组成： 应用层 传输层 网络层 网络接口层 TCP/IP 四层模型 1.1.3 为什么网络要分层？复杂的系统需要分层，因为每一层都需要专注于一类事情。网络分层的原因也是一样，每一层只专注于做一类事情。 各层之间相互独立：各层之间相互独立，各层之间不需要关心其他层是如何实现的，只需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接口调用）。这个和我们对开发时系统进行分层是一个道理。 提高了整体灵活性 ：每一层都可以使用最适合的技术来实现，你只需要保证你提供的功能以及暴露的接口的规则没有改变就行了。这个和我们平时开发系统的时候要求的高内聚、低耦合的原则也是可以对应上的。 大问题化小 ： 分层可以将复杂的网络问题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实现和标准化。 这个和我们平时开发的时候，一般会将系统功能分解，然后将复杂的问题分解为容易理解的更小的问题是相对应的，这些较小的问题具有更好的边界（目标和接口）定义。 1.2 常用网络协议1.2.1 应用层有哪些常用的协议？应用层常见协议 1.2.2 传输层有哪些常用的协议？传输层常见协议 1.2.3 网络层有哪些常用的协议？网络层常见协议 二、HTTP2.1 从输入URL到页面展示期间到底发生了什么？这个问题非常重要，基本包含了整个计算机网络的知识！能展开问的东西很多很多。 输入正确的url网址； DNS解析域名的IP地址；（什么是DNS？DNS解析IP地址的具体过程是什么？） 建立TCP连接，也就是三次握手；（三次握手的具体过程是什么？） 客户端发送HTTP&#x2F;HTTPS请求；（HTTP和HTTPS的区别是什么？Post和Get的区别是什么？） 服务器处理请求并返回HTTP报文；（常见的状态码有哪些？分别代表什么含义？） 浏览器解析渲染页面； HTTP请求结束，断开TCP连接，也即四次挥手。（四次挥手的具体过程是什么？为什么TIME_WAIT之后需要等待2MSL？） 2.2 打开一个网页，整个过程中会使用到哪些协议？ DNS：获取域名对应的IP TCP：与服务器建立TCP连接 IP：建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议 OSPF：IP数据包在路由器之间，路由选择使用OSPF协议 ARP：路由器与服务器通信时，需要将IP地址转换为MAC地址 HTTP：在TCP建立连接后，使用HTTP协议访问网页 2.3 HTTP状态码有哪些？常见 HTTP 状态码 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 「100 Continue」：表示正常，客户端可以继续发送请求。 「101 Switch Protocols」： 切换协议，服务器根据客户端的请求切换协议。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 ​\t注：301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。 「504 Gateway Time-out」充当网关或代理的服务器，未及时从远端服务器获取请求。 2.4 HTTP和HTTPS有什么区别？ 端口号：HTTP默认端口号是80，HTTPS默认端口号是443。 URL前缀：HTTP的前缀是http://，HTTPS的前缀是https://。 安全性和资源消耗：HTTP协议运行在TCP之上，所有的传输内容都是明文，客户端和服务端都无法验证对方身份。HTTPS是运行在SSL&#x2F;TLS之上，所有的传输内容都是进过加密，加密采用对称加密，但对称加密的密钥用服务器方的整数进行非对称加密。所以说HTTP的安全性没有HTTPS高，但是HTTPS比HTTP消耗更多的服务器资源。 搜索引擎优化：搜索引擎通常会更青睐使用HTTPS协议的网站，因为HTTPS能提供更高的安全性和用户隐私保护。 2.4.1 HTTPS加密的过程HTTPS加密过程 客户端将自己支持的加密算法发给服务器； 服务器选择一套客户端支持的加密算法，以证书形式返还给客户端； 客户端解析证书并验证证书的合法性，生成对称加密的密钥，也即客户端密钥，用服务器的公钥对客户端的密钥进行非对称加密； 客户端将加密好的密文发送给服务器； 服务器接收到客户端的密文后，会用自己的私钥对其进行解密，解密之后的明文就是客户端的密钥，然后使用客户端的密钥对要传递的数据进行对称加密。 2.5 HTTP&#x2F;1.0和HTTP&#x2F;1.1有什么区别？HTTP/1.0 和 HTTP/1.1 对比 连接方式：1.0为短连接，1.1支持长连接。 状态响应码：1.1中加入了大量新的状态码，比如说409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移等。 缓存机制：1.0中主要使用 Header 里的 If-Modified-Since，Expires来做为缓存判断的标准，1.1中引入更多的缓存控制策略。 带宽：1.0中存在浪费带宽的现象，比如说客户端只需要某个对象的一部分，而服务器将整个对象送过来了，还不支持断点续传的功能。1.1中在请求头中引入了range头域，允许只请求资源的某一部分。 Host头处理：1.1引入了Host头字段，允许在同一IP地址上托管多个域名，从而支持虚拟主机的功能。而1.0没有该功能。 2.5.1 解释一下什么是长连接和短连接？ 短连接：client与server通过三次握手建立连接，client发送请求消息，server返回响应，一次连接就完成了。 长连接：client向server发起连接，server接受client连接，双方建立连接。client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。 2.6 HTTP&#x2F;1.1和HTTP&#x2F;2.0有什么区别？HTTP/1.0 和 HTTP/1.1 对比 IO多路复用：2.0在同一连接上可以同时传输多个请求和响应。而1.1使用串行方式，每个请求和响应都需要独立的连接。这使得2.0在处理多个请求时更高效，减少了网络延迟、提高了性能。 二进制帧：2.0使用二进制帧进行数据传输，1.1使用文本格式报文。二进制帧更紧凑、高效，减少了传输的数据量和带宽消耗。 头部压缩：1.1支持Body压缩，Header不支持压缩。2.0支持对Header的压缩，减少了网络开销。 服务器推送：2.0支持服务器推送，可以在客户端请求一个资源时，将其他相关资源一并推送给客户端，从而减少客户端的请求次数和延迟。而1.1需要自己发送请求获取相关资源。 2.7 HTTP&#x2F;2.0和HTTP&#x2F;3.0有什么区别？- **传输协议**：2.0是基于TCP协议实现的，3.0新增了QUIC协议来实现可靠传输，提供与TLS/SSL相当的安全性，具有较低的延迟。可以把QUIC看做UDP的升级。 - **连接建立**：2.0需要经过经典的TCP三次握手（一般是三个RTT HTTP/2.0 和 HTTP/3.0 对比。由于QUIC的特性，3.0可以避免三次握手的延迟，允许第一次连接时发送数据（0个RTT）。 队头阻塞：2.0多请求复用一个TCP，一旦发生丢包就会阻塞所有HTTP请求。而3.0使用QUIC一定程度上解决了队头阻塞，一个连接建立多个不同的数据流，数据流之间互不影响。 错误恢复：3.0有更好的错误恢复机制，当出现丢包、延迟等问题时，可以更快进行回复和重传。而2.0依赖于TCP的错误恢复机制。 安全性：两者都支持加密通信，但是实现方式不同，2.0使用TLS进行加密，而3.0基于QUIC协议，包含了内置的加密和身份验证机制，安全性更强。 2.8 HTTP是不保存状态的协议，那么如何保存用户状态？使用Session机制，Session的主要作用就是通过服务端记录用户状态。最典型的场景就是购物车，当需要向购物车中添加商品时，系统不知道是哪个用户操作的，因为HTTP协议是无状态的，所以服务器给特定的用户创建特定的Session之后，就可以标识这个用户并跟踪这个用户了。 在服务端保存Session的方式很多，最常用的就是内存和数据库（比如Redis）。 2.8.1 Session存在服务端，那如何实现Session的跟踪？大多数情况下，通过Cookie中附加一个Session ID来进行跟踪。 2.8.2 如果Cookie被禁用怎么办？最常用的方法就是利用URL重写把Session ID直接附加在URL路径的后面。 2.9 常见概念的区别2.9.1 URI和URL的区别是什么？ URI（Uniform Resource Identifier）：是统一资源标志符，可以唯一标识一个资源。 URL（Uniform Resource Locator）：是统一资源定位符，可以提供该资源的路径。它是一种具体的URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。 2.9.2 Cookie和Session有什么区别？ 存储位置不同：Cookie存储在客户端的浏览器中，而Session存储在服务器。 存储内容不同：Cookie中只能存储字符串类型的数据，而Session可以存储任何Java对象。 安全性不同：Cookie中存储的信息可以被客户端查看和修改，而Session存储在服务器上，客户端无法查看和修改。 生命周期不同：Cookie可以设置过期时间，而Session默认在客户端关闭浏览器后就会失效。 存储容量不同：Cookie大小有限制，而Session存储容量较大，一般可以存储几MB的数据。 Cookie一般只能存储一些简单的用户信息，比如用户名、密码等； Session用于在服务器存储一些复杂的对象信息，比如购物车、用户登录信息等。 2.9.3 Get和Post有什么区别？GET 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。 GET请求 POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。 POST请求 主要区别如下： 参数位置：Get请求的参数以查询字符串形式写在URL中，而Post请求的参数出现在HTTP请求的消息体中。 安全性：Get请求的参数暴露在URL中，所以可以被浏览器缓存、历史记录等保存，存在安全风险，而Post的请求参数在消息体中，相对安全。 参数大小：Get请求因为在URL中，有长度限制，取决于浏览器和服务器的限制，而Post的请求没有长度限制。 编码方式：Get请求的参数默认使用URL编码，在传递非ASCⅡ字符时需要进行编码，而Post请求支持多种编码方式。 幂等性：Get请求是幂等的，即多次请求返回的结果是一致的；而Post请求不一定是幂等的，因为可能会对服务器状态进行修改。 总结：Get请求适合用于获取服务器资源（适合读），Post请求适合用于提交数据（适合写）。 2.10 HTTP的缓存技术了解吗？2.10.1 HTTP为什么要用缓存技术？当客户端向服务器请求资源时，会先去查浏览器缓存，如果缓存中有要请求资源，就可以直接从浏览器缓存中提取而不用再从原始服务器中请求这个资源。 优点： 缓解服务器压力； 降低客户端获取资源的延迟：缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存和服务器缓存。 HTTP缓存技术有两种实现方式，分别是强制缓存和协商缓存。 2.10.2 强制缓存强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动权在于浏览器这边。 强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期： Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 2.10.3 协商缓存协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。 协商缓存可以基于两种头部来实现。 第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 缓存过程 只有在未命中强制缓存的时候，才会发起协商缓存的请求。 2.11 安全相关问题2.11.1 对称加密和非对称加密有什么区别？ 对称加密：使用相同的密钥对数据进行加密和解密。常见的对称加密算法有DES、AES等。优点是加密和解密速度快，缺点是密钥管理不方便，如果密钥被泄露，数据就会变得不安全。 非对称加密：使用一对公钥和私钥对数据进行加密和解密。公钥可以自由分发，任何人都可以使用公钥对数据进行加密，但是只有拥有私钥的人才能解密。常见的非对称加密算法有RSA、DSA等。优点是密钥管理方便，缺点是加密和解密速度较慢。 2.11.2 XSS攻击是什么？XSS攻击指跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。 如何防范XSS攻击： 前端，服务端，同时需要限制字符串输入的长度。 前端，服务端，同时需要对HTML转义处理。将其中的”&lt;”,”&gt;”等特殊字符进行转义编码。 防 XSS 的核心是必须对输入的数据做过滤处理。 2.11.3 CSRF攻击是什么？CSRF攻击指跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。 可以简单理解为：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。 如何防范CSRF攻击： 安全框架，例如Spring Security。 Token机制。在HTTP请求中进行Token验证，如果请求中没有Token或者Token内容不正确，则认为CSRF攻击而拒绝该请求。 验证码。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。 Referer识别。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。 三、PING3.1 PING命令的作用是什么？PING命令是一种常用的网络诊断工具，经常用来测试网络中主机之间的连通性和网络延迟。 123456789101112C:\\Users\\Acer&gt;ping www.baidu.com正在 Ping www.a.shifen.com [14.119.104.189] 具有 32 字节的数据:来自 14.119.104.189 的回复: 字节=32 时间=33ms TTL=55来自 14.119.104.189 的回复: 字节=32 时间=33ms TTL=55来自 14.119.104.189 的回复: 字节=32 时间=33ms TTL=55来自 14.119.104.189 的回复: 字节=32 时间=33ms TTL=5514.119.104.189 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 33ms，最长 = 33ms，平均 = 33ms 3.2 PING命令的工作原理是什么？PING 基于网络层的 ICMP（Internet Control Message Protocol，互联网控制报文协议），其主要原理就是通过在网络上发送和接收 ICMP 报文实现的。 ICMP 报文中包含了类型字段，用于标识 ICMP 报文类型。ICMP 报文的类型有很多种，但大致可以分为两类： 查询报文类型 ：向目标主机发送请求并期望得到响应。 差错报文类型 ：向源主机发送错误信息，用于报告网络中的错误情况。 PING 用到的 ICMP Echo Request（类型为 8 ） 和 ICMP Echo Reply（类型为 0） 属于查询报文类型 。 PING 命令会向目标主机发送 ICMP Echo Request。 如果两个主机的连通性正常，目标主机会返回一个对应的 ICMP Echo Reply。 三、DNS3.1 DNS的作用是什么？DNS是域名管理系统，是当前用户浏览器访问网址之后，使用的第一个重要的协议。 DNS解决的是域名和IP地址的映射问题。 DNS:域名系统 在实际使用中，有一种情况下，浏览器是可以不必动用 DNS 就可以获知域名和 IP 地址的映射的。 浏览器在本地会维护一个hosts列表，一般来说浏览器要先查看要访问的域名是否在hosts列表中，如果有的话，直接提取对应的 IP 地址记录就好了。如果本地hosts列表内没有域名与IP 对应记录的话，那么 就需要用到DNS 。 目前 DNS 的设计采用的是分布式、层次数据库结构，DNS 是应用层协议，基于 UDP 协议之上，端口为 53 。 3.2 DNS服务器有哪些？ 根DNS服务器：根 DNS 服务器提供 TLD 服务器的 IP 地址。目前世界上只有 13 组根服务器，我国境内目前仍没有根服务器。 顶级域DNS服务器（TLD服务器）：顶级域是指域名的后缀，比如com、org、net、edu等等。顶级域服务器提供权威DNS服务器IP地址。 权威DNS服务器：在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的 DNS 记录，这些记录将这些主机的名字映射为 IP 地址。 本地DNS服务器：每个互联网服务提供商都有一个自己本地DNS服务器。当主机发出DNS请求时，该请求被发往本地DNS服务器，起到代理的作用。 3.3 DNS解析的过程是什么样的？ 客户端首先发出一个DNS请求，问www.server.com的IP是啥，并发给本地的DNS服务器（也就是本地客户端的TCP&#x2F;IP设置中填写的DNS服务器地址）。 本地域名服务器收到客户端请求后，如果缓存的表格中能找到这个网址的IP地址，那么就直接返回IP地址；如果没有，则本地DNS会去问它的根域名服务器，这个网址的IP地址。根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。 根DNS收到本地DNS请求后，发现网址后置是.com，则会告诉本地DNS这个网址归.com顶级域名服务器管理，并把这个顶级域名服务器的地址给本地DNS。 本地DNS收到地址后，去询问顶级域名服务器，然后顶级域名服务器会给www.server.com区域的权威DNS服务器地址。 本地DNS服务器去询问权威DNS服务器，权威DNS服务器查询到IP地址后，告诉本地DNS。 本地DNS再将IP地址告诉客户端，客户端与目标建立连接。 # 四、TCP和UDP ## 4.1 TCP和UDP的区别 - **是否面向连接**：**UDP在传输数据之前不需要先建立连接**。**TCP在传输数据之前需要先建立连接**，传输结束后要释放连接。 - **是否可靠传输**：远程主机收到UDP报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达，也即**UDP的传输服务不可靠**。**TCP提供可靠的传输服务**，在传递数据之前通过三次握手建立连接，而且在传递数据时，有确认、窗口、重传、拥塞控制机制。通过TCP传输的数据无差错、不丢失、不重复并且按序到达。 - **是否有状态**：**UDP是无状态的服务**，也即不管发出去之后的事。**TCP传输是有状态的**，会记录自己发送消息的状态，比如是否发送、是否被接受等等。 - **传输效率**：由于TCP在传输时多了连接、确认、重传等机制，所以TCP的传输效率要比UDP低很多。 - **传输形式**：UDP是面向报文的，TCP是面向字节流的。 - **首部开销**：TCP首部开销（20-60字节）比UDP首部开销（8字节）要大。 - **是否提供广播或多播服务**：TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多。 | | TCP | UDP | | :--------------------: | :---------: | :--------: | | 是否面向连接 | 是 | 否 | | 是否可靠 | 是 | 否 | | 是否有状态 | 是 | 否 | | 传输效率 | 较慢 | 较快 | | 传输形式 | 字节流 | 数据报文段 | | 首部开销 | 20 ~ 60字节 | 8字节 | | 是否提供广播或多播服务 | 否 | 是 | ## 4.2 什么时候选择TCP，什么时候选择UDP？ - **UDP一般用于即时通信**，比如：语音、视频、直播等，这些场景对于传输数据的准确性要求不是特别高。 - **TCP用于对传输准确性要求特别高的场景**，比如文件传输、收发邮件、远程登录等。 ## 4.3 HTTP是基于TCP还是UDP？ 需要分版本讨论，在HTTP1.0、1.1、2.0中，是基于TCP协议的，而3.0中HTTP基于UDP的QUIC协议。 通过这个变化解决了2.0中的队头阻塞问题，同时还避免了TCP三次握手的延迟，允许在第一次连接时就发送数据。 ## 4.4 使用TCP和UDP的协议分别有哪些？ ### 4.4.1 使用TCP的协议 1. HTTP：超文本传输协议（HTTP，HyperText Transfer Protocol DNS解析的过程是一种用于传输超文本和多媒体内容的协议，主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议。 FTP：文件传输协议 FTP（File Transfer Protocol）是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。 SMTP：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，是一种用于发送电子邮件的协议。 POP3&#x2F;IMAP：两者都是负责邮件接收的协议。IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。 SSH：SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。 4.4.2 使用UDP的协议 DHCP：动态主机配置协议，动态配置 IP 地址 DNS：域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。 4.5 TCP三次握手和四次挥手4.5.1 说一说什么是三次握手？建立一个TCP连接需要三次握手，缺一不可。 三次握手 一次握手：客户端发送带有SYN（SEQ&#x3D;x）标志的数据包到服务器，然后客户端进入SYN_SENT状态，等待服务器的确认。 二次握手：服务器发送带有SYN+ACK（SEQ&#x3D;y，ACK&#x3D;x+1）标志的数据包给客户端，然后服务器进入SYN_RECV状态。 三次握手：客户端发送带有ACK（ACK&#x3D;y+1）标志的数据包给服务器，然后客户端和服务器都进入ESTABLISHED状态，完成三次握手。 当完成三次握手之后，客户端和服务器之间就可以传输数据了。 4.5.2 为什么要进行三次握手？（为什么不是两次或四次握手？）因为TCP采用的是全双工通信，进行三次握手的目的是建立可靠的通信信道，最主要的目的就是客户端和服务器双方确认自己与对方的发送和接收功能是正常的。 第一次握手作用就是服务器确认：对方发送正常，自己接收正常。 第二次握手作用就是客户端确认：自己发送、接收正常，对方发送、接收正常；服务器确认：对方发送正常、自己接受正常。 第三次握手作用就是客户端确认：自己发送、接收正常，对方发送、接收正常；服务器确认：自己发送、接收正常，对方发送、接收正常。 三次握手就能刚好确认双方收发功能正常，缺一不可。 三次握手才可以阻止重复历史连接的初始化，防止旧的重复连接初始化造成混乱。 三次握手才可以同步双方的初始序列号。 三次握手才可以避免资源浪费。 4.5.3 第二次握手传回了ACK，为什么还要传回SYN？服务器传回给客户端ACK是为了告诉客户端：“我收到的信息确实是你发的信息”，这表明客户端到服务器之间的通信是正常的，而传回SYN是为了建立并确认从服务器到客户端的通信正常。 4.5.4 说一说什么是四次挥手？断开TCP连接需要四次挥手，缺一不可。 第一次挥手：客户端发送一个FIN（SEQ&#x3D;x）标志的数据包给服务器，用来关闭客户端到服务器的数据传输。然后，客户端进入FIN-WAIT-1状态。 第二次挥手：服务器收到这个FIN（SEQ&#x3D;x）标志的数据包，它发送一个ACK（SEQ&#x3D;x+1）标志的数据包给客户端。然后此时服务器进入CLOSE-WAIT状态，客户端收到数据包后进入FIN-WAIT-2状态。 第三次挥手：服务器关闭与客户端之间的连接，并发送一个FIN（SEQ&#x3D;y）标志的数据包给客户端，请求关闭连接，然后服务器进入LAST-ACK状态。 第四次挥手：客户端收到FIN数据包后，发送ACK（SEQ&#x3D;y+1）标志的数据包给服务器，并且进入TIME_WAIT状态，服务器在收到ACK（SEQ&#x3D;y+1）标志的数据包后进入CLOSE状态。此时客户端等待2MSL后依然没有收到回复，就证明服务器已经正常关闭，随后客户端也就可以正常关闭了，也变成CLOSE状态。 只要四次挥手没有结束，客户端和服务器之间就可以继续传输数据。 4.5.5 为什么要四次挥手？TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 比如，A和B打电话，即将结束时： 第一次挥手：A说：我没什么要说的了。 第二次挥手：B说：我知道了，但是B可能还有要说的话，A不能因为自己没什么要说的了就中断对话。 第三次挥手：B巴拉巴拉说了一通，B终于说：我说完了。 第四次挥手：A说：我知道了，这样双方都没什么说的了，对话才算结束。 4.5.6 为什么不把服务器发送的ACK和FIN合并，变成三次挥手？因为服务器在收到客户端发送的断开连接请求时，可能还有一些数据没有发送完，所以这时候先发送ACK，表示收到了你要断开连接的请求。等我这些数据发完，再发送FIN，表示我数据发完了，可以断开连接了。 4.5.7 如果第二次挥手时，服务器的ACK没有送到客户端会发生什么？客户端没有收到ACK确认，会重新发送FIN请求，继续第一次挥手的操作。 4.5.8 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？第四次挥手时，客户端发送给服务器的 ACK 有可能丢失，如果服务端因为某些原因而没有收到 ACK 的话，服务端就会重发 FIN，如果客户端在 2*MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，所以一来一回需要等待 2 倍的时间。 2MSL时长 这其实是相当于至少允许报文丢失一次。防止服务器没有收到 ACK 而不断重发 FIN。 4.6 TCP传输可靠性保障？4.6.1 TCP如何保证传输的可靠性？ 基于数据块传输：应用数据被分割成TCP认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。 对失序数据包重新排序以及去重：TCP为了保证不发生丢包，就给每个包一个序列号，有了序列号就能将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。 校验和：TCP将保持它首部和数据的校验和。这是一个端到端的校验和，目的是检测数据在传输过程中的任何变化。如果收到段的校验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 超时重传：当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为已丢失并进行重传。 流量控制：TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。 拥塞控制：当网络拥塞时，减少数据的发送。 4.6.2 TCP如何实现流量控制？TCP利用滑动窗口实现流量控制。其目的是为了控制发送方发送数据的速率，保证接收方来得及接收。接收方发送的确认报文中，窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为0时，发送方不能发送数据。 4.6.3 为什么要进行流量控制？双方在通信时，发送方的速率和接收方的速率不一定是相等的，如果发送方的发送速率太快，会导致接收方处理不过来。如果接收方处理不过来的话，就只能把数据存在接收缓冲区里。如果缓冲区满了，发送方还在发送数据的话，接收方只能把收到的数据包丢掉，浪费网络资源。所以要控制发送方的发送速率，让两者处于一种动态平衡。 注意：发送方不等于客户端，接收端也不等于服务器。 因为TCP是全双工通信，双方都可以进行双向通信。 4.6.4 发送窗口和接收窗口1.TCP发送窗口可以划分为四个部分 发送已确认； 发送未确认； 未发可发送； 不可发送； 发送窗口大小 &#x3D; 发送未确认 + 未发可发送 。 2.TCP接收窗口可以划分为三个部分 已收已确认； 等待接收； 不能接收； 接收窗口的大小 &#x3D; 等待接收 可以根据接收端处理数据的速度动态调整的。 接收窗口的大小约等于发送窗口的大小， 4.6.5 TCP如何实现拥塞控制？拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 TCP的拥塞控制 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP 的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。 拥塞避免： 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1。 快重传与快恢复： 在 TCP&#x2F;IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 4.6.6 什么是ARQ协议？自动重传请求ARQ是OSI模型中数据链路层和传输层的错误纠正协议之一。通过确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。 如果发送方在发送后一段时间内没有收到确认信息，也即ACK，通常会重新发送，直到收到确认或者重试超过一定次数。 ARQ协议包括停止等待ARQ协议和连续ARQ协议。 停止等待ARQ协议：为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复 ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。 连续 ARQ 协议：可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 4.7 什么是SYN攻击？大量的握手请求涌向 TCP 服务端，而它们只发出 SYN 报文而不以 ACK响应结束握手，服务端就要为这每一个请求都维持约一分多钟的连接去等待 ACK， 从而额外消耗很多服务器的网络连接资源，导致服务端较长时间内丧失服务功能。 其中最经典的就是 DoS（Denial of Service 拒绝服务）攻击。 SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。 4.7.1 如何避免SYN攻击？ 调大网络接口队列长度，提高网络接口吞吐能力和抗压能力； 增大TCP半连接队列； 开启SYN Cookie技术； 减少SYN+ACK重传次数； 4.8 拔掉网线后，原本的TCP连接还存在吗？客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。 有数据传输的情况： 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。 没有数据传输的情况： 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。 4.9 什么是粘包和拆包？发生的原因是什么？一个完整的业务可能会被TCP拆分成多个包进行发送，也有可能把多个小的数据包封装成一个大的数据包发送，这个就是TCP的拆包和粘包问题。 4.9.1 拆包 要发送的数据大于TCP发送方缓冲区剩余空间大小，将会发生拆包； 待发送数据大于最大报文长度，TCP在传输前将进行拆包； 4.9.2 粘包 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包； 接收数据端的应用层没有及时读取接收缓冲区中的数据，会导致数据包堆积，也会发生粘包； 4.9.3 解决方案 固定消息的长度。 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从缓冲区中读取固定长度的数据，这就自然而然的把每个数据包拆分开来； 设置消息边界：比如在数据包末尾增加特殊字符或特殊标记进行分割； 将消息分为消息头和消息体：消息头中包含表示消息总长度的字段，消息体是要读取的内容； 使用其它复杂的协议。 五、IP5.1 IP协议的作用是什么？IP（Internet Protocol，网际协议） 是 TCP&#x2F;IP 协议中最重要的协议之一，属于网络层的协议，主要作用是定义数据包的格式、对数据包进行路由和寻址，以便它们可以跨网络传播并到达正确的目的地。 目前 IP 协议主要分为两种，一种是过去的 IPv4，另一种是较新的 IPv6，目前这两种协议都在使用。 5.2 什么是IP地址？IP寻址如何工作？每个连入互联网的设备或域（如计算机、服务器、路由器等）都被分配一个 IP 地址（Internet Protocol address），作为唯一标识符。每个 IP 地址都是一个字符序列，如 192.168.1.1（IPv4）、2001:0db8:85a3:0000:0000:8a2e:0370:7334（IPv6）。 当网络设备发送 IP 数据包时，数据包中包含了 源 IP 地址 和 目的 IP 地址 。 源 IP 地址用于标识数据包的发送方设备或域，而目的 IP 地址则用于标识数据包的接收方设备或域。这类似于一封邮件中同时包含了目的地地址和回邮地址。 网络设备根据目的 IP 地址来判断数据包的目的地，并将数据包转发到正确的目的地网络或子网络，从而实现了设备间的通信。 这种基于 IP 地址的寻址方式是互联网通信的基础，它允许数据包在不同的网络之间传递，从而实现了全球范围内的网络互联互通。IP 地址的唯一性和全局性保证了网络中的每个设备都可以通过其独特的 IP 地址进行标识和寻址。 IP 地址使数据包到达其目的地 5.3 什么是IP地址过滤？简单来说就是限制或阻止特定IP地址或IP地址范围的访问。比如，有个图片服务突然被某一IP地址攻击，那我们就可以禁止这个IP地址访问图片服务。 IP地址过滤是一种简单的网络安全措施，实际应用中一般还会结合其他的网络安全措施，比如认证、授权、加密等等。 5.4 IPv4和IPv6有什么区别？IPv4（Internet Protocol version 4） 是目前广泛使用的 IP 地址版本，其格式是四组由点分隔的数字，例如：123.89.46.72。IPv4 使用 32 位地址作为其 Internet 地址，这意味着共有约 42 亿（ 2^32）个可用 IP 地址。 为了解决 IP 地址耗尽的问题，最根本的办法是采用具有更大地址空间的新版本 IP 协议 - IPv6（Internet Protocol version 6）。IPv6 地址使用更复杂的格式，该格式使用由单或双冒号分隔的一组数字和字母，例如：2001:0db8:85a3:0000:0000:8a2e:0370:7334 。可以使用 128 位互联网地址，这意味着越有 2^128（3 开头的 39 位数字，恐怖如斯） 个可用 IP 地址。 除了更大的地址空间之外，IPv6 的优势还包括： 无状态地址自动配置（Stateless Address Autoconfiguration，简称 SLAAC） ：主机可以直接通过根据接口标识和网络前缀生成全局唯一的 IPv6 地址，而无需依赖 DHCP（Dynamic Host Configuration Protocol）服务器，简化了网络配置和管理。 NAT（Network Address Translation，网络地址转换） 成为可选项 ：IPv6 地址资源充足，可以给全球每个设备一个独立的地址。 对标头结构进行了改进 ：IPv6 标头结构相较于 IPv4 更加简化和高效，减少了处理开销，提高了网络性能。 可选的扩展头 ：允许在 IPv6 标头中添加不同的扩展头（Extension Headers），用于实现不同类型的功能和选项。 ICMPv6（Internet Control Message Protocol for IPv6） ：IPv6 中的 ICMPv6 相较于 IPv4 中的 ICMP 有了一些改进，如邻居发现、路径 MTU 发现等功能的改进，从而提升了网络的可靠性和性能。 5.5 NAT的作用是什么？网络地址转换主要用于不同网络之间转换IP地址。它允许将私有IP地址（局域网中使用的IP地址）映射为公有IP地址（互联网中使用的IP地址）或者反向映射，从而实现局域网内多个设备通过单一公有IP地址访问互联网。 NAT 不光可以缓解 IPv4 地址资源短缺的问题，还可以隐藏内部网络的实际拓扑结构，使得外部网络无法直接访问内部网络中的设备，从而提高了内部网络的安全性。 NAT 实现 IP地址转换 六、ARP6.1 什么是MAC地址？MAC 地址的全称是 媒体访问控制地址（Media Access Control Address）。如果说，互联网中每一个资源都由 IP 地址唯一标识（IP 协议内容），那么一切网络设备都由 MAC 地址唯一标识。 可以理解为，MAC 地址是一个网络设备真正的身份证号，IP 地址只是一种不重复的定位方式（比如说住在某省某市某街道的张三，这种逻辑定位是 IP 地址，他的身份证号才是他的 MAC 地址），也可以理解为 MAC 地址是身份证号，IP 地址是邮政地址。MAC 地址也有一些别称，如 LAN 地址、物理地址、以太网地址等。 MAC 地址的长度为 6 字节（48 比特），地址空间大小有 280 万亿之多。 前 24 比特由 IEEE 统一管理，保证不会重复。而后 24 比特，由各家生产商自己管理，同样保证生产的两块网卡的 MAC 地址不会重复。 MAC 地址具有可携带性、永久性，身份证号永久地标识一个人的身份，不论他到哪里都不会改变。而 IP 地址不具有这些性质，当一台设备更换了网络，它的 IP 地址也就可能发生改变，也就是它在互联网中的定位发生了变化。 MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址。 6.2 ARP协议解决了什么问题？ARP协议全称地址解析协议，它解决的是网络层地址与链路层地址间的转换问题。因为一个IP数据报在物理上传输的过程中，总是需要知道下一跳的目的地，但是IP地址属于逻辑地址，而MAC地址才是物理地址，而ARP协议解决了IP地址转MAC地址的一些问题。 6.3 ARP协议工作原理？ARP 协议工作时有一个大前提，那就是 ARP 表。 在一个局域网内，每个网络设备都自己维护了一个 ARP 表，ARP 表记录了某些其他网络设备的 IP 地址-MAC 地址映射关系，该映射关系以 &lt;IP, MAC, TTL&gt; 三元组的形式存储。其中，TTL 为该映射关系的生存周期，典型值为 20 分钟，超过该时间，该条目将被丢弃。 ARP 的工作原理将分两种场景讨论： 同一局域网内的 MAC 寻址； 从一个局域网到另一个局域网中的网络设备的寻址。 6.3.1 同一局域网内的MAC寻址假设当前有如下场景：IP 地址为137.196.7.23的主机 A，想要给同一局域网内的 IP 地址为137.196.7.14主机 B，发送 IP 数据报文。 再次强调，当主机发送 IP 数据报文时（网络层），仅知道目的地的 IP 地址，并不清楚目的地的 MAC 地址，而 ARP 协议就是解决这一问题的。 为了达到这一目标，主机A只能通过ARP协议来获取主机B的MAC地址，并将IP报文封装成链路层帧，发送到下一跳。在该局域网内，将发生以下事情： 主机A检索自己的ARP表，发现ARP表中并无主机B的IP地址对应的映射条目，也就无从知道主机B的MAC地址。 主机A构建一个ARP查询分组，并将其广播到所在的局域网中。 ARP分组是一种特殊报文，主要有两类，一类是查询分组、一类是响应分组，具有相同的格式，均包含了发送和接收的IP地址、发送和接收的MAC地址。在查询分组中，发送的IP地址，也就是主机A的IP地址，接收的IP地址就是主机B的IP地址，发送的MAC地址就是主机A的MAC地址，但是接收的MAC地址并不是主机B的MAC地址（因为这就是需要查询的），而是一个特殊值FF-FF-FF-FF-FF-FF，也就是前面说的特殊地址，广播地址，也即查询分组将广播给该局域网内的所有设备。 主机A构造的查询分组将在该局域网内进行广播，理论上每个设备都会收到该分组，并检查查询分组的接收IP地址是否为自己的IP地址，如果是，那么说明查询分组已经找到了主机B，否则，这个查询分组对于当前设备无效，当前设备会将这个查询分组丢弃。 主机B收到了查询分组后，验证是对自己的问询，然后构造一个ARP响应分组，该分组的目的地只有一个——主机A，发送给主机A。同时主机B提取查询分组中主机A的IP地址和MAC地址信息，在自己的ARP表中构造一条主机A的IP-MAC映射记录。 ARP响应分组和ARP查询分组有相同的构造，不同的是，发送和接收的IP地址相反，发送的MAC地址为发送者本身，也即主机B的MAC地址，目标MAC地址为查询分组的发送者，也即主机A的MAC地址，也就是说ARP响应分组只有一个目的地，而不是查询分组那样是一个广播。 主机A收到了主机B的响应分组，提取出该分组中主机B的IP地址和MAC地址后，构造映射信息，加入到自己的ARP表中。 同一局域网内ARP寻址过程 再整个过程中，需要补充几点： 主机A想给主机B发送IP数据报，如果主机B的IP-MAC映射信息已经存在于主机A的ARP表中，那么就不需要广播，直接提取MAC地址并构造链路层帧发送就行。 ARP表中的映射信息是有生存周期的，一般为20分钟。 目标主机接受到了问询主机构造的问询报文后，将先把问询主机的IP-MAC映射存进自己ARP表中，这样才能获取到响应目标MAC地址，以便顺利发送响应分组。 总的来说ARP协议是一个广播问询，单播响应协议。 6.3.2 不同局域网内的MAC寻址更复杂的情况是，发送主机 A 和接收主机 B 不在同一个子网中，假设一个一般场景，两台主机所在的子网由一台路由器联通。这里需要注意的是，一般情况下，我们说网络设备都有一个 IP 地址和一个 MAC 地址，这里说的网络设备，更严谨的说法应该是一个接口。路由器作为互联设备，具有多个接口，每个接口同样也应该具备不重复的 IP 地址和 MAC 地址。因此，在讨论 ARP 表时，路由器的多个接口都各自维护一个 ARP 表，而非一个路由器只维护一个 ARP 表。 主机A查询ARP表，希望找到目标路由器的本子网接口的MAC地址。 目标路由器是指，根据目的主机B的IP地址，分析出B所在的子网，能够把报文转发到B所在子网的那个路由器。 主机A没找到，采用ARP协议，问询到该MAC地址，由于目标接口与主机A在同一个子网中，该过程与同一局域网内的MAC寻址相同。 主机A获取到目标接口的MAC地址，先构造IP数据报，其中源IP是A的IP地址，目的IP地址是B的IP地址，再构造链路层帧，其中源MAC地址是A的MAC地址，目的MAC地址是本子网内与路由器连接的接口的MAC地址。主机A将把这个链路层帧，以单播的方式，发送给目标接口。 目标接口接收到了主机A发来的链路层帧，解析，根据目的IP地址，查询转发表，将该IP数据报转发到与主机B所在子网相连的接口上。 到此，该帧已经从主机A所在的子网，转移到主机B所在的子网中了。 路由器接口查询ARP表，希望找到主机B的MAC地址。 路由器接口如果没找到，将采用ARP协议，广播问询，单播响应，获取到主机B的MAC地址。 路由器接口将对IP数据报重新封装成链路层帧，目标MAC地址为主机B的MAC地址，单播发送，直到到达目的地。 不同一局域网ARP寻址过程","tags":["Java","八股","基础","面试","计算机网络"],"categories":["Java八股","基础"]},{"title":"7.Redis","path":"/2023/07/02/7-Redis/","content":"一、Redis基础1.1 Redis有哪些优缺点？1.1.1 优点 读写性能优异。 支持数据持久化，支持AOF和RDB两种持久化方式。 支持事务，Redis的所有操作都是原子性的，同时还支持对几个操作合并后的原子性执行。 数据结构丰富，除了支持String类型的value外，还支持Hash、Set、ZSet、List等数据机构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 1.1.2 缺点 数据库容量受到物理内存限制，不能用作海量数据的高性能读写，只适用于较小数据量的高性能操作和运算上。 Redis不具备自动容错和恢复功能。 无法支持复杂查询。 数据容易丢失。 Redis较难支持在线扩容。 1.2 Redis为什么这么快？ Redis是基于内存的，内存的访问速度是磁盘的上千倍； Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用； Redis 内置了多种优化过后的数据结构实现，性能非常高。 1.3 为什么要用Redis？（为什么要用缓存？） 高性能 假如用户第一次访问数据库中的某些数据的话，是从硬盘中读取的，这个过程是比较慢。但是，如果用户访问的数据属于高频数据并且不会经常改变的话，可以将该用户访问的数据存在缓存中。这样保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。 高并发 直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存而不用经过数据库。进而，也就提高了系统整体的并发。 1.4 说一说Redis和Memcached的区别和共同点？1.4.1 共同点 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者性能都非常高。 1.4.2 区别 数据类型支持不同， Memcached 仅支持简单的 key-value 结构的数据记录，Redis 支持的数据类型要丰富得多。最为常用的数据类型主要有五种：String、Hash、List、Set 和 Sorted Set。 内存管理机制不同，在 Redis 中，并不是所有的数据都一直存储在内存中的。这是和 Memcached 相比一个最大的区别。当物理内存用完时，Redis 可以将一些很久没用到的 value 交换到磁盘。 数据持久化支持不同，Redis 虽然是基于内存的存储系统，但是它本身是支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB 快照和 AOF 日志。而 memcached 是不支持数据持久化操作的。 集群的管理不同，Memcached 本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现 Memcached 的分布式存储。相较于 Memcached 只能采用客户端实现分布式存储，Redis 更偏向于在服务器端构建分布式存储。 1.5 说一说Redis中常用的缓存读写策略？1.5.1 旁路缓存模式适用于请求比较多的场景。 旁路缓存模式中服务端需要同时维系DB和Cache，并且以DB的结果为主。 写： 先更新DB； 然后直接删除Cache。 先更新DB再删除缓存 写： 从Cache中读取数据，读取到就直接返回； Cache中读取不到的话，就从DB中读取数据返回； 再把数据放到Cache中。 写 在写数据的过程中，可以先删除Cache，然后再更新DB吗?不行！因为这样可能会造成DB和Cache中的数据不一致的问题。 比如，请求1先把Cache中的A数据删除 -&gt; 请求2从DB中读取数据 -&gt; 请求1再把DB中的A数据更新。 在写数据的过程中，可以先更新DB，然后再删除Cache吗？理论上来说还是有可能出现数据不一致性的问题，不过概率比较小，因为Cache的写入速度比DB写入速度快很多。 比如，请求1从DB中读数据A -&gt; 请求2更新DB中的数据A -&gt; 请求1将数据A写入Cache。 旁路缓存模式的缺点： 首次请求的数据一定不在Cache中。 解决方法：可以将热点数据提前放入Cache中。 写操作比较频繁的话会导致Cache中的数据会被频繁删除，这样会影响缓存的命中率。 解决方法： DB和Cache数据一致的情况下，同步更新DB和Cache，但需要加锁保证更新Cache时不存在线程安全问题。 DB和Cache数据不一致的情况下，同步更新DB和Cache，但是给Cache加一个比较短的过期时间。 1.5.2 读写穿透模式该模式中服务端把Cache视为主要数据存储，从中读取数据并将数据写入其中，Cache负责将数据读取和写入DB。 写穿透： 先查Cache，Cache中不存在，直接更新DB； Cache中存在，则先更新Cache，然后Cache服务自己更新DB（同步更新Cache和DB）。 写穿透 读穿透： 从Cache中读取数据，读取到就直接返回； 读取不到的话，先从DB加载，写入到Cache后返回响应。 读穿透 1.5.3 异步缓存写入模式与读写穿透模式类似，都是由Cache服务来负责Cache和DB的读写。 但是，读写穿透模式是同步更新Cache和DB，而异步缓存写入模式只是更新Cache，不直接更新DB，通过异步批量的方式来更新DB。 二、Redis数据结构2.1 Redis常用的数据结构有哪些？ 5种基本数据结构：String（字符串）、List（列表）、Hash（散列）、Set（集合）、Zset（有序集合）。 3种特殊数据结构：HyperLogLogs（基数统计）、Bitmap（位存储）、Geospatial（地理位置）。 2.2 String的应用场景有哪些？String是一种二进制安全的数据结构，可以用来存储任何类型的数据，比如字符串、整数、浮点数、图片（图片的base64编码或解码或图片的路径）、序列化后的对象。 常规数据的缓存，比如session、token、序列化后的对象、图片的编码或路径等。 计数，比如用户单位时间的请求数、页面单位时间的访问数等。 分布式锁。 2.3 存储对象数据使用String还是Hash更好？ String存储的是序列化后的对象数据、存储的是整个对象。Hash是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或添加部分字段。如果对象中的某些字段需要经常变动或需要单独查询对象中某些字段信息，就更适合用Hash。 String存储相对来说更节省内存，缓存相同数量的对象数据，String消耗的内存约是Hash的一半。并且存储具有多层嵌套的对象时也方便很多。 总结：绝大多数情况下，更建议使用String来存储对象数据。 2.4 Redis数据结构的底层实现2.4.1 String的底层实现了解吗？Redis虽然是基于C语言编写的，但是Redis中的String类型的底层并不是C语言中的字符串，而是作者自己编写了SDS（简单动态字符串）作为底层实现的。 SDS相比于C语言的字符串有以下提升： 可以避免缓冲区溢出：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。 获取字符串长度的复杂度较低： C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。 减少内存分配次数：为了避免修改（增加&#x2F;减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。 二进制安全：C 语言中的字符串以空字符 \\0 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。 2.4.2 List的底层实现了解吗？List 类型的底层数据结构是由压缩列表或双向链表实现的： 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构； 如果列表的元素不满足上面的条件，Redis 会使用双向链表作为 List 类型的底层数据结构； 在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。 2.4.3 Hash的底层实现了解吗？Hash 类型的底层数据结构是由压缩列表或哈希表实现的： 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的底层数据结构。 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 Redis中的Hash也是采用链地址法解决hash冲突，但是并没有采用红黑树。其底层定义了2个Hash表，目的就是rehash。 在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。 随着数据逐步增多，触发了 rehash 操作，这个过程分为三步： 给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍； 将「哈希表 1 」的数据迁移到「哈希表 2」 中； 迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。 渐进式rehash为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。 渐进式 rehash 步骤如下： 给「哈希表 2」 分配空间； 在 rehash 进行期间，每次哈希表元素正常进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。 rehash触发的条件是什么？rehash触发的条件与负载因子有关，负载因子 = hash表中已保存元素的数量 / hash表的大小 当负载因子 &gt;&#x3D; 1，并且Redis没有执行RDB快照或AOF重写时，就会进行rehash操作； 当负载因子 &gt;&#x3D; 5时，说明此时hash冲突已经非常严重了，不论此时有没有在执行RDB快照和重写AOF，都会强制进行rehash操作； 2.4.4 Set的底层实现了解吗？Set 类型的底层数据结构是由整数集合或哈希表实现的： 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构； 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。 2.4.5 ZSet的底层实现了解吗？Zset 类型的底层数据结构是由压缩列表或跳表实现的： 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构； 如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构； 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 2.5 压缩列表和跳表的实现原理了解吗？2.5.1 压缩列表的原理1、压缩列表的优缺点优点： 是一种内存紧凑型的数据结构，占用一块连续的内存空间； 能充分利用CPU缓存，节省内存开销； 缺点： 不能保存过多的元素，否则查询效率就会降低； 新增或修改元素时，内存空间需要重新分配，可能会引发连锁更新的问题； 2、压缩列表结构压缩列表结构 压缩列表在表头有三个字段： zlbytes，记录整个压缩列表占用内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。 所以在压缩列表中查找第一个或最后一个元素，可以直接通过表头的三个字段直接定位，时间复杂度是O(1)。 在查找其他元素时，就需要遍历查找，时间复杂度是O(n)，因此压缩列表不适合保存过多的元素。 3、压缩列表节点结构 压缩列表节点包含三部分内容： prevlen，记录了「前一个节点」的长度，目的是为了实现从后向前遍历； encoding，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。 data，记录了当前节点的实际数据，类型和长度都由 encoding 决定； 压缩列表之所以能节省内存空间，是因为会通过prevlen和encoding两个元素中的信息根据数据大小和类型进行不同的空间分配方法。 4、压缩列表中的连锁更新问题了解吗？因为压缩列表占用的是一整块连续的内存空间，所以在新增或修改元素时，如果空间不够，就会导致后续整个压缩链表元素所占用的空间都会发生变化，每个元素的空间都需要重新分配，从而引起连锁更新问题。 2.5.2跳表的原理链表在查找元素的时候，查询效率非常低，时间复杂度是O(N)。 跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，能快速定位数据，支持平均 O(logN) 复杂度的节点查找。 1、跳表的结构跳表结构 跳表就能让链表拥有近乎的接近二分查找的效率的一种数据结构，其原理依然是给上面加若干层索引，优化查找速度。 12345typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; unsigned long length; int level;&#125; zskiplist; 跳表结构里包含了： 跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点； 跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量； 跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量； 跳表节点的结构里包含了： 元素值 元素权重值 后向指针：指向前一个节点 level数组：用来保存每层的前向指针和跨度 2、跳表的查询过程跳表查询过程 跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件： 如果当前节点的权重 &lt; 要查找的权重时，跳表就会访问该层上的下一个节点。 如果当前节点的权重 &#x3D; 要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。 如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针; 然后沿着下一层指针继续上述步骤查找，这就相当于跳到了下一层接着查找。 3、跳表层数设置**跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)**。 跳表在创建节点的时候，会生成一个随机数，如果随机数 &lt; 0.25，层数就加一层，然后继续生成随机数，知道随机数的结果大于0.25，就最终确定该节点的层数。 这种做法相当于每增加一层的概率不超过25%，层数越高，概率越小。 Redis可以通过ZSKIPLIST_MAXLEVEL 定义最大层高数。 2.5.3 为什么ZSet用跳表，不用平衡树或红黑树？ 从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。 2.5.4 跳表各个操作的时间复杂度是多少？ 查找操作：时间复杂度是O(logN)； 插入操作：每层索引中插入的复杂度是O(1)，所以整个插入的时间复杂度是O(logN)； 删除操作：删除操作包含两个步骤，分别是查找和删除，所以删除的时间复杂度是2O(logN)，忽略常熟部分，也就是O(logN)； 2.6 购物车信息是用String还是Hash存储更好？上面2.3中分析过了，由于购物车中的商品频繁需要修改和变动，所以购物车信息建议使用Hash存储： 用户ID为Key 商品ID为field，商品数量为Value Hash维护简单的购物车信息 2.6.1 用户购物车信息的维护具体应该怎么操作？ 用户添加商品就是往Hash里面添加field和value； 查询购物车信息就是遍历Hash； 更改商品数量就修改对应的value值； 删除商品就是删除Hash中对应的field； 清空购物车就直接删除对应Key； 2.7 用Redis实现一个排行榜怎么做？可以用到Redis中的Zset数据结构，可以实现各种排行榜，比如送礼物排行榜、微信步数排行榜、段位排行榜等等。 其中一些常见的Redis命令：ZRANGE（从小到大排序）、ZREVRANGE（从大到小排序）、ZREVRANK（指定元素排序）。 2.8 Set的应用场景是什么？Redis 中 Set 是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet 。 存放数据不能重复的场景。比如文章点赞、动态点赞等等。 需要获取多个数据源交集、并集和差集的场景。比如共同好友、共同粉丝、共同关注、好友推荐等等。 需要随机获取数据源中的元素。比如抽奖系统、随机点名等等。 2.9 如何用Set实现抽奖系统？ SADD key member1 member2 ...：向指定集合添加一个或多个元素。 SPOP key count：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的情况。 SRANDMEMBER key count：随机获取指定集合中指定数量的元素，适合运行重复中奖的情况。 2.10 如何用Bitmap统计活跃用户？Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。 可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。 如果想要使用 Bitmap 统计活跃用户的话，可以使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。 初始化数据： 123456SETBIT 20210308 1 1(integer) 0SETBIT 20210308 2 1(integer) 0SETBIT 20210309 1 1(integer) 0 统计 20210308~20210309 总活跃用户数: 1234BITOP and desk1 20210308 20210309(integer) 1BITCOUNT desk1(integer) 1 统计 20210308~20210309 在线活跃用户数: 1234BITOP or desk2 20210308 20210309(integer) 1BITCOUNT desk2(integer) 2 三、Redis持久化机制3.1 说一说Redis支持的持久化机制？ 快照（RDB） 只追加文件（AOF） RDB和AOF的混合持久化（Redis 4.0新增） 3.2 RDB持久化3.2.1 什么是RDB持久化？Redis 可以通过创建快照来获得存储在内存里面的数据在 某个时间点 上的副本。 Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。 快照持久化是 Redis 默认采用的持久化方式，在 redis.conf 配置文件中默认有此下配置： 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发bgsave命令创建快照。save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发bgsave命令创建快照。save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发bgsave命令创建快照。 3.2.2 RDB创建快照时会阻塞主线程吗？Redis提供了两个命令来生成RDB快照文件： save：同步保存操作，会阻塞Redis主线程； bgsave：fork出一个子进程，子进程执行，不会阻塞Redis主线程，默认选项。 3.3 AOF持久化3.3.1 什么是AOF持久化？与RDB持久化相比，AOF持久化的实时性更好。 默认情况下Redis没有开启AOF，但是Redis 6.0之后默认是开启的。 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 server.aof_buf 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ fsync策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的。 3.3.2 AOF的基本流程？ 命令追加：所有的写命令会追加到AOF缓冲区中。 文件写入：将AOF缓冲区的数据写入到AOF文件中。这一步需要调用writer函数，将数据写入到系统内核缓冲区后直接返回。（此时并没有同步到磁盘） 文件同步：AOF缓冲区根据对应的持久化方式向磁盘做同步操作。 文件重写：随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。 重启加载：当Redis重启时，可以加载AOF文件进行数据恢复。 AOF 工作基本流程 3.3.3 持久化方式有哪些？Redis配置文件中有三种不同的AOF持久化方式： appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。 appendfsync everysec ：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒） appendfsync no ：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。 可以看出：这 3 种持久化方式的主要区别在于 fsync 同步 AOF 文件的时机（刷盘）。 3.3.4 AOF为什么是在执行完命令后记录日志？关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。 AOF 记录日志过程 避免额外的检查开销，AOF记录日志不会对命令进行语法检查； 在命令执行完之后再记录，不会阻塞当前命令执行。 缺点： 如果刚执行完命令Redis就宕机，会导致对应的修改丢失； 可能会阻塞后续其他命令的执行，因为AOF记录日志是在Redis主线程中进行的。 3.3.5 AOF文件重写了解吗？当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。 AOF 重写 由于 AOF 重写会进行大量的写入操作，为了避免对 Redis 正常处理命令请求造成影响，Redis 将 AOF 重写程序放到子进程里执行。 AOF 文件重写期间，Redis 还会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。 3.4 Redis 4.0对持久化机制做了什么优化？由于 RDB 和 AOF 各有优势，于是，Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。 这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。 当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 3.5 如何选择RDB和AOF？3.5.1 RDB的优势 RDB文件存储的内容是经过压缩的二进制数据，保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。 使用RDB文件恢复数据，直接解析还原数据即可，不需要一条条地执行命令，速度非常快。 3.5.2 AOF的优势 AOF的数据安全性更高，可以实时或秒级持久化数据。RDB会对机器的CPU资源和内存资源产生严重的影响。 RDB可能会存在版本不兼容的问题。 AOF以一种易于理解和解析的格式包含所有操作的日志。方便导出AOF文件进行分析。 总结： Redis保存的数据丢失一些也没有影响的话，可以使用RDB； 不建议单独使用AOF，因为时不时创建一个RDB快照可以进行数据库备份、更快的重启以及解决AOF引擎错误。 如果保存的数据要求安全性比较高的话，建议同时开启RDB和AOF持久化或者开启混合持久化。 四、Redis线程模型4.1 Redis单线程模型了解吗？Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。 4.1.1 既然是单线程，那怎么监听大量的客户端连接呢？Redis通过IO多路复用来监听来自客户端的大量连接，将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。 优点：I&#x2F;O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗。 文件事件处理器主要包含4个部分： 多个socket（客户端连接） IO多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将socket关联到相应的事件处理器） 事件处理器（连接应答、命令请求、命令回复） Redis的网络模型就是使用了IO多路复用 + 时间分派器来应对多个Socket请求，比如连接应答、命令请求、命令回复。 在Redis 6.0之后，为了更好地提高性能，命令回复处理器使用了多线程来处理回复事件，命令请求处理器中的命令转换也使用了多线程，增加命令转换速度。 文件事件处理器（file event handler） 4.2 Redis是单线程的，那为什么还这么快？ Redis的大部分操作都是在内存中完成，因此Redis读取速度只跟计算机内存或者网络带宽有关； Redis采用单线程可以避免多线程之间的竞争，避免了多线程切换带来的时间和性能开销； Redis采用IO多路复用处理请求； 4.2.1 解释一下什么是IO多路复用？IO多路复用其实就是用单个线程同时监听多个Socket，并且在某个Socket可读写时通知，从而避免无效等待，充分利用CPU资源。 目前的IO多路复用都是采用epoll模式实现的，它会在通知用户进程Socket就绪的同时，把已就绪的Socket写入用户空间，不用挨个遍历找是哪个Socket就绪了，提升了性能。 4.3 Redis 6.0之前为什么不使用多线程？虽然Redis是单线程模型，但是实际上Redis在4.0之后的版本中就已经加入了对多线程的支持。 单线程编程容易，并且更容易维护； Redis的性能瓶颈不在CPU，而在于内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能； 4.4 Redis 6.0之后为什么引入了多线程引入多线程主要是为了提高网络IO读写性能。但是对于命令的执行，Redis仍然采用单线程来处理。 Redis 6.0的多线程默认是禁用的，只使用主线程。 五、Redis内存管理5.1 为什么Redis要给缓存设置过期时间？因为内存是有限的，如果缓存中的数据一直保存的话，会造成内存溢出，所以设置过期时间有助于环节内存消耗。 5.1.1 设置过期时间除了缓解内存消耗还有什么用？很多时候，业务场景对于某些数据的需求只在某段时间内存在，比如说短信验证码只在一分钟内有效、用户登录的token只在一天内有效等等。如果使用传统的数据库来处理的话，一般还需要自己判断是否过期，这样会导致数据库性能差很多，而且很麻烦。 5.2 Redis如何判断数据是否过期？Redis通过一个过期字典（可以看做是hash表）来保存数据过期时间。过期字典的key指向Redis数据库中的某个key，过期字典的value是一个long long型整数，这个整数保存了key所指向的数据库key的过期时间。 Redis过期字典 过期字典是存储在redisDb这个结构中： 1234567typedef struct redisDb &#123; ... dict *dict; //数据库键空间,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ...&#125; redisDb; 5.3 过期数据的删除策略了解吗？Q：加入设置了一批key只能存活1分钟，那么一分钟后Redis是怎么对这批key进行删除的呢？ 常用的过期数据删除策略就两个： 惰性删除：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期key没有被删除。 定期删除：每隔一段时间抽取一批key执行删除过期key操作。并且，Redis底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 惰性删除对CPU更友好。定期删除对内存更友好。所以Redis采用的是惰性删除+定期删除。 但是以上两种删除策略还是可能存在遗漏很多过期key的情况，这样同样会造成内存溢出的情况。 怎么解决这个问题呢？ Redis内存淘汰机制 5.4 Redis的内存淘汰机制了解吗？Q：MySQL中有2000w条数据，Redis中只有20w条数据，如何保证Redis中的数据都是热点数据？ Redis提供了6中数据淘汰策略： volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（最常用） allkeys-random：从数据集中任意选择数据淘汰。 no-eviction：禁止驱除数据，当内存不足时，不准新写入数据。 Redis 4.0之后增加了两种淘汰策略： volatile-lfu：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰。 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。 六、Redis事务6.1 什么是Redis事务？Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。 Redis 事务实际开发中使用的非常少，功能比较鸡肋，不建议在日常开发中使用，不要将其和我们平时理解的关系型数据库的事务混淆了。 6.2 如何使用Redis事务？ 开始事务，使用MULTI 命令入队，批量操作Redis命令，按照先进先出顺序 执行事务，使用EXEC 6.3 Redis事务支持原子性吗？不支持！Redis事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常正常执行。并且Redis事务是不支持回滚操作的，因此，Redis是不支持原子性。 6.4 Redis事务支持持久性吗？支持！Redis支持三种持久化方式：RDB、AOF和混合持久化。 6.5 Redis事务支持回滚吗？Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。 七、Redis性能优化7.1 使用批量操作减少网络传输一个Redis命令的执行可以简化为4步： 发送命令； 命令排队； 命令执行； 返回结果。 其中第一步和第四步耗费时间之和成为RTT（往返时间），也即数据在网络上传输的时间。 使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少RTT。 7.2 大量key集中过期的问题对于过期的key，Redis采用的是定期删除+惰性删除策略。 那么在定期删除的过程中，如果遇到大量key集中过期问题怎么解决呢？ 给key设置随机过期时间。 开启lazy-free（惰性删除&#x2F;延迟释放）。让Redis采用异步方式延迟释放key使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 7.3 Redis bigkey7.3.1 什么是bigkey？简单来说，如果一个key对应的value所占用的内存较大，那么这个key就可以看做是bigkey。 那具体要占多大才算大呢？ String类型的value超过10kb，其他类型的value包含的元素超过5000个。 7.3.2 bigkey有什么危害？ 客户端超时阻塞：由于Redis执行命令是单线程处理，然后在操作大key时会比较耗时，阻塞其他命令的执行； 引发网络阻塞：每次获取大key产生的网络流量较大，如果一个key的大小是1MB，每次访问量是1000，那么每秒会产生1000MB的流量，这对普通千兆网卡的服务器是灾难性的； 阻塞工作线程：如果使用del命令删除大key时，会阻塞工作线程，这样没法处理后续命令； 内存分布不均，集群模型在slot分片均匀情况下，会出现数据和查询倾斜情况，部分有大key的Redis节点占用内存多，QPS也会比较大。 7.3.3 如何发现bigkey？ 使用Redis自带的--bigkeys命令来查找，最好在从节点或者业务低峰阶段进行扫描，以免影响正常运行的业务； 使用scan命令查找bigkey，该命令会对数据库进行扫描，然后用type命令获取返回的每一个key的类型。 使用RdbTools工具分析RDB文件，找到其中的bigkey。比如可以将大于10kb的所有key输出到一个表格中； 7.3.4 如何避免大Key呢？ 在设计阶段把大key拆分成一个个小key； 定期检查Redis中是否存在大key，删除的时候不要用del命令删除，因为会阻塞主线程，而是使用unlink命令删除大key。 7.3.5 为什么要用unlink命令删除大key呢？因为del命令删除是一个同步命令，其删除操作会阻塞主线程的操作，而unlink命令会异步地删除指定的值。 unlink会先将要删除的键添加到一个待删除的列表中，并且立即返回，不会阻塞主线程的操作。然后Redis服务器会在后台异步地删除待删除列表中的值。 7.4 Redis内存碎片7.4.1 什么是内存碎片？简单来说，内存碎片就是不可用的空闲内存。 举个例子：操作系统为你分配了 32 字节的连续内存空间，而你存储数据实际只需要使用 24 字节内存空间，那这多余出来的 8 字节内存空间如果后续没办法再被分配存储其他数据的话，就可以被称为内存碎片。 内存碎片 7.4.2 为什么会有Redis内存碎片？ Redis存储数据的时候想操作系统申请的内存空间可能会大于实际需求的存储空间。（要多了） 频繁修改Redis中的数据。 7.4.3 如何查看Redis内存碎片信息？可以使用info memory命令查看Redis内存相关信息。 Redis内存碎片率的计算公式： mem_fragmentation_ratio （内存碎片率）&#x3D; used_memory_rss (操作系统实际分配给 Redis 的物理内存空间大小)&#x2F; used_memory(Redis 内存分配器为了存储数据实际申请使用的内存空间大小) 多大的内存碎片率才需要清理呢？ 通常情况下，我们认为 mem_fragmentation_ratio &gt; 1.5 的话才需要清理内存碎片。 mem_fragmentation_ratio &gt; 1.5 意味着你使用 Redis 存储实际大小 2G 的数据需要使用大于 3G 的内存。 7.4.4 如何清理Redis内存碎片？Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。 直接通过 config set 命令将 activedefrag 配置项设置为 yes 即可。 八、Redis生产问题8.1 缓存穿透一句话：穿透穿透，就是把缓存和数据库都穿透了。 8.1.1 什么是缓存穿透？简单来说，就是大量请求的key是不合理的，根本不存在于缓存中，也不存在与数据库中。 这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，甚至会直接宕机。 缓存穿透 举个例子：某个黑客故意制造一些非法的 key 发起大量请求，导致大量请求落到数据库，结果数据库上也没有查到对应的数据。也就是说这些请求最终都落到了数据库上，对数据库造成了巨大的压力。 8.1.2 如何解决缓存穿透？最基本的就是要做好参数校验，一些不合法的参数请求直接抛出异常给客户端。 1. 缓存无效key如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，这种方式可以解决请求的 key 变化不频繁的情况。 2. 布隆过滤器通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。 具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。 加入布隆过滤器之后的缓存处理流程图 但是，需要注意的是布隆过滤器可能会存在误判的情况。 总结： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。 布隆过滤器的原理： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（可能会有多个，因为有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为1. 当需要判断一个元素是否存在于布隆过滤器的时候： 对给定元素再次进行相同的哈希计算； 得到值后判断位数组中的每个元素是否都为1，如果值都为1，那说明这个值在布隆过滤器中，只要有一个值不为1，说明该元素不在。 所以，一定会出现不同的字符串可能哈希计算出的位置相同，所以会导致说某个元素存在，但其实不存在。 8.2 缓存击穿一句话：击穿击穿，就是打穿了缓存，对数据库定点打击。 8.2.1 什么是缓存击穿？请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 缓存击穿 举个例子 ：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。 8.2.2 如何解决缓存击穿？ 设置热点数据永不过期或过期时间较长。 针对热点数据提前预热，将其存入缓存中，并设置合理的过期时间。比如秒杀场景中，数据在秒杀结束前都不会过期。 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。 8.3 缓存穿透和缓存击穿有什么区别？缓存穿透中，请求的key既不存在于缓存中，也不在数据库中。 缓存击穿中，请求的key对应的是热点数据，存在于数据库中，但是不存在于缓存中。 8.4 缓存雪崩一句话：雪崩雪崩，就是缓存崩了，导致请求像雪崩一样落在数据库上。 8.4.1 什么是缓存雪崩？缓存在同一时间大面积失效，导致大量的请求直接落到数据库上，对数据库造成巨大压力。 缓存雪崩 举个例子 ：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力。 8.4.2 如何解决缓存雪崩？1. 针对Redis服务不可用的情况 采用Redis集群，避免单机出问题整个缓存服务都无法使用的情况。 限流，避免同时处理大量的请求。 2. 针对热点缓存失效的情况 设置不同的失效时间，比如随机设置缓存失效时间。 缓存永不失效（不推荐）。 设置二级缓存。 8.5 缓存击穿和缓存雪崩有什么区别？两者比较类似，缓存雪崩的原因是缓存中大量或所有数据失效，缓存击穿导致的原因主要是某个热点数据不存在于缓存中。 8.6 怎么保证Redis和Mysql数据一致性？常规的方法有两种： 先更新数据库，再删除缓存； 先删除缓存，再更新数据库。 第一种方式下，如果缓存更新失败，也会导致数据不一致；第二种方式下，理想情况是可以保证数据一致性的，但是在极端情况下，删除缓存的操作并不是原子操作，所以其他线程此时来访问redis，还是会出现数据不一致的情况。 所以如果要保证Redis和MySQL的数据一致性，有两种情况，分别是强一致性情况和允许延迟一致性情况。 对于要求强一致性的业务，可以采用redisson提供的读写锁来实现双写一致性，保证同一时间只运行一个请求更新缓存； 读锁可以使其他线程共享读操作； 写锁可以拒绝其他线程的写操作； 对于允许延迟一致性的业务，可以采用异步的方案同步数据，以下两种都属于先更新数据库，再删除缓存的方法： 使用MQ消息中间件，更新数据后，通知缓存删除，如果删除失败，就继续读取数据重新删除，这就是重试机制，借助重试机制删除缓存。当删除成功，就把数据从消息队列中移除； 利用canel中间件，可以不修改业务代码，通过读取数据库的binlog日志数据，再去更新缓存； 8.6.1 什么是延迟双删？其实就是“先删除缓存，再更新数据库”的具体实现数据一致性的方法，其主要步骤有四个： 删除Redis缓存数据； 更新数据库数据； 延时sleep； 删除Redis缓存数据； 8.6.2 为什么要删除缓存数据，而不是更新？在复杂的业务场景下，如果缓存的内容涉及到关联多个数据库表，那么为了修改缓存数据，需要查询多个关联表，再进行计算和修改更新，此时的更新缓存就显得没有必要了，因为直接删除会更快。如果缓存都更新后，却没有用上，那更是浪费时间，所以删除更能提高缓存的利用效率，减少复杂度。 8.6.3 为什么延迟双删需要sleep一段时间呢？如果事务1进行数据库A&#x3D;10进行+1操作，当有其他事务2在该时间段内进行查询操作时，因为这时候事务A对数据库的写操作还没结束，这时候事务2读到的是旧数据A&#x3D;10。 如果事务1在写入数据库后，此时A&#x3D;11，然后直接进行Redis的删除，这时候事务2在事务1删除Redis后更新了Redis，使A还等于10，那么这样就导致了数据库和缓存的数据不一致。 后面事务以后每次读取时读到的都是A&#x3D;10的脏数据，直到Redis过期。 出问题的原因是什么，就是因为有事务2在事务1写入数据库的时间段内读取了数据库后，更新了缓存，导致其他时间段内都不会发生不一致的问题。 所以事务1才需要延时一段时间之后，对Redis进行再删除操作，避免其他事务对Redis的更新影响数据一致性问题。 而 延时时间 = 事务2读数据的时间 + 事务2更新缓存的时间 这时候事务1在第二次删除Redis前，事务2已经更新了Redis，保证了事务1一定能删除掉事务2的脏数据。这样就保证了最终的Redis和MySQL数据的一致性 九、Redis集群Redis中提供的集群方案总共有三种：主从复制、哨兵模式、分片集群。 9.1 什么是主从复制？主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master&#x2F;leader)，后者称为从节点(slave&#x2F;follower)； 数据的复制是单向的，只能由主节点到从节点。Master 以写为主，Slave 以读为主。默认情况下，每台 Redis 服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 9.2 主从复制的作用？ 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复。 负载均衡：由主节点提供写服务、从节点提供读服务，分担服务器负载，提高Redis服务器的并发量。 集群基础：主从复制还是哨兵和集群能够实施的基础。 9.3 一主二从主从复制，读写分离！ 80% 的情况下都是在进行读操作！减缓服务器的压力！架构中经常使用！ 一主二从！主机可以写，从机不能写只能读！主机中的所有信息和数据，都会自动被从机保存！ Slave 启动成功连接到 master 后会发送一个 sync 同步命令 Master 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master 将传送 整个数据文件到 slave，并完成一次完全同步。 9.3.1 数据的同步方式 全量复制：用于初次复制或其它无法进行部分复制的情况，将主节点中的所有数据都发送给从节点。当数据量过大的时候，会造成很大的网络开销。 增量复制：只复制新增的数据，也就是 master 变化不大，被更改的指令都保存在内存时，会触发增量复制。 9.4 哨兵模式哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个 独立的进程，作为进程，它会独立运行。 其原理是哨兵通过发送命令，等待 Redis 服务器响应，从而监控运行的多个 Redis 实例。 如果故障了根据投票数自动将从节点转换为主节点。 通过哨兵模式，可以监控主从服务器，并提供主从节点故障转移功能。 哨兵模式 9.4.1 优点 哨兵集群，基于主从复制模式，拥有所有主从配置的优点。 主从可以切换，故障可以转移，系统可用性更好。 哨兵模式就是主从模式升级，手动到自动。 9.4.2 缺点 Redis不好在线扩容，一旦集群容量达到上线，扩容十分麻烦。 哨兵模式配置十分麻烦。 9.4.3 Redis的哨兵模式是怎么知道有多少节点的呢？可以通过哨兵的自动发现机制实现的。 一般情况下，哨兵节点每10秒向主从节点发送INFO命令，以此获取主从节点的信息。在第一次执行的时候，哨兵仅知道我们给出的主节点信息，通过对主节点执行INFO命令就可以获取其从节点列表。这样周期性的循环，就可以不断地发现新加入的节点。 9.4.4 Redis哨兵之间是怎么知道彼此的呢？因为哨兵可以通过INFO命令发现主节点和从节点的信息，而Redis提供了一种发布订阅的消息通信模式，哨兵们就是通过一个约定好的频道发布&#x2F;订阅信息进行通信： 每隔2秒，每个哨兵就会通过它监控的主节点、从节点向频道发送一条hello消息； 每个哨兵会通过它监控的主节点、从节点订阅频道的消息，以此来接收其他哨兵发布的消息。 9.4.5 Redis哨兵是怎么判断节点的服务状态的呢？主要是基于心跳机制监测服务状态，每隔1秒，想集群中的每个实例发送ping命令： 主观下线：如果某个哨兵发现某个实例没有在规定时间响应，就认为该实例主观下线； 客观下线：若超过指定数量（一般是哨兵数量的一半）的哨兵都认为该实例主观下线，那么就可以认为该实例客观下线； 9.4.6 Redis哨兵是怎么推举出新的主节点呢？ 判断每个从节点与主节点断联时间的长短，时间越长就说明该从节点的数据与最新的数据差异较大，排除该节点； 判断从节点的slave-priority值，也即从节点的优先级，值越小，优先级越高； 如果优先级相同，就会判断offset值，值越大说明与主节点数据越接近，其优先级越高； 判断从节点运行id的大小，越小优先级越高； 9.5 集群出现脑裂该怎么解决？脑裂其实就是由于网络问题，集群节点之间失去联系。主从数据不同步；哨兵重新平衡选举，产生两个主节点，这就是集群的脑裂。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。 解决方法可以在redis中设置两个参数： 设置主节点最少连接的从节点个数，如果从节点数小于这个数，就禁止主节点写数据； 设置主从复制和同步的延迟时间，当超过一定时间时，就禁止主节点写数据。 9.6 分片集群有什么用？当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 Redis 分片集群（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。 集群中有多个主节点，每个主节点保存不同数据，并且还可以给每个主节点设置多个从节点，继续增大集群的并发能力。同时每个主节点之间通过ping检测彼此健康状态，有点类似于哨兵模式。当客户端请求访问集群时，会被转发到正确的节点。 分片集群中不再需要哨兵，由主节点就可以起到哨兵的作用。 9.6.1 分片集群中数据怎么存储和读取的？一个分片集群共有16384个哈希槽，集群中每个主节点绑定了一定范围内的哈希槽，key通过CRC16校验后对16384取模来决定放在哪个槽存储。 比如有三个主节点，如图所示： 分片集群 读取的过程也是一样的。","tags":["Java","八股","基础","面试","Redis"],"categories":["Java八股","基础"]},{"title":"6.MySQL","path":"/2023/06/29/6-MySQL/","content":"一、MySQL基础1.1 什么是关系型数据库？关系型数据库（RDBMS，Relational Database Management System）就是一种建立在关系模型的基础上的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。 关系型数据库中，我们的数据都被存放在了各种表中（比如用户表），表中的每一行就存放着一条数据（比如一个用户的信息）。 关系型数据库表关系 1.1.1 常见的关系型数据库 MySQL：由Oracle公司开发，是目前应用最广泛的开源数据库之一。 Oracle：由Oracle公司开发，是企业级应用中最为常用的数据库之一。 SQL Server：由Microsoft公司开发，是企业级应用中较为常用的数据库之一。 PostgreSQL：是一种功能强大的开源关系型数据库，具有良好的数据完整性和安全性。 DB2：由IBM公司开发，是一种可扩展的、高效的企业级关系型数据库。 SQLite：是一种轻型关系型数据库，适用于嵌入式设备和移动应用程序。 MariaDB：由MySQL的创始人开发，是一个社区驱动的关系型数据库管理系统。 Sybase：由SAP公司开发，是一种可扩展的、高效的企业级关系型数据库。 1.2 什么是SQL？SQL 是一种结构化查询语言(Structured Query Language)，专门用来与数据库打交道，目的是提供一种从数据库中读写数据的简单有效的方法。 1.3 什么是MySQL？MySQL是一种关系型数据库，主要用于持久化存储我们的系统中的一些数据，比如用户信息。 1.4 MySQL的优点？ 开源免费； 成熟稳定，功能完善； 文档丰富，社区活跃，生态完善； 开箱即用，操作简单，维护成本低； 兼容性好，支持主流的常见操作系统，支持多种开发语言； 事务支持优秀； 支持分库分表、读写分离、高可用； 1.5 MySQL三大范式了解吗？ 第一范式：遵循原子性，即表中字段的数据，不能再拆分。比如：一个表中地址字段为xx省xx市xx区，那么就不遵守第一范式，因为这个地址字段还可以再继续拆分为省、市、区三个字段。 第二范式：遵循唯一性，即表中任意一个主键可以确定除主键外的所有非主键值。更简单讲的话就是：一个表只能描述一件事。比如一个表中如果有学号、姓名、年龄、选修课程、成绩、学分等字段，那么这个表就不遵守第二范式，因为如果用学号做主键，只能确定姓名和年龄，不能确定选修的课程和成绩。正确的做法是将这个表拆分为学生表、课程表、成绩表，使得每个表只描述一件事。 第三范式：消除传递依赖，即任一主键都可以确定所有非主键字段的值，不存在通过非主键字段A确定非主键字段B。比如一个表中有学号、姓名、班级、班主任四个字段，通过主键学号可以唯一的确定其他所有字段的信息，但是在非主键字段中，我们也可以通过班级推导出唯一的班主任，所以这就不满足第三范式。正确的做法是将该表拆分为学生表和班级表，就可以消除传递依赖。 1.6 MySQL增删改查的具体语句 增：INSERT INTO table_name (column1, column2, column3, ...) VALUES (value1, value2, value3, ...); 删：DELETE FROM table_name WHERE condition; 改：UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE condition; 查：SELECT column1, column2, ... FROM table_name WHERE condition; 二、MySQL基础架构MySQL架构 从上图的架构图可以看出，MySQL主要由以下几部分构成： 连接器：身份认证和权限相关（登录MySQL）； 查询缓存：执行查询语句的时候，会先查询缓存（但是在8.0版本后移除，因为不太实用）； 分析器：没有命中缓存的话，SQL语句就会经过分析器，对SQL语句进行词法分析和语法分析； 优化器：按照MySQL认为最优的方案去执行。 执行器：执行语句，然后从存储引擎返回数据。执行语句之前会判断是否有权限； 插件式存储引擎：主要负责数据的存储和读取，采用的是插件式架构。 2.1 SQL语句在MySQL中执行的过程？MySQL主要分为Server层和存储引擎层。 Server 层主要负责建立连接、分析和执行SQL语句：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。 存储引擎层主要负责数据的存储和提取： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。 2.1.1 查询语句的执行流程如下 连接器：建立连接，管理连接、校验用户身份； 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划； 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端； 更新语句执行流程如下：分析器—-&gt;权限校验—-&gt;执行器—&gt;引擎—redo log(prepare 状态)—&gt;binlog—&gt;redo log(commit 状态) 2.2 MySQL读取数据的方式有哪些？ SQL查询语句：使用SELECT语句来查询数据库中的数据。这是最常见和基本的方式，可以使用不同的SELECT语句来检索所需的数据。 视图：视图是虚拟的表，它们基于一个或多个表的查询结果。您可以像查询表一样查询视图，但视图本身不包含实际数据，而是动态生成。 JDBC（Java数据库连接）：Java编程语言可以使用JDBC来连接MySQL数据库，并通过编写Java代码来读取和处理数据。 导入和导出工具：MySQL提供了导入和导出工具，如mysqldump和mysqlimport，用于将数据从文件导入数据库或将数据库数据导出到文件。 三、MySQL存储引擎3.1 MySQL支持那些存储引擎？默认使用哪个？MySQL支持多种存储引擎，可以通过show engines命令查看。 查看 MySQL 提供的所有存储引擎 从上图可以看出，默认引擎是InnoDB。并且所有的存储引擎中只有InnoDB是事务性存储引擎，也即只有InnoDB支持事务存储； 3.2 MySQL存储引擎架构了解吗？MySQL 存储引擎采用的是 插件式架构 ，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。 存储引擎是基于表的，而不是数据库。 3.3 MylSAM和InnoDB有什么区别？MySQL 5.5之前，使用的默认引擎是MylSAM，但是不支持事务和行级锁，而且崩溃后无法安全恢复； MySQL 5.5之后，使用的默认引擎是InnoDB。 MylSAM只支持表级别的锁粒度，InnoDB支持行级别的锁粒度。 MylSAM不提供事务支持，InnoDB提供事务支持，实现了SQL标准定义了四个隔离级别。 MylSAM不支持外键，InnoDB支持外键。 MylSAM不支持MVCC(多版本并发控制)，InnoDB支持。 MyISAM 和 InnoDB 都是使用 B+Tree 作为索引结构，但是InnoDB 的数据文件本身就是索引文件，而MyISAM，索引文件和数据文件是分离的。 MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。 InnoDB 的性能比 MyISAM 更强大。 四、MySQL索引索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。 索引底层数据结构存在很多种类型，常见的索引结构有: B 树， B+树 和 Hash、红黑树。在 MySQL 中，无论是 Innodb 还是 MyIsam，都使用了 B+树作为索引结构。 4.1 索引的优缺点优点： 大大加快数据的检索速度，减少检索的数据量； 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性； 缺点： 索引的创建和维护需要耗费很多时间，对数据进行增删改的时候，需要动态修改索引，降低SQL的执行效率； 索引需要使用物理文件存储，也会耗费一定空间。 4.1.1 索引一定能提高查询性能吗？大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引不一定能带来性能提升。 4.2 索引的底层数据结构4.2.1 Hash表为什么能通过key快速取出value？原因在于 哈希算法（也叫散列算法）。通过哈希算法，我们可以快速找到 key 对应的 index，找到了 index 也就找到了对应的 value。 为什么MySQL没有使用其作为索引的数据结构？主要是因为 Hash 索引不支持顺序和范围查询。假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引可就不行了。并且，每次 IO 只能取一个。 4.2.2 B树和B+树B 树也称 B-树,全称为 多路平衡查找树 ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 Balanced （平衡）的意思。 目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。 B树和B+树有什么异同？ B树的所有节点既存放key也存放data，而B+树只有在叶子结点存放key和data，其他内节点只存放key。 B树的叶子结点都是独立的；B+树的叶子结点有一条引用链路指向与它相邻的叶子结点。 B树的检索过程相当于对范围内的每个节点的关键字做二分查找，有可能没有到达叶子结点，检索就结束了；而B+树的效率更稳定，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 数据库为什么使用B+树而不是B树？ B树适用于随机检索，而B+树适用于随机检索和顺序检索； B+树的空间利用率更高，因为B树的每个节点要存key和data，而B+树节点只存储key，这样B+树的一个节点就可以存储更多的索引，从而使树的高度变低，减少了IO次数，检索速度更快； B+树的叶子节点都连在一起，所以顺序查找更方便； B+树的性能更稳定。 4.3 常见的索引类型4.3.1 主键索引数据表的主键列使用的就是主键索引。一张数据表有只能有一个主键，并且主键不能为 null，不能重复。 在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。 为什么要使用自增的ID作为主键索引？如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满时，就会自动开辟一个新的页。 如果使用非自增的主键（比如身份证、学号等），由于每次插入主键的值近似于随机插入，因此每次新记录就会被插到现有索引页的中间某个位置，此时 MySQL 就会移动数据，造成频繁的页分裂和页旋转，使得插入速度变慢。 因此，InnoDB 的主键应该尽量使用整型自增的 ID。这样能够在存储和查询上提高效率。 4.3.2 二级索引（辅助索引）二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。 以下四种索引都属于二级索引： 唯一索引(Unique Key) ：唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。 普通索引(Index) ：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。 前缀索引(Prefix) ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。 全文索引(Full Text) ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。 4.3.3 聚簇索引聚簇索引（Clustered Index）即索引结构和数据一起存放的索引，并不是一种单独的索引类型。InnoDB 中的主键索引就属于聚簇索引。 在 MySQL 中，InnoDB 引擎的表中的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。 优点： 查询速度非常快：聚簇索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。相比于非聚簇索引， 聚簇索引少了一次读取数据的 IO 操作。 对排序查找和范围查找优化：聚簇索引对于主键的排序查找和范围查找速度非常快。 缺点： 依赖有序的数据：因为 B+树是多叉平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大：如果索引列的数据被修改时，那么对应的索引也将会被修改，而且聚簇索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。 4.3.4 非聚簇索引非聚簇索引(Non-Clustered Index)即索引结构和数据分开存放的索引，并不是一种单独的索引类型。二级索引(辅助索引)就属于非聚簇索引。MySQL 的 MyISAM 引擎，不管主键还是非主键，使用的都是非聚簇索引。 非聚簇索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。 优点： 更新代价比聚簇索引小 缺点： 依赖有序数据：与聚簇索引一样，非聚簇索引也依赖于有序数据。 可能会二次查询（回表）：当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 存储方式区别 B+树底层 4.3.5 覆盖索引非聚簇索引一定回表查询吗？不一定，比如用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。这种情况就称之为覆盖索引，覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。 什么是索引下推？索引下推（Index Predicate Pushdown）是数据库查询优化的一种技术，它在查询过程中将过滤条件尽可能地推送到索引层级，以减少不必要的数据读取和计算，从而提高查询性能。 索引下推的实现依赖于数据库管理系统的查询优化器，优化器会根据查询条件和索引的结构，判断哪些条件可以在索引层级进行过滤，并将这些条件下推到索引层级。这样，数据库在执行查询时，可以首先应用索引层级的过滤条件，然后再进行数据读取，减少了不必要的数据传输和处理。 4.3.6 联合索引使用表中的多个字段创建索引，就是 联合索引，也叫 组合索引 或 复合索引。 以 score 和 name 两个字段建立联合索引： 1ALTER TABLE `cus_order` ADD INDEX id_score_name(score, name); 4.3.7 最左前缀匹配原则最左前缀匹配原则指的是，在使用联合索引时，MySQL 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询（如 **&gt;、&lt;**）才会停止匹配。对于 &gt;=、&lt;=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配。 所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据。 4.4 正确使用索引的一些建议4.4.1 选择合适的字段创建索引 不为 NULL 的字段 ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。 被频繁查询的字段 ：我们创建索引的字段应该是查询操作非常频繁的字段。 被作为条件查询的字段 ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。 频繁需要排序的字段 ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。 被经常频繁用于连接的字段 ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率 4.4.2 频繁更新的字段慎重建立索引4.4.3 限制每张表的索引数量4.4.4 尽量考虑联合索引而不是单列索引4.4.5 避免冗余索引4.4.6 字符串类型的字段使用前缀索引4.4.7 避免索引失效常见的导致索引失效的情况有： 创建了组合索引，但查询条件未遵守最左前缀匹配原则。在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引。 在索引列上进行计算、函数、类型转换等操作。因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。 以 % 开头的 LIKE 查询比如 like &#39;%abc&#39;。因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。而这中模糊查询查的是后缀，所以不知道从哪个索引开始，只能进行全表查询； 查询条件中使用 or，且or的前后条件中有一个列没有索引，涉及的索引都不会被使用到。因为 or 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。 4.4.8 删除长期未使用的索引五、MySQL事务5.1 什么是事务？事务是逻辑上的一组操作，要么都执行，要么都不执行。 假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作，这两个操作必须都成功或者都失败。 小明账户余额减少1000元 小红账户余额增加1000元 事务会把这两个操作看成一个整体，这两个工作要么一起成功，要么一起失败。这样就不会出现小明余额减少，但小红余额没有增加的情况。 事务示意图 5.2 什么是数据库事务？简单来说，数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：要么全部执行成功,要么全部不执行 。 数据库事务 5.3 事务有哪些特性？ACID 关系型数据库都具有ACID特性： 原子性：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用。 一致性：执行事务前后，数据保持一致。比如转账例子中，无论事务是否成功，转账人和收款人的金额总量是不变的。 隔离性：并发访问数据库时，一个用户的事务不被其他事务所干扰，各事物之间数据库是独立的。 持久性：一个事务被提交后，它对数据库中的数据改变是持久的，即使数据库发生故障也不应该对其有任何影响。 注：只有保证了事务的原子性、隔离性、持久性之后，一致性才能得到保障。也即A、I、D都是手段，C是目的。 AID->C 5.4 数据库事务实现的原理是什么？以MySQL的InnoDB引擎为例， 通过redo log（重做日志）来实现事务的持久性； 通过undo log（回滚日志）来实现事务的原子性； 通过锁机制、MVCC等手段来实现事务的隔离性； 原子性+隔离性+持久性保证了一致性； 5.4.1 redo log和undo log的区别？ redo log记录的是物理页的物理变化，服务器宕机可以用来同步数据； undo log记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据； redo log保证了事务的持久性、undo log保证了事务的原子性； 5.6 并发事务带来了那些问题？5.6.1 脏读一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。 例如：事务 1 读取某表中的数据 A&#x3D;20，事务 1 修改 A&#x3D;A-1，事务 2 读取到 A &#x3D; 19,事务 1 回滚导致对 A 的修改并为提交到数据库， A 的值还是 20。 脏读 5.6.2 丢失修改在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A&#x3D;20，事务 2 也读取 A&#x3D;20，事务 1 先修改 A&#x3D;A-1，事务 2 后来也修改 A&#x3D;A-1，最终结果 A&#x3D;19，事务 1 的修改被丢失。 丢失修改 5.6.3 不可重复读指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 例如：事务 1 读取某表中的数据 A&#x3D;20，事务 2 也读取 A&#x3D;20，事务 1 修改 A&#x3D;A-1，事务 2 再次读取 A &#x3D;19，此时读取的结果和第一次读取的结果不同。 不可重复读 5.6.4 幻读幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 例如：事务 2 读取某个范围的数据，事务 1 在这个范围插入了新的数据，事务 2 再次读取这个范围的数据发现相比于第一次读取的结果多了新的数据。 幻读 5.7 不可重复读和幻读有什么区别？ 不可重复读的重点是内容修改或者记录减少，比如多次读取一条记录发现其中某些记录的值被修改。 幻读的重点在于记录新增，比如多次执行同一条查询语句时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样。 解决方案： 执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全，避免出现不可重复读。 执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。 5.8 并发事务的控制方式有哪些？MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。 锁 控制方式下会通过锁来显示控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。 共享锁（S 锁） ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁） ：又称写锁&#x2F;独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。 5.8.1 解释一下MVCCMVCC 是多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突。 MVCC 在 MySQL 的底层实现所依赖的手段主要是: 隐藏字段、undo log日志、read view读视图。 隐藏字段 trx_id（事务id），用来记录每次一操作的事务id，是自增的； roll_pointer（回滚指针），指向上一个版本的事务版本的地址； undo log 主要作用是记录回滚日志，存储老版本数据； undo log内部会形成一个版本链，多个事务并行操作某一行数据时，记录不同事务修改数据的版本，通过回滚指针形成一个链表； readView 解决的是一个事务查询选择版本的问题，根据readView的匹配规则和事务id判断该访问哪个版本的数据； 不同的隔离级别快照读不一样，最终的访问结果也不一样；比如读已提交的隔离级别，每一次执行快照读的时候都会生成ReadView，而可重复读的隔离级别，只会在第一次执行快照读的时候生成ReadView。 5.8.2 解决幻读的方式：虽然默认的隔离级别是可重复读，但是仍然可以很大程度上避免幻读（并不是完全解决）。 针对快照读（普通 select 语句），是通过 MVCC 机制解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等特殊读语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 总结：在可重复读的隔离级别下，对于快照读来说，幻读是通过MVCC机制解决的，对于当前读来说，幻读是通过Next-key lock解决的。 5.9 有哪些事务隔离级别？ READ-UNCOMMITTED(读未提交) ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读已提交) ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读) ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化) ： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读，但是性能比较低。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED 存在 存在 存在 READ-COMMITTED 不存在 存在 存在 REPEATABLE-READ（默认） 不存在 不存在 存在 SERIALIZABLE 不存在 不存在 不存在 5.10 隔离级别是怎么实现的？MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。 SERIALIZABLE 隔离级别是通过锁来实现的，READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。 读已提交隔离级别：在每次读取事务时，生成一个新的ReadView，意味着事务期间多次读取同一条数据可能出现不一致情况； 可重复读隔离级别：在启动事务时生成一个ReadView，然后整个事务期间都使用这个ReadView，保证了事务期间读取的数据都是事务启动前的记录； 5.11 MySQL的默认隔离级别是什么？MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。可以通过SELECT @@tx_isolation;命令来查看，MySQL 8.0 该命令改为SELECT @@transaction_isolation; 六、MySQL锁MySQL中根据锁的范围，可以分为全局锁、表级锁和行级锁三类。 6.1 说一说全局锁命令：flush tables with read lock； 执行后，整个数据库就处于只读状态了，增删改操作都会被阻塞。 主要的应用场景是做全库逻辑备份，这样在备份期间，就不会因为表中数据或结构更新，出现备份的数据与预期不一致的情况。 6.2 表级锁和行级锁了解吗？有什么区别？MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性能非常差。 InnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。 表级锁和行级锁对比： 表级锁： MySQL 中锁定粒度第二大的一种锁（第一是全局锁），是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。不过，触发锁冲突的概率最高，高并发下效率极低。表级锁和存储引擎无关，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定粒度最小的一种锁，是 针对索引字段加的锁 ，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。行级锁和存储引擎有关，是在存储引擎层面实现的。 6.3 InnoDB有哪几类行级锁？ 记录锁（Record Lock） ：属于单个行记录上的锁。 间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。 临键锁（Next-Key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 在 InnoDB 默认的隔离级别 REPEATABLE-READ 下，行级锁默认使用的是 Next-Key Lock。但是，如果操作的索引是唯一索引或主键，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。 6.4 意向锁有什么作用？用意向锁来快速判断是否可以对某个表使用表锁。 意向锁是一种表级锁，共有两种： 意向共享锁（IS锁）：事务有意向对表中的某些记录加共享锁，加共享锁前必须先取得该表的意向共享锁。 意向排他锁（IX锁）：事务有意向对表中的某些记录加排他锁，加排他锁前必须先取得该表的意向排他锁。 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享&#x2F;排他锁之前，InnoDB会先获取该数据行所在数据表对应的意向锁。 意向锁之间是互相兼容的。 6.5 当前读和快照读有什么区别？快照读（一致性非锁定读）：是指读取一个事务在开始执行之前数据库中的某个时间点的数据版本。 这种读取方式可以保证读取的数据是一致的，即读取的所有数据都是从同一时刻的数据库状态中获取的。在快照读的过程中，如果其他事务对数据进行了修改，读取操作也不会受到影响，因为读取的是之前的数据版本。 当前读（一致性锁定读）：是指读取数据库中最新的数据版本，也就是说，当前读会读取最新提交的事务对数据所做的修改。 当前读可以分为共享锁和排他锁两种方式。共享锁可以让其他事务也可以读取数据，但不能对其进行修改，而排他锁则可以独占该数据，并且其他事务不能读取或修改该数据。 总的来说，快照读保证了读取的数据是一致的，而当前读则可以读取到最新的数据版本，但会存在并发问题，需要通过锁等机制来保证数据的一致性和正确性。 6.5.1 当前读和快照读对应的语句有哪些？当前读： update delete insert select（共享读锁） 快照读：不同的隔离级别都不同 读已提交：每次select都会生成一个快照读； 可重复读：开启事务后第一个select语句才会快照读。 6.6 了解自增锁吗？关系型数据库设计表的时候，通常会有一列作为自增主键。InnoDB 中的自增主键会涉及一种比较特殊的表级锁——— 自增锁（AUTO-INC Locks）。 6.7 讲一讲间隙锁比如有A、B、C三个人在排队，现在来了个D，怎么样让新来的D不站在B的旁边呢？ 只需要把A和B、B和C之间的间隙锁住，这样D就不能站在B的旁边了。而这个例子中的A、B、C、D就相当于数据库里的一条条记录。 锁住他们之间间隙的操作就叫间隙锁。 间隙锁的目的就是为了防止幻读： 防止间隙内有新的数据被插入； 防止已经存在的数据，更新成为间隙内的数据。 七、MySQL性能优化7.1 MySQL能直接存储文件吗？可以将存储的文件转换成对应的二进制数据即可存储。不过不建议这样操作，因为会严重影响数据库性能。可以使用互联网厂商提供的云服务存储功能。 7.2 MySQL如何存储IP地址？可以将IP地址转换成整型数据存储，性能更好，占用空间也更小。 MySQL中提供了两个方式来处理IP地址： INET_ATON()：将IP地址转为无符号整型（4-8位）。 INET_NTOA()：将整型IP转为地址。 插入数据前，先用 INET_ATON() 把 ip 地址转为整型，显示数据时，使用 INET_NTOA() 把整型的 ip 地址转为地址显示即可。 7.3 常见的SQL调优方式7.3.1 创建索引 要尽量避免全表扫描。首先应该考虑在where及order by涉及的列上建立索引。 在进场需要进行检索的字段上创建索引。比如要按照表字段username进行检索，那么就应该在用户名这个字段上创建索引。 一个表的索引数最好不要超过6个。 7.3.2 避免在索引上使用计算7.3.3 使用预编译查询尽量使用参数化SQL，这样不仅可以避免SQL注入漏洞攻击，最重要的是数据库会对这些参数化SQL进行预编译。这样可以大大提高执行的速度。 7.3.4 调整where字句中的连接顺序数据库管理系统一般采用自下而上的顺序解析where字句，所以表连接最好写在其他where条件之间，这样可以过滤掉最大数量的记录。 7.3.5 尽量将多条SQL语句压缩到一句SQL中每次执行SQL语句的过程都是很耗时的，所以尽量避免过多的执行SQL语句，能够压缩到一句执行就不要用多条来执行。 7.3.6 用where字句替换HAVING字句7.3.7 使用表的别名7.3.8 优化select查询语句 任何地方都不要用select * from t，用具体的字段列表代替“*”，不要返回用不到的任何字段。 尽量避免在where字句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描。 7.3.9 优化update更新语句如果只更新几个字段，不要用update更新全部字段，否则频繁调用会引起明显的性能消耗，同时会带来大量日志。 7.3.10 优化insert插入语句在新建临时表时，如果一次性插入的数据量很大，那么可以使用select into代替create table，避免造成大量log，提高速度；如果插入的数据量不大，为了缓和系统表的资源，应该先create table，然后insert。 7.3.11 尽量使用union all代替union因为union会多一次过滤的过程，效率比较低； 7.4 MySql的分页了解吗？MySql的分页技术可以通过limit和offset子句实现。 limit：用于限制查询结果返回的行数，可以指定要返回的最大行数； offset：用于指定从结果集的起始位置开始返回的行数，可以指定要跳过的行数； 通过结合使用limit和offset可以实现分页查询，比如，limit 10 offset 20表示查询结果从第20行开始，返回十行数据，即返回第21到30行数据。 注：对于小的偏移量，直接使用limit来查询没有什么问题，但随着数据量的增大，越往后分页，limit语句的偏移量就会越大，速度也会明显变慢。 7.5 MySQL超大分页怎么处理？（Limit有什么性能问题？如何处理海量数据的分页？）超大分页一般是处理数据量比较大的情况，如果只是用limit和offset进行分页查询，需要对数据进行排序，会导致效率很低。 所以可以采用覆盖索引和子查询解决超大分页的情况。 先分页查询数据的id字段，确定id列表。因为查询id的时候走的是覆盖索引，所以效率会高很多； 通过子查询过滤数据，只查询id列表中的数据。 八、数据库优化8.1 大表数据查询如何进行优化？ 索引优化 SQL语句优化 水平拆分 垂直拆分 建立中间表 使用缓存技术 固定长度的表访问起来更快 越小的列访问越快 8.2 主键一般用自增的ID还是UUID？自增ID的优点： 字段长度比UUID小很多 数据库自动编号，按顺序存放，利于检索。 无须担心主键重复问题。 自增ID的缺点： 因为是自增，所以在某些业务场景下，容易被其他人查到业务量。 发生数据迁移或表合并时会非常麻烦。 在高并发场景下，竞争自增锁会降低数据库的吞吐能力。 UUID的优点： 唯一标识，不会存在重复的问题，在数据拆分、合并时也能保持全局的唯一性。 可以在应用层生成，提高数据库的吞吐能力。 无须担心业务量泄漏的问题。 UUID的缺点： 因为是随机生成，所以会发生随机IO，影响插入速度，并且会造成磁盘的使用率较低。 UUID占用空间较大，建立的索引越多，造成的影响越大。 UUID之间比较大小的速度比自增ID慢，影响查询速度。 总结：一般情况 MySQL 推荐使用自增 ID。因为在 MySQL 的 InnoDB 存储引擎中，主键索引是一种聚簇索引，主键索引的 B+树的叶子节点按照顺序存储了主键值及数据，如果主键索引是自增 ID，只需要按顺序往后排列即可， 如果是 UUID，ID 是随机生成的，在数据插入时会造成大量的数据移动，产生大量的内存碎片，造成插入性能的下降。 8.3 什么是垂直拆分和水平拆分？8.3.1 垂直拆分垂直拆分包括垂直分表和垂直分库。 垂直分表：将一个表按照字段分成多个表，每个表存储其中一部分字段。一般会将常用的字段放到一个表中，将不常用的字段放在另一个表中。 优势：避免IO竞争，减少锁表的概率。更好提升热门数据的查询效率。 垂直分库：按照业务对表进行分类，部署到不同的数据库上，不同的数据库可以放到不同的服务器上。 优势：降低业务中的耦合，方便对不同的业务进行分级管理。提升IO、数据库连接数、解决单机硬件资源的瓶颈问题。 垂直拆分的缺点：主键出现冗余，需要管理冗余的列、事务的处理变得复杂、仍然存在单表数据量过大的问题。 8.3.2 水平拆分水平拆分包括水平分表和水平分库。 水平分表：将一个表的数据按照一定规则拆分到多个表中。 优势：解决了单表数据量过大的问题、避免IO竞争并减少锁表的概率。 水平分库：把同一个表的数据按照一定规则拆分到不同的数据库中，不同的数据库可以放到不同的服务器上。 优势：解决了单库大数据量的瓶颈问题、IO冲突减少，锁的竞争减少，某个数据库出问题不影响其他数据库，提高了系统的稳定性和可用性。 水平拆分的缺点：分片事务一致性难以解决，逻辑会变得更复杂、数据扩展难度大，不易维护。 8.4 分库分表后，ID键如何处理？分库分表后不能每个表的 ID 都是从 1 开始，所以需要一个全局ID，设置全局ID 主要有以下几种方法： UUID 自增ID Redis生成ID Twitter的snowflake算法 8.5 MySQL主从复制原理MySQL复制：为保证主服务器和从服务器的数据一致性，在向主服务器插入数据后，从服务器会自动将主服务器中修改的数据同步过来。 主从复制的原理：主从复制主要有三个线程，binlog 线程，I&#x2F;O 线程，SQL 线程。 binlog 线程：负责将主服务器上的数据更改写入到二进制日志（Binary log）中。 I&#x2F;O 线程：负责从主服务器上读取二进制日志（Binary log），并写入从服务器的中继日志（Relay log）中。 SQL 线程：负责读取中继日志，解析出主服务器中已经执行的数据更改并在从服务器中重放。 MySQL主从一致性原理 Master 在每个事务更新数据完成之前，将操作记录写入到 binlog 中。 Slave 从库连接 Master 主库，并且 Master 有多少个， Slave 就会创建多少个 binlog dump 线程。当 Master 节点的 binlog 发生变化时，binlog dump 会通知所有的 Slave，并将相应的 binlog 发送给 Slave。 I&#x2F;O 线程接收到 binlog 内容后，将其写入到中继日志（Relay log）中。 SQL 线程读取中继日志，并在从服务器中重放。 主从复制的作用：高可用和故障转移、负载均衡、数据备份、升级测试 8.5.1 除了这种binlog方式，还有其他方式吗？数据同步模型 8.6 读写分离读写分离主要依赖于主从复制，主从复制为读写分离服务。 读写分离的优势： 主服务器负责写，从服务器负责读，缓解了锁的竞争 从服务器可以使用 MyISAM，提高查询性能、节约系统开销 提高数据可用性 8.7 分库分表之后如何进行数据迁移？ 停机迁移，该方案比较简单，也比较常用，具体操作就是在系统使用人数非常少的时候，挂个公告说系统需要维护升级1小时，然后进行停机迁移； 双写方案，该方案主要针对的是不能停机迁移的场景，实现起来比较麻烦。具体实现原理： 对老库进行增删改操作，同时也要写入新库，也即双写。如果操作的数据不存在于新库的话，需要插入到新库中，这样就能保证新库的数据是最新的； 在迁移过程中，双写操作只会让被更新操作的老库数据同步到新库，还需要将老库中的数据与新库的数据做对比，将老库有，新库没有的数据插入到新库；","tags":["Java","八股","基础","面试","MySQL"],"categories":["Java八股","基础"]},{"title":"5.Spring全家桶","path":"/2023/06/26/5-Spring全家桶/","content":"1、 Spring基础1.1 什么是Spring框架？Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。 Spring 最核心的思想就是不重新造轮子，开箱即用，提高开发效率。 1.2 Spring的模块有哪些？以下是Spring5.x版本的模块结构图： Spring5.x主要模块 Spring4.x 版本中 Web 模块的 Portlet 组件已经被废弃掉，同时增加了用于异步响应式处理的 WebFlux 组件。 1.2.1 Core Container模块这是Spring的核心模块，主要提供IoC依赖注入功能的支持。 spring-core ：Spring 框架基本的核心工具类。 spring-beans ：提供对 bean 的创建、配置和管理等功能的支持。 spring-context ：提供对国际化、事件传播、资源加载等功能的支持。 spring-expression ：提供对表达式语言（Spring Expression Language） SpEL 的支持，只依赖于 core 模块，不依赖于其他模块，可以单独使用 1.2.2 AOP spring-aspects ：该模块为与 AspectJ 的集成提供支持。 spring-aop ：提供了面向切面的编程实现。 spring-instrument ：提供了为 JVM 添加代理（agent）的功能。 具体来讲，它为 Tomcat 提供了一个织入代理，能够为 Tomcat 传递类文件，就像这些文件是被类加载器加载的一样。没有理解也没关系，这个模块的使用场景非常有限。 1.2.3 Data Access&#x2F;Integration spring-jdbc ：提供了对数据库访问的抽象 JDBC。不同的数据库都有自己独立的 API 用于操作数据库，而 Java 程序只需要和 JDBC API 交互，这样就屏蔽了数据库的影响。 spring-tx ：提供对事务的支持。 spring-orm ： 提供对 Hibernate、JPA 、iBatis 等 ORM 框架的支持。 spring-oxm ：提供一个抽象层支撑 OXM(Object-to-XML-Mapping)，例如：JAXB、Castor、XMLBeans、JiBX 和 XStream 等。 spring-jms : 消息服务。自 Spring Framework 4.1 以后，它还提供了对 spring-messaging 模块的继承。 1.2.4 Spring Web spring-web ：对 Web 功能的实现提供一些最基础的支持。 spring-webmvc ： 提供对 Spring MVC 的实现。 spring-websocket ： 提供了对 WebSocket 的支持，WebSocket 可以让客户端和服务端进行双向通信。 spring-webflux ：提供对 WebFlux 的支持。WebFlux 是 Spring Framework 5.0 中引入的新的响应式框架。与 Spring MVC 不同，它不需要 Servlet API，是完全异步。 1.2.5 Messagingspring-messaging 是从 Spring4.0 开始新加入的一个模块，主要职责是为 Spring 框架集成一些基础的报文传送应用。 1.2.6 Spring TestSpring 团队提倡测试驱动开发（TDD）。有了控制反转 (IoC)的帮助，单元测试和集成测试变得更简单。 Spring 的测试模块对 JUnit（单元测试框架）、TestNG（类似 JUnit）、Mockito（主要用来 Mock 对象）、PowerMock（解决 Mockito 的问题比如无法模拟 final, static， private 方法）等等常用的测试框架支持的都比较好。 1.3 Spring、SpringMVC、SpringBoot之间有什么关系？Spring 是一个轻量级 Java 开源框架，目的是解决企业级应用开发的复杂性，简化 Java 开发。Spring 通过一个 IoC 容器，来管理 Bean 对象，使用依赖注入实现控制反转，可以很方便的整合各种框架，提供 AOP 机制弥补 OOP 的代码重复问题、更方便将不同类不同方法中的共同处理抽取成切面、自动注入给方法执行，比如日志、异常等。 Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。 MVC架构 Spring Boot 旨在简化 Spring 开发，简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用！ 1.4 Spring的优缺点是什么？1.4.1 优点 轻量级：Spring 框架不需要使用繁重的 EJB 组件，可以在轻量级容器中运行，因此开发和部署更为简单。 面向切面编程（AOP）：Spring 提供了很好的 AOP 支持，使得开发者可以更加容易地实现事务管理、安全、日志等功能，降低了代码的复杂度。 控制反转（IOC）：Spring 提供了依赖注入（DI）的支持，通过容器管理对象之间的依赖关系，降低了耦合度，使得代码更加可维护。 支持多种开发框架：Spring 对各种开发框架（如 Struts、Hibernate、MyBatis 等）都提供了很好的支持，使得开发者可以更加容易地集成这些框架。 提高开发效率：Spring 提供了很多实用的工具和模板，如 JDBC 模板、ORM 模板等，使得开发者可以更加快速地开发出高质量的应用。 1.4.2 缺点 学习曲线较陡峭：Spring 框架是一个比较复杂的框架，需要开发者学习很多概念和 API，因此学习曲线较陡峭。 过度封装：Spring 提供了很多封装，使得开发者很难理解其中的原理，也使得一些简单的操作变得复杂。 运行效率：Spring 框架由于需要进行大量的依赖注入和 AOP 操作，因此在运行时会消耗一定的系统资源，可能会影响应用的运行效率。 容器过重：Spring 的容器较重，启动速度较慢，可能会对应用的性能造成一定的影响。 1.5 Spring中用到了哪些设计模式？ 工厂模式：Spring中通过BeanFactory、ApplicationContext创建Bean对象。 代理模式：Spring AOP基于代理模式实现的。 单例模式：Spring中的Bean默认都是单例的。 模板方法：Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器模式：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式：Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式：Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 1.6 说一说Spring中拦截器和过滤器的区别拦截器 ：是指service或者一个方法，前调用一个方法，或者在方法后调用一个方法，比如动态代理就是拦截器的简单实现，在调用方法前做出某些业务逻辑的操作，或调用方法后，甚至在抛出异常的时候做业务逻辑的操作。 过滤器：是在JavaWeb中，传入的request、response提前过滤掉一些信息，通过提前设置一些参数，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）或者去除掉一些非法字符。 Web项目结构 过滤器 -&gt; Servlet -&gt; 拦截器 -&gt; Controller 拦截器和过滤器比较 拦截器是基于Java的反射机制的，而过滤器是基于函数回调； 拦截器是Spring的一个组件，可以单独使用，也可以在Web中使用，而过滤器的使用依赖于Tomcat等容器，只能在Web程序中使用； 拦截器是在请求进入Controller之前进行预处理的，而过滤器是在请求进入Servlet之前进行预处理； 拦截器只会对Controller中的请求或访问static目录下得资源请求起作用，而过滤器几乎可以对所有进入容器的请求起作用； 拦截器可以获取IOC容器中各个bean，在拦截其中注入一个service，是可以调用业务逻辑的，但是过滤器不行。 1.7 常用注解1.7.1 Spring常用注解 声明Bean的：@Component、@Service、@Repository、 @Controller； 依赖注入相关的：@Autowired、@Qualifier、@Resourse； 设置作用域的：@Scope； Spring配置相关的：@Configuration，@ComponentScan 和 @Bean； AOP相关注解：@Aspect，@Before，@After， @Around，@Pointcut； 1.7.2 SpringMVC常用注解 @RequestMapping：用于映射请求路径； @RequestBody：注解实现接收http请求的json数据，将json转换为java对象； @RequestParam：指定请求参数的名称； @PathViriable：从请求路径下中获取请求参数(&#x2F;user&#x2F;{id})，传递给方法的形式参数； @ResponseBody：注解实现将controller方法返回对象转化为json对象响应给客户端； @RequestHeader：获取指定的请求头数据； @PostMapping：用来声明 POST 请求处理方法的注解； @GetMapping：用来声明 GET请求处理方法的注解； 1.7.3 SpringBoot常用注解SpringBoot的核心注解是@SpringBootApplication , 他由几个注解组成 ： @SpringBootConfiguration： 组合了@Configuration注解，实现配置文件的功能； @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项； @ComponentScan：对Spring组件进行扫描。 2、Spring IoC2.1 谈谈自己对Spring IoC和DI的理解IoC（Inversion of Control:控制反转） 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。不过， IoC 并非 Spring 特有，在其他语言中也有应用。 总结：Spring通过DI（依赖注入）实现IOC（控制反转）。 2.1.1 为什么叫控制反转？ 控制 ：指的是对象创建（实例化、管理）的权力 反转 ：控制权交给外部环境（Spring 框架、IoC 容器） IOC 在 Spring中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。 Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。 2.1.2 IoC有什么作用？ 管理对象的创建和依赖关系的维护。 解耦，由容器去维护具体的对象。 托管了类的整个生命周期。 2.1.3 为什么IoC能实现解耦？IoC容器相当于是第三方，可以实现具有依赖关系的对象之间的解耦。 IOC容器的作用 由于引入了第三方，也就是IoC容器，使得A、B、C、D四个对象之间没有了耦合关系。齿轮之间的传动完全依赖于第三方。 简单来说，就是将全部对象的控制权全部上交给IoC容器，IoC容器就成为了整个系统的关键核心。 IoC容器把系统中的所有对象粘合在一起发挥作用，如果没有IoC容器，那么对象与对象之间自然就没有联系。 所以IoC容器能实现解耦。 2.1.4 什么是依赖注入DI？依赖注入是一种消除类之间依赖关系的设计模式。其作用是去除Java类之间的依赖关系，实现松耦合，以便于开发测试。 在依赖注入中对象不再自己创建或查找它们所依赖的对象，而是通过外部机制(比如配置文件或注解)将依赖项提供给它们。 例如，A类要依赖B类，A类不再直接创建B类，而是把这种依赖关系配置在外部xml文件（或Java config文件）中，然后由Spring容器根据配置信息创建、管理bean类。 比如： 1234567891011121314151617class Player&#123; Weapon weapon; // weapon 被注入进来 Player(Weapon weapon)&#123; this.weapon = weapon; &#125; public void attack() &#123; weapon.attack(); &#125; public void setWeapon(Weapon weapon)&#123; this.weapon = weapon; &#125; &#125; 上述的例子中，Weapon类的实例并不在代码中创建，而是通过构造函数传入的，传入的类型是父类的Weapon，所以传入的对象类型可以使任何Weapon的子类。 至于具体传入哪个子类，可以在外部xml文件（或config文件）中配置，Spring容器根据配置信息创建所需要的子类实例，并且注入Player类中，如下： 123456&lt;bean id=&quot;player&quot; class=&quot;com.qikegu.demo.Player&quot;&gt; &lt;construct-arg ref=&quot;weapon&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;weapon&quot; class=&quot;com.qikegu.demo.Gun&quot;&gt; &lt;/bean&gt; 上面代码中&lt;construct-arg ref=&quot;weapon&quot;/&gt; ref指向id=&quot;weapon&quot;的bean，传入的武器类型是Gun，如果想改为Sword，可以作如下修改： 12&lt;bean id=&quot;weapon&quot; class=&quot;com.qikegu.demo.Sword&quot;&gt; &lt;/bean&gt; 2.1.5 依赖注入有哪些方式？ 构造方法注入：如果只有一个有参数的构造方法并且参数类型与注入的bean的类型匹配，那么就会注入到该构造方法中； Setter注入：在xml文件中写入，然后再set方法中注入； 注解注入：通过@Autowired注解注入。 注：如果采用Setter方法注入，并且类中有一个代餐的构造方法，必须要有空参构造方法，不然Spring没有办法实例化对象，导致报错。 2.2 什么是Spring Bean？简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。 我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。 1234&lt;!-- Constructor-arg with &#x27;value&#x27; attribute --&gt;&lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; &lt;constructor-arg value=&quot;...&quot;/&gt;&lt;/bean&gt; IoC容器如何使用配置元数据来管理对象： 使用配置元数据管理对象 2.3 将一个类声明为Bean的注解有哪些？ @Componet：通用的注解，可以标注任意的类为Spring组件。如果不知道一个Bean属于哪个层，可以用@Componet注解来标注。 @Repository：对应持久层，即Dao层，主要用于数据库的相关操作。 @Service：对应服务层，主要涉及一些复杂的逻辑，需要用到Dao。 @Controller：对应Spring MVC控制层，主要用于接受用户请求并调用Service层返回数据给前端页面。 2.4 @Componet和@Bean的区别是什么？ @Componet注解作用于类，而@Bean注解作用于方法。 @Componet通常是通过类路径扫描（可以用@ComponetScan定义扫描的路径）来自动侦测以及自动装配到Spring容器中。@Bean通常是我们在标有该注解的方法中定义产生这个bean，告诉Spring这是某个类的实例，当我需要用它的时候还给我。 @Bean注解比@Componet注解的自定义性更强，而且很多地方只能通过@Bean来注册bean。比如当引用第三方库中的类，需要装配到Spring容器时，只能通过@Bean来实现。 @Bean注解的使用示例： 1234567@Configurationpublic class AppConfig &#123; @Bean public TransferService transferService() &#123; return new TransferServiceImpl(); &#125;&#125; 这段代码相当于下面的xml配置： 123&lt;beans&gt; &lt;bean id=&quot;transferService&quot; class=&quot;com.acme.TransferServiceImpl&quot;/&gt;&lt;/beans&gt; 2.5 注入Bean的注解有哪些？Spring内置的@Autowired（自动装配）以及JDK内置的@Resource和@Inject都可以注入Bean 2.5.1 使用@Autowired 注解自动装配 bean 的过程是怎样的?在使用@Autowired 注解之前需要在 Spring 配置文件进行配置标签，然后在启动Spring IoC 时，容器就会自动装载一个AutowiredAnnotationBeanPostProcessor后置处理器，当容器扫描到@Autowied、@Resource 或@Inject 时，就会在 IoC 容器自动查找需要的 bean， 并装配给该对象的属性。 在使用@Autowired 时，首先在容器中查询对应类型的 Bean： ​\t如果查询的结果为空，那么会抛出异常； ​\t如果查询结果刚好为一个，就将该 Bean 装配给@Autowired 指定的属性； ​\t如果查询的结果不止一个，需要配合@Qualifier 注解根据名称来查找； ​ 如果配合@Qualifier 注解根据名称来查找的结果为空，会抛出异常，可以将@Autowire 注解的 required 属性设置为 false。 2.6 @Autowired和@Resource的区别是什么？Autowired 属于 Spring 内置的注解，默认的注入方式为byType（根据类型进行匹配），也就是说会优先根据接口类型去匹配并注入 Bean （接口的实现类）。 这会导致什么问题呢？ 当一个接口存在多个实现类的话，byType这种方式就无法正确注入对象了，因为这个时候 Spring 会同时找到多个满足条件的选择，默认情况下它自己不知道选择哪一个。 这种情况下，注入方式会变为 byName（根据名称进行匹配），这个名称通常就是类名（首字母小写）。就比如说下面代码中的 smsService 就是我这里所说的名称，这样应该比较好理解了吧。 123// smsService 就是我们上面所说的名称@Autowiredprivate SmsService smsService; 举个例子，SmsService 接口有两个实现类: SmsServiceImpl1和 SmsServiceImpl2，且它们都已经被 Spring 容器所管理。 1234567891011// 报错，byName 和 byType 都无法匹配到 bean@Autowiredprivate SmsService smsService;// 正确注入 SmsServiceImpl1 对象对应的 bean@Autowiredprivate SmsService smsServiceImpl1;// 正确注入 SmsServiceImpl1 对象对应的 bean// smsServiceImpl1 就是我们上面所说的名称@Autowired@Qualifier(value = &quot;smsServiceImpl1&quot;)private SmsService smsService; 所以，还是建议通过 @Qualifier 注解来显式指定名称而不是依赖变量的名称。 @Resource属于 JDK 提供的注解，**默认注入方式为 byName**。如果无法通过名称匹配到对应的 Bean 的话，注入方式会变为byType。 @Resource 有两个比较重要且日常开发常用的属性：name（名称）、type（类型）。 1234public @interface Resource &#123; String name() default &quot;&quot;; Class&lt;?&gt; type() default Object.class;&#125; 如果仅指定 name 属性则注入方式为byName，如果仅指定type属性则注入方式为byType，如果同时指定name 和type属性（不建议这么做）则注入方式为byType+byName。 123456789// 报错，byName 和 byType 都无法匹配到 bean@Resourceprivate SmsService smsService;// 正确注入 SmsServiceImpl1 对象对应的 bean@Resourceprivate SmsService smsServiceImpl1;// 正确注入 SmsServiceImpl1 对象对应的 bean（比较推荐这种方式）@Resource(name = &quot;smsServiceImpl1&quot;)private SmsService smsService; 总结，两者的区别： @Autowired是Spring提供的注解，而@Resource是JDK提供的注解； @Autowired默认注入方式为byType（根据类型匹配），@Resource默认注入方式为byName(根据名称匹配)； 当一个接口存在多个实现类的情况下，@Autowired和@Resource都需要通过名称才能正确匹配到对应的Bean。@Autowired可以通过@Qualifier注解来显式指定名称，@Resource可以通过name属性来显式指定名称。 2.7 Bean的作用域有哪些？ singleton : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。 prototype : 每次获取都会创建一个新的 bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。 request （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。 session （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。 application&#x2F;global-session （仅 Web 应用可用）： 每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。 websocket （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。 2.7.1 如何配置Bean的作用域呢？ xml方式： 1&lt;bean id=&quot;...&quot; class=&quot;...&quot; scope=&quot;singleton&quot;&gt;&lt;/bean&gt; 注解方式： 12345@Bean@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)public Person personPrototype() &#123; return new Person();&#125; 2.8 单例Bean的线程安全问题了解吗？单例 Bean 存在线程安全问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。 通常有两种解决方法： 在Bean中尽量避免定义可以变的成员变量。 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在TheadLocal中。（推荐） 不过，大部分Bean实际都是无状态（没有实际变量）的，比如说Dao、Service，这种情况下，Bean是线程安全的。 2.9 Bean的生命周期了解吗？Bean生命周期 通过BeanDefinition获取Bean的定义信息，比如类的全路径，是否延迟加载，是否是单例等； 调用构造函数实例化Bean ； Bean的依赖注入，比如set方法注入，平时用的@Autowire就是在这一步完成的； 处理Aware接口，比如BeanNameAware、BeanFactoryAware、ApplicationContextAware； Bean的后置处理器BeanPostProcessor-befor； 初始化方法； Bean的后置处理器BeanPostProcessor-after，主要就是对Bean进行增强； 销毁Bean； 2.9.1 什么是Aware接口？Aware 接口是一个具有标识作用的超级接口，指示 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式。 Aware 接口是一个空接口，具体的实现由各个子接口决定，且该接口通常只包含一个单个参数并且返回值为void的方法。可以理解就是set方法。该方法的命名方式为 set + 去掉接口名中的 Aware 后缀，即 XxxAware 接口，则方法定义为 setXxx()，例如 BeanNameAware的方法就是setBeanName，ApplicationContextAware的方法就是setApplicationContext。 注意，仅实现Aware接口，不会提供任何默认功能，需要明确的指定实现哪个子接口。 简单来说，Aware翻译过来的意思是有感知的，察觉的，如果类上实现了该接口，表明对什么有感知，比如BeanNameAware, 表示知道了自己的BeanName。 2.9.2 为什么要处理Aware接口呢？因为我们在实际的开发过程中，有些Bean可能需要用到Spring容器本身的功能资源，所以Spring容器中的Bean此时就要意识到Spring容器的存在才能调用Spring所提供的资源。我们通过Spring提供的一系列接口Spring Aware来实现具体的功能。 2.10 Spring Bean中的循环依赖问题循环依赖（循环引用）其实就是两个或两个以上的bean互相持有对方，最终形成闭环。比如A依赖B，B依赖A。 在Spring框架中根据三级缓存已经解决了大部分的循环依赖。 一级缓存：单例池，缓存已经经历了完整的生命周期，已经初始化完成的bean对象；（解决不了循环依赖） 二级缓存：缓存早期的bean对象（生命周期还没走完）； 三级缓存：缓存的是ObjectFactory，表示对象工厂，用来创建某个对象的。 2.10.1 三级缓存具体是怎么解决循环依赖的呢？（具体流程是什么？） 先实例化A对象，同时会创建ObjectFactory对象存入三级缓存中； A在初始化的时候需要B对象，这时候回去创建B对象； B对象实例化完成，也会创建ObjectFactory对象存入三级缓存； B对象需要注入A，可以通过三级缓存中的ObjectFactory对象生成A的半成品对象存入二级缓存；（此时的A对象可以是普通对象，也可以是代理对象） B通过二级缓存获取到A的对象后，就可以正常注入A，然后B对象创建成功后，将对象B存入一级缓存； 返回到A对象，因为此时B对象已经创建成功了，所以A对象可以直接注入B对象，完成对象A的创建，并存入一级缓存中； 删除二级缓存中A的半成品对象； 2.10.2 构造方法出现了循环依赖怎么解决？由于构造函数是在bean的生命周期中第一个执行的，三级缓存并不能解决构造函数的依赖注入问题。 所以可以使用@Lazy懒加载注解解决，什么时候需要对象，再进行bean对象的创建。 3、Spring AOP3.1 谈谈自己对Spring AOP的理解AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑（例如事务处理、日志管理、权限控制等）抽取公共模块复用，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 AOP 代表的是一个横向的关系，如果说“对象”是一个空心的圆柱体，其中封装了对象的属性和行为；那么AOP的方法，就仿佛一把利刃，将这些空心圆柱体剖开，以获得其内部的消息。而剖开的面，也就是所谓的“切面”了。然后它又以巧夺天功的妙手将这些剖开的切面复原，不留痕迹。 AOP使用“横切”技术，将软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，相反与之关系不大的部分就是横切关注点。这些横切关注点就是上面说到的，与业务无关，但是对多个对象产生影响的公共行为和逻辑，比如权限认证、日志管理、事务处理这些功能。 AOP的作用就是分离系统中的核心关注点和横切关注点。 Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理，如下图所示： SpringAOPProcess 3.1.1 常见的AOP使用场景 记录操作日志：使用AOP中的环绕通知+切点表达式来实现； 缓存处理 Spring中内置的事务 3.2 Spring AOP和AspectJ AOP有什么区别？Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 如果的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。 3.3 JDK动态代理和Cglib动态代理的区别？ JDK动态代理是基于接口实现的代理，使用Java反射机制在运行时创建代理类。JDK动态代理要求目标对象实现至少一个接口，代理类与目标类实现相同的接口，通过实现InvocationHandler接口并重写invoke()方法实现代理类的具体逻辑。 Cglib动态代理是基于继承实现的代理，使用字节码生成技术在运行时生成代理类。Cglib动态代理不要求目标对象实现接口，可以对任何类进行代理。代理类继承目标类，通过重写目标类的方法实现代理类的具体逻辑。 相比于JDK动态代理，Cglib动态代理的效率更高，因为它不需要反射调用目标类的方法，而是通过直接调用代理类中重写的方法实现。但是Cglib动态代理也有一些限制，例如无法代理被final修饰的方法、类以及private、static等方法。 因此，如果目标对象实现了接口，建议使用JDK动态代理；如果目标对象没有实现接口，或者需要代理被final修饰的方法，可以考虑使用Cglib动态代理。 3.4 AOP中通知类型有哪些？ Before（前置通知）：目标对象的方法调用之前触发 After （后置通知）：目标对象的方法调用之后触发 AfterReturning（返回通知）：目标对象的方法调用完成，在返回结果值之后触发 AfterThrowing（异常通知） ：目标对象的方法运行中抛出 &#x2F; 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。 Around （环绕通知）：编程式控制目标对象的方法调用。环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法 3.5 多个切面的执行顺序如何控制？1、通常使用@Order 注解直接定义切面顺序 12345// 值越小优先级越高@Order(3)@Component@Aspectpublic class LoggingAspect implements Ordered &#123; 2、实现Ordered 接口重写 getOrder 方法。 12345678910@Component@Aspectpublic class LoggingAspect implements Ordered &#123; // .... @Override public int getOrder() &#123; // 返回值越小优先级越高 return 1; &#125;&#125; 4、Spring MVC4.1 谈谈自己对Spring MVC的理解MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。 MVC架构 Spring MVC 模式下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)。 4.1.1 Spring MVC的优点 可以支持各种视图技术，而不仅仅局限于 JSP； 与 Spring 框架集成（如 IoC 容器、AOP 等）； 清晰的角色分配：前端控制器(DispatcherServlet) , 处理器映射器（HandlerMapping)，处理器适配器（HandlerAdapter)，视图解析器（ViewResolver）。 支持各种请求资源的映射策略。 4.2 Spring MVC的核心组件有哪些？ DispatcherServlet ：前端控制器，负责接收请求、分发，并给予客户端响应。 HandlerMapping ：处理器映射器，根据 uri 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。 HandlerAdapter ：处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler； Handler ：请求处理器，处理实际请求的处理器。 ViewResolver ：视图解析器，根据 Handler 返回的逻辑视图 &#x2F; 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端 4.3 Spring MVC的工作原理？Spring MVC的工作原理如下图： SpringMVC工作原理 客户端发送请求，DispatcherServlet拦截请求； DispatcherServlet根据请求信息调用HandlerMapping。HandlerMapping根据url去匹配查找能处理Handler（也就是常说的Controller控制器），并将请求涉及到的拦截器和Handler一起封装。 DispatcherServlet调用HandlerAdapter适配执行Handler。 Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet。ModelAndView 顾名思义，包含了数据模型以及相应的视图的信息。Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispatcherServlet会把返回的Model传给View（视图渲染）。 最后再把View返回给客户端。 但是现在的开发过程基本都是接口开发、前后端分离，采用json格式传递数据，并没有ModelAndView，所以现在的处理流程会简单很多： 目前的流程 具体的步骤前半部分与之前一样，只是在controller上加个@ResponseBody注解，将结果转换为JSON并响应，并没有视图那一步。 4.4 统一异常处理怎么做？推荐使用注解的方式统一异常处理，具体会使用到 @ControllerAdvice + @ExceptionHandler 这两个注解 。 1234567891011121314@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler &#123; @ExceptionHandler(BaseException.class) public ResponseEntity&lt;?&gt; handleAppException(BaseException ex, HttpServletRequest request) &#123; //...... &#125; @ExceptionHandler(value = ResourceNotFoundException.class) public ResponseEntity&lt;ErrorReponse&gt; handleResourceNotFoundException(ResourceNotFoundException ex, HttpServletRequest request) &#123; //...... &#125;&#125; 这种异常处理方式下，会给所有或者指定的 Controller 织入异常处理的逻辑（AOP），当 Controller 中的方法抛出异常的时候，由被@ExceptionHandler 注解修饰的方法进行处理。 ExceptionHandlerMethodResolver 中 getMappedMethod 方法决定了异常具体被哪个 @ExceptionHandler 注解修饰的方法处理异常。 1234567891011121314151617181920@Nullableprivate Method getMappedMethod(Class&lt;? extends Throwable&gt; exceptionType) &#123; List&lt;Class&lt;? extends Throwable&gt;&gt; matches = new ArrayList&lt;&gt;(); //找到可以处理的所有异常信息。mappedMethods 中存放了异常和处理异常的方法的对应关系 for (Class&lt;? extends Throwable&gt; mappedException : this.mappedMethods.keySet()) &#123; if (mappedException.isAssignableFrom(exceptionType)) &#123; matches.add(mappedException); &#125; &#125; // 不为空说明有方法处理异常 if (!matches.isEmpty()) &#123; // 按照匹配程度从小到大排序 matches.sort(new ExceptionDepthComparator(exceptionType)); // 返回处理异常的方法 return this.mappedMethods.get(matches.get(0)); &#125; else &#123; return null; &#125;&#125; 从源代码看出： getMappedMethod()会首先找到可以匹配处理异常的所有方法信息，然后对其进行从小到大的排序，最后取最小的那一个匹配的方法(即匹配度最高的那个)。 5、Spring事务5.1 Spring管理事务的方法有几种？ 编程式事务。在代码中硬编码（不推荐）：通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于理解 Spring 事务管理原理有帮助。 声明式事务。在 XML 配置文件中配置或者直接基于注解（推荐） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 5.2 Spring事务中有哪几种事务传播行为（传播机制）？Spring 事务的传播行为是指：多个事务方法相互调用时,事务如何在这些方法间传播。为了解决业务层方法之间互相调用的事务问题。 举个栗子，方法A是一个事务的方法，方法A执行过程中调用了方法B，那么方法B有无事务以及方法B对事务的要求不同都会对方法A的事务具体执行造成影响，同时方法A的事务对方法B的事务执行也有影响，这种影响具体是什么就由两个方法所定义的事务传播类型所决定。 **PROPAGATION_REQUIRED**：使用的最多的一个事务传播行为，我们平时经常使用的@Transactional注解默认使用就是这个事务传播行为。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 **PROPAGATION_REQUIRES_NEW**：创建一个新的事务，如果当前存在事务，则把当前事务挂起。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。 **PROPAGATION_NESTED**：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于PROPAGATION_REQUIRED。 **PROPAGATION_MANDATORY**：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性），这个使用的很少。 若是错误的配置以下 3 种事务传播行为，事务将不会发生回滚： PROPAGATION_SUPPORTS: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 PROPAGATION_NOT_SUPPORTED: 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 PROPAGATION_NEVER: 以非事务方式运行，如果当前存在事务，则抛出异常。 5.3 Spring事务中的隔离级别有哪几种？ ISOLATION_DEFAULT :使用后端数据库默认的隔离级别，MySQL 默认采用的 REPEATABLE_READ 隔离级别 ，Oracle 默认采用的 READ_COMMITTED 隔离级别. ISOLATION_READ_UNCOMMITTED :最低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 ISOLATION_READ_COMMITTED : 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 ISOLATION_REPEATABLE_READ : 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 ISOLATION_SERIALIZABLE : 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 5.4 Spring事务中失效的场景有哪些？ 方法上异常捕获处理，自己处理了异常，没有抛出，就会导致事务失效。解决方法就是手动抛出异常即可； 方法抛出检查异常，如果报错，也会导致事务失效。解决方法就是配置rollbackFor属性为Exception； 方法不是public修饰的，也会导致事务失效。解决方法就是将非public方法，改为public； 6、Spring Boot6.1 什么是Spring Boot？Spring Boot 是 Spring 源组织下的子项目，是 Spring 组件一站式解决方案，主要是简化了使用 Spring 的难度，简化了繁重的配置，提供了各种启动器，开发者能快速上手。 6.2 Spring Boot的优点和缺点？优点： 容易上手，提升开发效率，为 Spring 开发提供一个更快、更广泛的入门体验。 开箱即用，远离繁琐的配置。 没有代码生成，也不需要 XML 配置。 提供了一系列大型项目通用的非业务性功能，例如：内嵌服务器、安全管理、运行数据监控、运行状况检查和外部化配置等。 避免大量的 Maven 导入和各种版本冲突。 缺点： 入门简单精通难，各种强大的功能封装的太好了，内部原理比较难参透； SpringBoot一旦出错，由于内部封装的比较深，所以部分错误调试的难度要比Spring难很多。 6.3 谈谈Spring Boot自动装配原理 ？在 SpringBoot 应用的每个启动类上都会有个注解@SpringBootApplication 123456@SpringBootApplicationpublic class SpringSecurityJwtGuideApplication &#123; public static void main(java.lang.String[] args) &#123; SpringApplication.run(SpringSecurityJwtGuideApplication.class, args); &#125;&#125; 我们可以把 @SpringBootApplication看作是 @SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan 注解的集合。 根据 SpringBoot 官网，这三个注解的作用分别是： @EnableAutoConfiguration：开启 SpringBoot 的自动配置机制 @ComponentScan： 扫描被@Component (@Repository,@Service,@Controller)注解的 bean，注解默认会扫描该类所在的包下所有的类。 @SpringBootConfiguration：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类 其中@EnableAutoConfiguration注解是实现自动配置的核心注解。该注解通过@Import注解导入对应的配置选择器，关键的是内部读取了该项目和该项目引用的jar包的classpath路径下META-INF&#x2F;spring.factories文件中所配置的类的全类名。 这些配置类中所定义的Bean会根据条件注解所指定的条件来决定是否要将其导入到Spring容器中。 比如@ConditionalOnClass注解，判断是否有对应的class文件，如果有则加载该类，把这个配置类的所有Bean放入到Spring中使用。 具体来说SpringBoot的自动装配是通过注解实现的，当满足某些条件时，自动装配相应的组件。 判断自动装配开关是否打开。默认spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml 中设置； 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName； 获取需要自动装配的所有配置类，读取META-INF/spring.factories； 到这里可能面试官会问你:“spring.factories中这么多配置，每次启动都要全部加载么？”。 很明显，这是不会的。因为，这一步有经历了一遍筛选，@ConditionalOnXXX 中的所有条件都满足，该类才会生效。 值得注意的是，Spring Boot的自动装配仅限于Spring框架本身提供的组件和第三方库中的Spring组件，对于其他的组件，需要手动进行配置。 6.4 Spring Boot Starter是什么？如何自定义？Spring Boot Starter 是 Spring boot 的核心，可以理解为一个可拔插式的插件。 例如，想使用Reids插件，那么可以导入spring-boot-starter-redis 依赖 Starter 的命名。官方对 Starter 项目的 jar 包定义的 artifactId 是有要求的 ， 当然也可以不遵守 。 Spring官方Starter通常命名为 spring-boot-starter-&#123;name&#125;如：spring-boot-starter-web，Spring官方建议非官方的 starter 命名应遵守&#123;name&#125;-spring-boot-starter 的格式。 自定义starter的步骤如下： 新建一个maven项目，在pom.xml文件中定义好所需要的依赖； 新建配置类，写好配置项和默认值，使用@ConfigurationProperties指明配置前缀； 新建自动装配类，使用@Configuration和@Bean进行自动装配； 新建Spring.factories文件，用于指定自动装配类的路径； 将starter安装到maven仓库，让其他项目能够引用。 6.5 Spring Boot核心配置文件Spring boot 核 心 的 两个配置文件 ： bootstrap (. yml 或 者 . properties)：bootstrap 由父 ApplicationContext 加载的，比 applicaton 优先加载，配置在应用程序上下文的引导阶段生效。一般来说我们在 Spring Cloud Config 或者 Nacos 中会用到它。且 bootstrap 里面的属性不能被覆盖； application (. yml 或者 . properties)：由 ApplicatonContext 加 载，用于 Spring boot 项目的自动化配置 6.6 Spring Boot打成jar和普通jar有什么区别？Spring Boot 打成的 jar 无法被其他项目依赖，主要还是他和普通 jar 的结构不同。 普通的 jar 包，解压后直接就是包名，包里就是我们的代码，而 Spring Boot 打包成的可执行 jar 解压后，在\\BOOT-INF\\classes 目录下才是我们的代码，因此无法被直接引用。如果非要引用，可以在 pom.xml 文件中增加配置， 将 Spring Boot 项目打包成两个 jar ，一个可执行，一个可引用 6.7 Spring Boot和Spring Cloud的区别？SpringBoot 专注于快速、方便的开发单个微服务个体，SpringCloud 关注全局的服务治理框架。 SpringCloud 将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供配置管理、服务发现、断路器、路由、 微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务。 SpringBoot 可以离开SpringCloud 独立开发项目 ， 但是 SpringCloud 离不开 SpringBoot ，属于依赖的关系。 6.8 Spring Boot的启动流程 首先从main里面找到run方法，在执行run方法之前先new一个SpringApplication对象； 进入run方法，创建应用监听器开始监听； 然后加载配置环境，把配置环境加入到监听对象中； 然后加载应用上下文，当做run方法的返回对象； 最后创建Spring容器，实现starter自动化配置和bean的实例化等工作。","tags":["Java","八股","基础","面试","Spring"],"categories":["Java八股","基础"]},{"title":"4.Java虚拟机","path":"/2023/06/23/4-Java虚拟机/","content":"1、Java内存区域如果没有特殊说明，都是针对的是 HotSpot 虚拟机。 1.1 运行时数据区Java 虚拟机在执行 Java 程序时，会将内存划分为若干区域，划分的方式， 在 JDK1.8 和之前的方式略有不同。 JDK1.8 之前：（线程共享：堆、方法区、直接内存; 线程私有：虚拟机栈、本地方法栈、程序计数器） 运行时数据区 JDK1.8：（线程共享：堆、方法区变为了元空间（放在了本地内存中）、直接内存; 线程私有：虚拟机栈、本地方法栈、程序计数器） 1.1.1 程序计数器程序计数器可以看作是线程所执行的字节码的行号指示器，记录线程运行到哪一行的位置。 它主要有两个作用： （1）字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 （2）在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候，能够知道该线程上次运行到哪儿了。 ⚠️注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 1.1.2 虚拟机栈平常说的栈内存就是 Java 虚拟机栈，它由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。 栈 局部变量表：主要存放编译期可知的各种数据类型、对象应用。 操作数栈：主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算产生的临时变量也会放在操作数栈中。 动态链接：主要服务一个方法需要调用其他方法的场景。其作用就是为了将符号引用转换为调用方法的直接引用，这个过程被称为动态链接。 动态链接 Java 方法有两种返回方式，一种是 return 语句正常返回，一种是抛出异常。不管哪种返回方式，都会导致栈帧被弹出。也就是说， 栈帧随着方法调用而创建，随着方法结束而销毁。无论方法正常完成还是异常完成都算作方法结束。 会出 StackOverFlowError 和 OOM 这两 个错误。 1.1.3 本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 1.1.4 堆Java 虚拟机所管理的内存中最大的一块，堆是所有线程共享的一块内存区域，在虚拟机启动时创建。 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap）。 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。 JDK 1.7及之前，堆内存通常被分为三部分： 新生代 老年代 永久代 下图所示的 Eden 区、两个 Survivor 区 S0 和 S1 都属于新生代，中间一层属于老年代，最下面一层属于永久代。 堆结构 JDK 1.8及之后，永久代已经被元空间取代，元空间使用的是本地内存。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 S0 或者 S1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 1.1.5 方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 方法区常用的参数有哪些？ 123456//JDK 1.8之前-XX:PermSize=N //方法区 (永久代) 初始大小-XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen//JDK 1.8-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）-XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 1.1.6 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 1.2 方法区和永久代以及元空间是什么关系？方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口。这里类就可以看做是永久代和元空间，接口可以看做是方法区 也就是说永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。 永久代和元空间与方法区的关系 1.3 为什么要将永久代替换为元空间？ 整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小，而且元空间可以动态调整大小。 元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。 1.4 字符串常量池1.4.1 设计思想JVM为了提高性能，减少内存开销，在实例化字符串常量时，进行了一些优化： 为字符串开辟了一个字符串常量池，类似于缓存区； 创建字符串常量时，首先查询字符串常量池中是否存在该字符串； 若存在该字符，返回引用实例，若不存在，实例化该字符串并放入池中； 1.4.2 字符串常量的位置JDK 1.6及之前：有永久代，运行时常量池在永久代，运行时常量池中包含字符串常量池。 JDK 1.7：有永久代，此时字符串常量池已经被分离出来，放在堆中。 JDK 1.8：无永久代，运行时常量池在元空间中，而字符串常量池在堆中。 1.4.3 常见的三种字符串操作及原理分析1String s = &quot;xxx&quot;; 在创建对象s时，JVM会先去常量池中通过equals(key)方法，判断是否有相同的对象： 如果有，则直接返回该对象在常量池中的引用； 如果没有，则会在常量池中创建一个新对象，再返回引用。 这种方式创建的字符串对象，只会在常量池中。s最终指向常量池中的引用。 1String s = new String(&quot;xxx&quot;); 这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，**最后返回堆内存中的对象引用**。 首先会检查字符串常量池中是否存在”xxx”： 不存在，先在字符串常量池中创建一个字符串对象”xxx”，再去堆内存中创建一个字符串对象”xxx”； 存在，直接去堆内存中创建一个字符串对象”xxx”； 最后将堆内存中的引用返回。 注意：如果”xxx”在字符串常量池中存在，那么就只会创建一个对象（在堆中创建），如果不存在，那么会创建两个对象（在堆中和字符串常量池中都创建）。 12String s1 = new String(&quot;xxx&quot;);String s2 = s1.intern(); String中的intern()方法是一个native方法，当调用这个方法时会进行判断： 如果常量池中已经包含一个等于此String对象的字符串（用equals()方法确定），则返回常量池中的字符串，此时指向常量池中的引用； 否则，将intern返回的引用指向当前字符串s1（JDK 1.6版本需要将s1复制到字符串常量池中）。此时指向堆中的引用。 1.4.4 经典面试题（1）下面代码创建了几个对象，最终的结果是什么？ 123String s1 = new String(&quot;he&quot;) + new String(&quot;llo&quot;);String s2 = s1.intern();System.out.println(s1 == s2); 在JDK 1.6环境下输出的是false，一共创建了6个对象，因为s1.intern()会将字符串复制到字符串常量池中，并创建新的对象，返回新对象的引用地址，所以结果为false。 在JDK 1.7及以上版本输出的是true，一共创建了5个对象。因为用了”+”，所以创建了new SrtingBuilder()对象，然后字符串常量池和堆中各创建了2个，所以一共是5个对象。之所以结果是true，是因为s1.intern()返回的是s1对象的引用地址，并没有创建新的对象，所以是true。 （2） 下面程序执行的结果是什么？ 12345String s0 = &quot;ab&quot;;String s1 = &quot;ab&quot;;String s2 = &quot;a&quot; + &quot;b&quot;;System.out.println(s0 == s1);//trueSystem.out.println(s0 == s2);//true 因为s0和s1中”ab”都是字符串常量，它们在编译期就已经被确定了，所以返回true； 而”a”和”b”也都是字符串常量，当一个字符串由多个字符串常量拼接而成时，那么它自己肯定也是字符串常量，所以s2在编译期也被优化为”ab”。 所以s0 &#x3D;&#x3D; s1 &#x3D;&#x3D; s2. （3）字符串常量和字符串对象的比较 123456String s0 = &quot;ab&quot;;String s1 = new String(&quot;ab&quot;);String s2 = &quot;a&quot; + new String(&quot;b&quot;);System.out.println(s0 == s1);//falseSystem.out.println(s0 == s2);//falseSystem.out.println(s1 == s2);//false 因为new String()创建的字符串并不是常量，不能再编译期就确定，所以所创建的字符串返回的是堆中的引用。 s0是字符串常量池中的引用，s1是堆中的引用，所以s0 &#x3D;&#x3D; s1输出的当然是false； 同理s2的后半部分是新创建对象在堆中的引用，所以s0 &#x3D;&#x3D; s2输出的当然是false； s1 会在堆上创建一个新的 String 对象，而 s2 则会在常量池中创建一个新的 String 对象。虽然它们的值都是 &quot;ab&quot;，但是它们的引用不同，因此 s1 == s2 的比较结果是 false。 （4）String字符串不可变 123456String s1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;\t//看jdk版本，5个或者1个String a = &quot;a&quot;;String b = &quot;b&quot;;String c = &quot;c&quot;;String s2 = a + b + c; //会创建一个StringBuilder对象、一个String对象和一个&quot;abc&quot;对象，共三个对象System.out.println(s1 == s2);//false s1等价于String s1 = &quot;abc&quot;，而s2在JVM底层其实是通过StringBuilder中append()方法实现的。 所以在用”+”来拼接引用类型时，会产生新的String对象。 （5）下面的代码创建了几个对象？ 1String s1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;; 在JDK 1.6及之前创建了五个对象，分别是 “a”,“b”,“c”,“ab”,”abc”。因为该版本中字符串常量池在永久代中，永久代的垃圾回收机制是很特殊的，在此区域内的数据是不会被回收的，只有到达临界值会发生Full GC，关闭JVM才会释放内存。 在JDK 1.7及之后创建了一个对象，也即JVM会在编译期进行优化。 1.4.5 总结当字符串用”+”来拼接时，拼接后的字符串是否会生成新的对象，要根据”+”两侧的字符串判断。 如果两侧字符串均为字符串常量，即有确切的常量值，则JVM会在编译期对其进行优化，会将两个字符串常量拼接为一个字符串常量，如果拼接后的字符串常量在字符串常量池中存在的，则不创建对象，如果不存在，则会创建对象。 如果两侧字符串有字符串引用存在，因为引用的值在JVM的编译期是无法确定的，所以”+”无法被JVM编译器进行优化，只有在程序运行期来动态分配，并为凭借后的字符串创建新的对象（分配新的内存地址）。 1.5 说一说Java对象创建的过程？对象创建过程 虚拟机遇到一条new指令时，首先会进行类加载检查： 检查这个指令的参数是否能在常量池中定位到一个类的符号引用； 检查这个符号引用代表的类是否已经被加载、解析和初始化过。如果没有，那么需要先执行相应的类加载过程。 对象所需要的内存大小在类加载之后就可以完全确定，分配内存就相当于把一块确定大小的内存从堆中划出来，具体的分配方式取决于堆内存是否规整，是否规整又取决于所采用的GC收集器是否带有压缩整理功能。 内存分配的两种方式： 指针碰撞 空闲列表内存分配方式 内存分配并发问题（保证线程安全） CAS+失败重试：虚拟机采用 CAS+失败重试的方式保证更新操作的原子性来对分配内存空间的动作进行同步处理。 TLAB：为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一步工作过程也可以提前至TLAB分配时进行。初始化的操作保证了对象实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 初始化零值之后，虚拟机要对对象进行必要的设置，这些设置信息放在对象头中，对象头中包括：MarkWord、数组长度、类型指针。 为对象的属性赋值，执行对象的构造方法。 1.6 说一说对象的内存布局？在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。 对象的内存布局 Hotspot 虚拟机的对象头包括两部分信息，第一部分MarkWord，用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。（只有数组对象才有第三部分，即数组长度部分） 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 1.7 说一说对象的访问定位的方式？建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄和直接指针。 使用句柄：如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 使用句柄 直接指针：如果使用直接指针访问，reference 中存储的直接就是对象的地址。 直接指针 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 HotSpot 虚拟机主要使用的就是直接指针的方式来进行对象访问。 1.8 说一说JVM是由哪些部分组成的，他们的运行流程是什么？JVM有四大组成部分，分别是： 类加载器 运行时数据区 执行引擎 本地库接口 执行流程是： 首先利用IDE，将java源代码.java，编译成.class文件； 类加载器将.class文件加载到jvm中； 再通过执行引擎将字节码翻译成底层系统指令，再交由 CPU 去执行，而这个过程中需要调用其他语言的本地库接口来实现整个程序的功能。 1.9 说一说堆和栈的区别？ 栈内存中一般存储的是局部变量和方法调用，堆内存中存储的是Java对象和数组； 栈不会垃圾回收，堆会进行垃圾回收； 栈是线程私有的，堆是线程共有的； 1.10 哪些区域会造成OOM异常？除了程序计数器，其他五个区域都会造成OOM异常。 2、类加载过程和类加载器2.1 类的生命周期类的生命周期 2.2 类加载过程系统加载 Class 类型的文件主要三步：加载-&gt;连接-&gt;初始化。连接过程又可分为三步：验证-&gt;准备-&gt;解析。 加载的过程主要完成三件事： 通过全类名获取定义此类的二进制字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的Class对象，作为方法区这些数据的访问入口 2.3 类加载器 类加载器是一个负责加载类的对象，用于实现类加载过程中的加载步骤 每个Java类都有个引用指向加载它的ClassLoader 数组类不是通过ClassLoader创建的，是由JVM直接生成的 简单来说，类加载器的主要作用就是加载 Java 类的字节码（ .class 文件）到 JVM 中（在内存中生成一个代表该类的 Class 对象）。 2.3.1 类加载器加载规则JVM 启动的时候，并不会一次性加载所有的类，而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载，这样对内存更加友好。 对于已经加载的类会被放在 ClassLoader 中。在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。也就是说，对于一个类加载器来说，相同二进制名称的类只会被加载一次。 2.3.2 类加载器总结JVM中设置了三个重要的ClassLoader： BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要用来加载 JDK 内部的核心类库（ %JAVA_HOME%/lib目录下的 rt.jar 、resources.jar 、charsets.jar等 jar 包和类）以及被 -Xbootclasspath参数指定的路径下的所有类。 ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类以及被 java.ext.dirs 系统变量所指定的路径下的所有类。 AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。 除了这三种类加载器之外，用户还可以加入自定义的类加载器来进行拓展，以满足自己的特殊需求。就比如说，我们可以对 Java 类的字节码（ .class 文件）进行加密，加载时再利用自定义的类加载器对其解密。 类加载过程 除了 BootstrapClassLoader 是 JVM 自身的一部分之外，其他所有的类加载器都是在 JVM 外部实现的，并且全都继承自 ClassLoader抽象类。这样做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。 每个 ClassLoader 可以通过getParent()获取其父 ClassLoader，如果获取到 ClassLoader 为null的话，那么该类是通过 BootstrapClassLoader 加载的。 12345678910111213141516public class Main&#123; public static void main(String[] args) &#123; ClassLoader classLoader = Main.class.getClassLoader(); StringBuilder split = new StringBuilder(&quot;|--&quot;); boolean needContinue = true; while(needContinue)&#123; System.out.println(split.toString() + classLoader); if (classLoader == null)&#123; needContinue = false; &#125;else&#123; classLoader = classLoader.getParent(); split.insert(0, &quot;\\t&quot;); &#125; &#125; &#125;&#125; 结果： 123|--sun.misc.Launcher$AppClassLoader@18b4aac2\t|--sun.misc.Launcher$ExtClassLoader@1b6d3586 |--null 从输出结果可以看出： 我们编写的 Java 类 Main 的 ClassLoader 是AppClassLoader； AppClassLoader的父 ClassLoader 是ExtClassLoader； ExtClassLoader的父ClassLoader是Bootstrap ClassLoader，因此输出结果为 null 2.3.3 自定义类加载器如果我们要自定义自己的类加载器，很明显需要继承 ClassLoader抽象类。 ClassLoader 类有两个关键的方法： protected Class loadClass(String name, boolean resolve)：加载指定二进制名称的类，实现了双亲委派机制 。name 为类的二进制名称，resove 如果为 true，在加载时调用 resolveClass(Class&lt;?&gt; c) 方法解析该类。 protected Class findClass(String name)：根据类的二进制名称来查找类，默认实现是空方法。 如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法。 2.4 双亲委派模型2.4.1 概念当加载一个类时，先委托其父类加载器（扩展类加载器）进行查找，如果找不到，再委托上层父类加载器（启动类加载器）进行查找，如果找到了，就加载该目标类。 如果所有父类加载器在各自的加载路径下均找不到目标类，则在自己的类加载器（应用程序加载器）路径中查找，并加载该目标类。 总结：向上委派，向下加载 双亲委派模型 注意⚠️：双亲委派模型并不是一种强制性的约束，只是 JDK 官方推荐的一种方式。 类加载器之间的父子关系一般不是以继承的关系来实现的，而是通常使用组合关系来复用父加载器的代码。 2.4.2 底层源码1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; //首先，检查该类是否已经加载过 Class c = findLoadedClass(name); if (c == null) &#123; //如果 c 为 null，则说明该类没有被加载过 long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //当父类的加载器不为空，则通过父类的loadClass来加载该类 c = parent.loadClass(name, false); &#125; else &#123; //当父类的加载器为空，则调用启动类加载器来加载该类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //非空父类的类加载器无法找到相应的类，则抛出异常 &#125; if (c == null) &#123; //当父类加载器无法加载时，则调用findClass方法来加载该类 //用户可通过覆写该方法，来自定义类加载器 long t1 = System.nanoTime(); c = findClass(name); //用于统计类加载器相关的信息 sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; //对类进行link操作 resolveClass(c); &#125; return c; &#125;&#125; 从源码中可以看出整个双亲委派机制的流程： 检查指定名称的类是否已经加载过，如果加载过，就不需要再加载，直接返回。 如果此类没有加载过，那么再判断是否有父加载器，有的话则由父加载器加载，即调用parent.loadClass(name, false);，或者调用启动类加载器来加载。 如果父类加载器和启动类加载器都没有找到指定的类，那么子加载器才会尝试自己加载，即调用当前类的findClass(name)方法来完成类加载。 2.4.3 Java中如何判定两个类是否相同？JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。 只有两者都相同的情况，才认为两个类是相同的。即使两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相同。 2.4.4 为什么要设计双亲委派机制？ 避免类的重复加载。每个类加载器都有自己的命名空间，类加载器之间互相隔离，这样就可以避免在同一个虚拟机中出现两个完全相同的类。如果没有使用双亲委派机制，那么同一个类可能会被不同的类加载器加载多次，这会浪费内存空间，并且也容易引起类之间的兼容性问题。 提高安全性。由于父类加载器可以保证自己加载的类不被子类加载器所替代，这样就可以防止恶意的代码替换掉核心 API 中的类，从而保证了程序的安全性。 简化类加载器的实现。如果每个类都要自己实现类加载的过程，那么会十分繁琐，使用双亲委派机制可以让类加载器只关注自己的加载任务，把加载过程交给父类加载器实现。 2.4.5 如何打破双亲委派机制？自定义加载器的话，需要继承 ClassLoader 。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法。 3、JVM垃圾回收Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap）。 3.1 对象堆内分配3.1.1 对象优先在Eden区分配大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 堆内存中，Eden与Survivor区内存默认比例为8:1:1（堆内存分配原则：让Eden区尽量大，servivor区够用即可） 3.1.2 大对象直接进入老年代大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 大对象直接进入老年代主要是为了避免为大对象分配内存时复制操作（因为新生代中垃圾回收采用的是复制算法）而降低效率。 3.1.3 长期存活的对象将进入老年代虚拟机给每个对象一个对象年龄（Age）计数器。 大部分情况，对象都会首先在 Eden 区域分配。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间（s0 或者 s1）中，并将对象年龄设为 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)。 对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁，不同垃圾收集器不同），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 3.1.4 对象动态年龄判断对象动态年龄判断机制一般是Minor GC之后触发。 当一批对象的总大小 ≥ Survivor区域内存大小的50%（这个值可以通过-XX:TargetSurvivorRatio指定），那么此时大于等于这批对象中年龄最大的其他对象，就可以直接进入老年代了。目的是让那些可能是长期存活的对象，尽早进入老年代。 3.1.5 空间分配担保空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。 3.2 对象死亡的判断方法（垃圾判断算法）其实就是对象的回收，释放掉在内存中已经没用的对象。 有两种方法：引用计数法和根可达性分析算法 3.2.1 引用计数法给对象中添加一个引用计数器： 每当有一个地方引用它，计数器就加 1； 当引用失效，计数器就减 1； 任何时候计数器为 0 的对象就是不可能再被使用的。 计数器值为0的对象就是要被回收的对象。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 循环引用问题：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 3.2.2 根可达性分析算法通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。 下图中的 Object 6 ~ Object 10 之间虽有引用关系，但它们到 GC Roots 不可达，因此为需要被回收的对象。 根可达性分析法 哪些对象可以作为GC Roots？ 虚拟机栈中引用的对象 本地方法栈中引用的对象 方法区中类静态变量 方法区中常量 持有同步锁的对象 常驻异常对象 引用类型JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 强引用：普通引用变量，比如new出来的对象。无论内存是否足够，都不会回收。 软引用：当GC内存不足时，会回收该对象。 弱引用：GC会直接回收。 虚引用：GC会直接回收，主要用来跟踪对象被垃圾回收的活动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 3.2.4 如何判断一个类是无用的类？同时满足以下三个条件，就是无用的类： 该类的所有实例都已经被回收，也即Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 3.2.5 如何判断一个常量是废弃常量？ 常量没有被任何对象引用。 常量所在的类已经被加载，而且加载的Class对象已经被引用。 3.3 垃圾收集算法3.3.1 标记清除算法首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。 优点：删除较快，简单高效。 缺点：产生内存碎片（内存不连续）；当老年代对象过多时，效率较慢。 标记清除算法 3.3.2 标记复制算法它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 优点：不会出现内存碎片问题，简单高效。 缺点：浪费空间，移动对象的开销大。 标记复制算法 3.3.3 标记整理算法根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 优点：消除了清除算法中内存不连续的问题，消除了复制算法中内存减半的高额代价。 缺点：移动对象的开销较大。 标记整理算法 3.3.4 分代收集算法当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。 在老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 为什么虚拟机要分新生代和老年代？当前虚拟机的垃圾收集都采用分代收集算法，这种算法需要根据对象存活周期的不同将内存分为几块。所以JVM将堆分为新生代和老年代，这样就可以根据各个年代的特点选择合适的垃圾收集算法，更好地管理内存、提高垃圾回收效率。 3.4 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 3.4.1 Serial收集器这个收集器是一个单线程收集器，它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 简单而高效（与其他收集器的单线程相比） 新生代采用标记-复制算法，老年代采用标记-整理算法。 Serial 收集器 3.4.2 ParNew收集器ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。 新生代采用标记-复制算法，老年代采用标记-整理算法。 老年代GC采用的是串行方式收集。 ParNew 收集器 3.4.3 Parallel Scavenge收集器Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 新生代采用标记-复制算法，老年代采用标记-整理算法。 可以设置老年代的收集方式： 1234-XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行-XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 这是 JDK1.8 默认收集器 Parallel Old收集器运行示意图 3.4.4 Serial Old收集器Serial 收集器的老年代版本，它同样是一个单线程收集器。 Serial 收集器 它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 3.4.5 Parallel Old收集器Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。 在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。 Parallel Old收集器运行示意图 3.4.6 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。 CMS 收集器 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 3.4.7 G1收集器G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器。以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征. 它具备以下特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清除”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 G1 收集器 G1 收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 3.4.8 ZGC收集器与 CMS 中的 ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。 在 ZGC 中出现 Stop The World 的情况会更少！ 3.5 Minor Gc 和 Full GC 有什么不同呢？Minor GC 也称为新生代垃圾回收，指的是清理新生代内存区域中不再被引用的对象。一般来说，新生代中存活时间较短的对象被回收的概率较高。Minor GC 通常比较快速，并且不会对整个堆空间产生影响。 Full GC 则是对整个 Java 堆空间进行垃圾回收，包括新生代和老年代。Full GC 一般比较耗时，会暂停整个应用程序的运行，对性能有较大的影响。 需要注意的是，Full GC 的触发条件通常比较严格，一般是当新生代没有足够空间存放新对象，或老年代空间不足，或永久代空间不足等情况下才会触发。而 Minor GC 触发的条件相对较为宽松，一般是当新生代中的对象数量超过了新生代的容量限制时就会触发。 因此，Minor GC 和 Full GC 的主要区别在于执行的范围和影响程度。Minor GC 通常只涉及新生代空间，对整个应用程序的影响较小；而 Full GC 涉及整个堆空间，会导致整个应用程序暂停，对性能有较大的影响。 3.6 三色标记算法三色标记算法是一种JVM垃圾标记的算法，它可以减少JVM在GC过程中的STW时长，是CMS、G1等垃圾收集器中主要使用的标记算法。 3.6.1 为什么需要三色标记算法？三色标记算法之前JVM主要使用的是根可达性算法，但是根可达性算法存在一些问题： 误标记的问题。在多线程环境下，如果一个线程正在遍历对象图，而此时另一个线程正在修改图，就会出现遍历结果不可靠的问题。 STW时间长。根可达性算法的整个过程都需要STW，但是这会导致GC过程中应用程序的卡顿时间也很长，从而影响系统的整体性能。 3.6.2 三色标记法中三色对应的状态三色标记法将对象的状态通过：白色、灰色、黑色三种颜色表示。 白色：表示对象尚未被GC访问过。如果全部标记完成后，对象仍为白色，那表示这个对象就是需要回收的对象； 灰色：表示对象已经被GC访问过，但至少存在一个引用没有被扫描过。属于中间状态； 黑色：表示对象已经被GC访问过，且对象的所有引用都被扫描过。 3.6.3 三色标记法标记的过程三色标记法 初始时，所有对象都是白色，都放到白色集合中； 将GC Roots直接引用的对象都设置为灰色，并且放到灰色集合中； 遍历所有灰色对象： 如果灰色的对象没有其他引用，就将该对象标记为黑色，并将该对象从灰色集合中移到黑色集合中； 如果灰色对象有其他引用的对象，就将引用的对象标记为灰色，并将引用的对象移到灰色集合中，然后将该对象标记为黑色，并移动到黑色集合中。 然后继续重复步骤3，直到所有标记结束，在白色集合中的对象就是需要回收的对象。 3.6.4 三色标记法的缺陷 多标，多标会产生浮动垃圾。在并发标记的过程中，如果由于方法运行结束导致部分局部变量（GC Roots）被销毁，这个GC Roots引用的对象之前又被标记为非垃圾对象，那么本轮GC就不会回收这个对象。而这些本应该被回收，但是没有回收的内存，就被称为浮动垃圾。 解决方案：浮动垃圾并不会影响垃圾回收的正确性，只是需要等到下一轮GC才能被清除。 漏标，漏标会导致被引用的对象被当成垃圾误删除。 解决方案： 增量更新：当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束后，再以这些记录过的引用关系中的黑色对象为Root，重新扫描一次。可以简单理解为：黑色对象一旦新插入指向白色对象的引用后，就变回灰色对象了，然后又继续遍历扫描。 原始快照：当灰色对象要删除指向白色对象的引用关系时，就将要删除的引用记录下来，在并发扫描结束后，再以这些记录过的灰色对象为Root，重新扫描一次，这样就能扫描到白色对象，将白色对象直接标记为黑色。 3.6.5 为什么G1用原始快照，CMS用增量更新？原始快照比增量更新效率会更高，但是缺点是会造成更多的浮动垃圾。 因为原始快照不需要在重新标记阶段再次深度扫描被删除的引用对象，而CMS对增量引用的跟对象会做深度扫描，重新深度扫描对象的话G1的代价会比CMS代价更高，所以G1选择原始快照，不深度扫描对象，只是简单标记，等下一轮GC再深度扫描。 4、JVM调优4.1 JVM调优的参数可以在哪里设置？ war包部署在Tomact中设置，可以修改TOMCAT_HOME&#x2F;bin&#x2F;catalina.sh文件 jar包部署在启动参数设置，通过命令java -Xms512m -Xmx1024m -jar xxxx.jar 4.2 常用的调优参数有哪些？4.2.1 调整最大堆内存和最小堆内存-Xmx：指定 java 堆最大值（默认值是物理内存的 1&#x2F;4(&lt;1GB)） -Xms：初始 java 堆最小值（默认值是物理内存的 1&#x2F;64(&lt;1GB)) 开发过程中，通常会将 -Xms 与 -Xmx 两个参数配置成相同的值，其目的是为了能够在 java 垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。 4.2.2 调整虚拟机栈的设置每个线程默认会开启1M的内存，用于存放栈帧、参数、局部变量等，一般256k就够用了。 -Xss：对每个线程stack大小的调整，比如-Xss128k 4.2.3 调整新生代和老年代的比值-XX:NewRatio — 新生代（eden+2*Survivor）和老年代（不包含永久区）的比值 例如：-XX:NewRatio&#x3D;4，表示新生代:老年代&#x3D;1:4，即新生代占整个堆的 1&#x2F;5。在 Xms&#x3D;Xmx 并且设置了 Xmn 的情况下，该参数不需要进行设置。 4.2.4 调整Survivor区和Eden区的比值-XX:SurvivorRatio（幸存代）— 设置两个 Survivor 区和 Eden 的比值 例如：8，表示两个 Survivor:Eden&#x3D;2:8，即一个 Survivor 占年轻代的 1&#x2F;10 4.3.5 设置年轻代晋升老年代的阈值-XX:MaxTenuringThreshold=thrshold 默认值是15，取值范围为[0, 15]。 4.3.6 设置垃圾回收器-XX:+UseParallelGC -XX:+UseParallelOldGC 4.3.6 设置年轻代和老年代的大小-XX:NewSize — 设置年轻代大小 -XX:MaxNewSize — 设置年轻代最大值 -XX:OldSize — 设置老年代大小 4.3.7 设置元空间大小-XX:MetaspaceSize — 设置元空间初始化大小，64位JVM默认为20.75M -XX:MaxMetaspaceSize — 设置元空间最大大小，逻辑限制为内存上限 一般建议在JVM中将这两个设置为一样的值，并且设置的要比默认初始值更大，对于8G内存的机器来说，一般会设置为256M。 4.3.8 一台8G内存的机器JVM的参数怎么设置？java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorR atio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0 4.3 JVM常用调优工具？ 命令工具 jps：进程状态信息 jstack：查看java进程内线程的堆栈信息 jmap：查看堆转内存快照、内存使用情况 jhat：堆转储快照分析工具 jstat：JVM统计监测工具 可视化工具： jconsole：用于对jvm的内存、线程、类的监控 VisualVM：能够监控线程、内存情况 4.4 Java内存泄漏的排查思路？ 获取堆内存的dump文件； 使用jmap命令获取； 使用vm参数获取； 通过工具（比如VisualVM）分析dump文件； 通过查看堆信息，可以大概定位具体的代码行； 找到对应的代码行进行修复。 4.5 CPU飙高排查思路？ 使用top命令查看cpu的占用情况； 找到哪个进程占用的cpu较高； 使用jps命令查看进程中的线程信息； 使用jstack命令查看具体的进程中哪些线程出现了问题，然后定位问题。","tags":["Java","八股","基础","面试"],"categories":["Java八股","基础"]},{"title":"3.Java多线程","path":"/2023/06/20/3-Java多线程/","content":"1、进程和线程进程：是程序的一次执行过程，是系统运行的基本单位，是操作系统资源分配的基本单位。线程：比进程更小的执行单位，是处理器任务调度和执行的基本单位，一个进程可以包含多个线程。多个线程可以共享进程的堆和方法区资源。 1.1 从JVM角度理解进程与线程区别Java 虚拟机的运行时数据区包含堆、方法区、虚拟机栈、本地方法栈、程序计数器。 各个进程之间是相互独立的，每个进程会包含多个线程，每个进程所包含的多个线程并不是相互独立的，这个线程会共享进程的堆和方法区，但这些线程不会共享虚拟机栈、本地方法栈、程序计数器。如下图所示，假设某个进程包含三个线程。 运行时数据区 内存分配：进程之间地址空间和资源是相互独立的，同一个进程之间的线程会共享进程的地址空间和资源。 资源开销：每个进程具备各自的数据空间，进程之间的切换会有较大的开销。属于同一进程的线程会共享堆和方法区，同时具备私有的虚拟机栈、本地方法栈、程序计数器，线程之间切换资源开销较小，但不利于资源的管理和保护。 1.2 虚拟机栈、本地方法栈和程序计数器为什么是私有的？ 虚拟机栈： 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 本地方法栈： 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 程序计数器主要有下面两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。 1.3 什么是堆和方法区？堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 2、几个区别2.1 并发与并行的区别 并发：一个处理器处理多个任务，按时间片轮流处理多个任务。 并行：单位时间多个处理器同时处理多个任务。 并行与并发 2.2 同步与异步的区别 同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。 异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而，异步方法通常会在另外一个线程中，“真实”地执行着。整个过程，不会阻碍调用者的工作。 3、多线程的优缺点 优点：当一个线程进入等待状态或者阻塞时，CPU 可以先去执行其他线程， 提高 CPU 的利用率。 缺点： 上下文切换。频繁的上下文切换会影响多线程的执行速度。 死锁。多线程并发执行可能会产生死锁。 受资源限制。程序执行的速度受限于计算机的硬件或软件资源。 4、什么是线程的上下文切换？即便是单核的处理器也会支持多线程，处理器会给每个线程分配 CPU 时间片来实现这个机制。 时间片是 CPU 分配给每个线程的执行时间，一般来说时间片非常的短，所以处理器会不停地切换线程。 CPU 会通过时间片分配算法来循环执行任务，当前任务执行完一个时间片后会切换到下一个任务，但切换前会保存上一个任务的状态，因为下次切换回这个任务时还要加载这个任务的状态继续执行，从任务保存到再加载的过程就是一次上下文切换。 5、守护线程和用户线程区别 用户线程：平时用到的线程均为用户线程。 守护线程：用来服务用户线程的线程，例如垃圾回收线程。 任何线程都可以设置为守护线程和用户线程，通过方法 Thread.setDaemon(boolean on)设置，true 则是将该线程设置为守护线程，false 则是将该线程设置为用户线程。同时，Thread.setDaemon()必须在 Thread.start()之前调用，否则运行时会抛出异常。 守护线程和用户线程的主要区别在于线程结束后 Java 虚拟机是否结束。 用户线程：当任何一个用户线程未结束，Java 虚拟机是不会结束的。 守护线程：如果只剩守护线程未结束，Java 虚拟机是会结束的。 6、死锁、活锁、饥饿 死锁：由于两个或两个以上的线程相互竞争对方的资源，而同时不释放自己的资源，导致所有线程同时被阻塞。 活锁：任务执行时没有被阻塞，由于某些条件没有被满足，导致线程一直重复尝试、失败、尝试、失败。例如，线程 1 和线程 2 都需要获取一个资源，但他们同时让其他线程先获取该资源，两个线程一直谦让，最后都无法获取。 饥饿：以打印机打印文件为例，当有多个线程需要打印文件，如果系统按照短文件优先的策略进行打印，但当短文件的打印任务一直不间断地出现，那长文件的打印任务会被一直推迟，导致饥饿。 产生饥饿的原因：高优先级的线程占用了低优先级线程的CPU时间。 6.1 死锁的四个必要条件 互斥条件：一个资源在同一时刻只由一个线程占用。 请求与保持条件：一个线程在请求被占资源时发生阻塞，并对已获得的资源保持不放。 循环等待条件：发生死锁时，所有的线程会形成死循环，一直阻塞。 不可剥夺条件：线程已获得的资源在未使用完的情况下，不能被其他线程剥夺，只能由自己使用完释放资源。 123456789101112131415161718192021222324252627282930313233343536private static Object resource1 = new Object();private static Object resource2 = new Object();public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1)&#123; //返回当前正在执行的线程对象 System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;wait get resource2&quot;); synchronized (resource2)&#123; System.out.println(Thread.currentThread() + &quot;get resource2&quot;); &#125; &#125; &#125;, &quot;线程 1&quot;).start(); new Thread(() -&gt; &#123; synchronized (resource2)&#123; //返回当前正在执行的线程对象 System.out.println(Thread.currentThread() + &quot;get resource2&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;wait get resource1&quot;); synchronized (resource1)&#123; System.out.println(Thread.currentThread() + &quot;get resource1&quot;); &#125; &#125; &#125;, &quot;线程 2&quot;).start();&#125; 运行结果： 运行结果 线程1通过synchronized(resource1)获得resource1的监视器锁，然后通过Thread.sleep(1000)，让线程1休眠1s，为的是让线程2行动，然后获取到resource2的监视器锁。线程1和线程2休眠结束后，都开始企图获取对方的资源，然后这两个线程都会陷入互相等待的状态，于是产生了死锁。 6.2 如何预防和避免死锁?6.2.1 如何预防死锁？破坏死锁产生的必要条件即可： 破坏请求与保持条件：一次性申请所有资源。 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它所占有的资源。 破坏循环等待条件：按照顺序申请资源。比如按某一顺序申请资源，释放资源时则反序释放。 6.2.2 如何避免死锁？在资源分配时，借助算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。将上面线程2的代码改成下面这样就不会产生死锁了 123456789101112131415new Thread(() -&gt; &#123; synchronized (resource1)&#123; //返回当前正在执行的线程对象 System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;wait get resource2&quot;); synchronized (resource2)&#123; System.out.println(Thread.currentThread() + &quot;get resource2&quot;); &#125; &#125;&#125;, &quot;线程 2&quot;).start(); 运行结果 6.3 死锁、活锁、饥饿的区别 活锁是在不断尝试，而死锁是一直在等待； 活锁有可能自行解开，而死锁无法自行解开； 饥饿可以自行解开，而死锁不行； 7、线程的生命周期线程的生命周期 线程创建后将处于NEW初始状态，调用start()方法后开始运行，此时线程处于READY就绪状态。 可运行状态的线程获取CPU时间片后就处于RUNNING运行中状态。 当线程执行wait()方法后，线程进入WATING等待状态，进入等待状态的线程需要依靠其他线程的通知才能返回到运行状态，而TIMED_WATING超时等待状态相当于在等待状态的基础上增加了超时限制，比如通过sleep(long millis)方法或者wait(long millis)方法可以将Java线程置于超时状态。 当超时时间到达后Java线程将会回到RUNNABLE状态。 当线程调用同步方法时，在没有获取到锁的情况下，线程会进入BLOCKED阻塞状态，一直到获取到锁。 线程在执行RUNNABLE的run()方法后会进入到TERMINATED终止状态。 8、创建线程的方式？8.1 继承Thread类创建线程首先继承Thread类，重写run()方法，在main()函数中调用子类实例的start()方法。 1234567891011121314class ThreadDemo extends Thread&#123; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + &quot;run()方法正在执行&quot;); &#125;&#125;public class Main&#123; public static void main(String[] args) &#123; ThreadDemo threadDemo = new ThreadDemo(); threadDemo.start(); System.out.println(Thread.currentThread().getName() + &quot;main()方法执行结束&quot;); &#125;&#125; 运行结果 8.2 实现Runnable接口创建线程首先创建实现Runnable接口的类RunnableDemo，重写run()方法；创建类RunnableDemo的实例对象runnableDemo，以此为参数创建Thread对象，调用start()方法。 123456789101112131415class RunnableDemo implements Runnable&#123; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + &quot;run()方法正在执行&quot;); &#125;&#125;public class Main&#123; public static void main(String[] args) &#123; RunnableDemo runnableDemo = new RunnableDemo(); Thread thread = new Thread(runnableDemo); thread.start(); System.out.println(Thread.currentThread().getName() + &quot;main()方法执行结束&quot;); &#125;&#125; 8.3 使用Callable和Future创建线程 创建Callable接口的实现类CallableDemo，重写call()方法。 以类CallableDemo的实例化对象作为参数创建FutureTask对象。 以FutureTask对象作为参数创建Thread对象。 调用Thread对象的start()方法。 123456789101112131415161718class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println(Thread.currentThread().getName() + &quot;call()方法执行中&quot;); return null; &#125;&#125;public class Main&#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; CallableDemo callableDemo = new CallableDemo(); FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(callableDemo); Thread thread = new Thread(integerFutureTask); thread.start(); System.out.println(&quot;返回结果&quot; + integerFutureTask.get()); System.out.println(Thread.currentThread().getName() + &quot;main()方法执行结束&quot;); &#125;&#125; 8.4 使用线程池例如Executor框架，可以提供四种线程池： newCachedThreadPool创建一个可缓存的线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool创建一个定长的线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool创建一个定长的线程池，支持定时及周期性任务执行。 newSingleThreadExecutor创建一个单线程化的线程池，只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。 123456789101112131415161718192021222324252627282930class ThreadDemo extends Thread&#123; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + &quot; 正在执行&quot;); &#125;&#125;public class Main&#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //创建一个可重用固定长度的线程池 ExecutorService fixedThreadPool = Executors.newFixedThreadPool(2); //实现接口 ThreadDemo t1 = new ThreadDemo(); ThreadDemo t2 = new ThreadDemo(); ThreadDemo t3 = new ThreadDemo(); ThreadDemo t4 = new ThreadDemo(); ThreadDemo t5 = new ThreadDemo(); //将线程放入池中执行 fixedThreadPool.execute(t1); fixedThreadPool.execute(t2); fixedThreadPool.execute(t3); fixedThreadPool.execute(t4); fixedThreadPool.execute(t5); //关闭线程池 fixedThreadPool.shutdown(); &#125;&#125; image.png 9、runnable和callable区别相同点： 两者都是接口； 都需要调动Thread.start()启动线程。 不同点： callable的核心是call()方法，允许返回值；而runnable的核心是run()方法，没有返回值。 call()方法可以抛出异常，但是run()方法不行。 callable和runnable都可以应用于executors，但Thread类只支持runnable。 10、start()和run()10.1 两者区别 线程是通过Thread对象所对应的方法run()来完成其操作的，而线程的启动是通过start()方法执行。 run()方法可以重复调用，start()方法只调用一次。 10.2 为什么调用start方法时会执行run方法，而不直接执行run方法？当 new 一个 Thread 时，线程进入了新建状态。 调用 start()方法，会启动一个线程并使线程进入就绪状态，当分配到时间片后就可以开始运行了。start()会执行线程的相应准备工作，然后自动执行run()方法的内容，这是真正的多线程工作。 但是，如果直接执行 run() 方法，会把 run() 方法当成一 个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结：调用 start()方法才可以启动线程并使线程进入就绪状态，直接执行run()方法的话不会以多线程的方式执行。 11、线程同步和调度的方法（对线程的控制方法） wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁。 sleep()：使当前线程进入指定毫秒数的休眠，暂停执行，需要处理异常InterruptedException，不会释放持有的锁。 notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能精准的唤醒某一个等待的线程，而是JVM确定唤醒哪个线程，与优先级无关。 notifyAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态。 join()：与sleep()方法一样，是一个可中断的方法，在一个线程中调用另一个线程的join()方法，会使得当前的线程挂起，直到执行join()方法的线程结束。例如在B线程中调用A线程的join()方法，B线程进入了阻塞状态，直到A线程结束或者到达指定时间。 yield()：提醒调度器当前线程愿意放弃当前的CPU资源，使得当前线程从运行状态切换到就绪状态。 12、sleep()和yield()区别 sleep()方法会使得当前线程暂停指定的时间，没有消耗CPU时间片。 sleep()使得线程进入阻塞状态，yield()方法只是对CPU进行提示，如果CPU没有忽略这个提示，会使得线程上下文的切换，进入到就绪状态。 sleep()需要抛出异常，而yield()不需要抛出异常。 sleep()会完成给定的休眠时间，yield()不一定。 13、sleep()和wait()的区别相同点： 都能使线程进入到等待状态。 都是可中断方法，被中断后都会收到中断异常。 不同点： wait()是Object方法，sleep()是Thread方法。 wait()必须在同步方法中进行，sleep()不需要。 线程同步方法中执行sleep()不会释放monitor的锁，而wait()方法会释放monitor的锁。 sleep()方法在短暂的休眠后会主动退出阻塞，而wait()方法在没有指定时间的情况下，需要被其他线程中断才可以退出阻塞。 14、线程间通信方式 共享变量：多个线程通过访问共享变量来实现通信。一般情况下需要使用 synchronized 或者 volatile 来保证共享变量的可见性和原子性。 wait/notify：多个线程之间通过调用对象的 wait() 和 notify() 方法来实现通信。其中，wait() 方法会让当前线程进入等待状态，并且释放对象的锁；而 notify() 方法会唤醒等待队列中的某个线程，让其进入就绪状态。 Condition：Condition 接口提供了类似 wait&#x2F;notify 的功能，但是相比之下更加灵活。通过 Condition 接口的 await() 和 signal() 方法，可以实现多个线程之间的等待和唤醒操作。 管道：通过管道实现线程之间的通信。一般情况下，需要使用 PipedInputStream 和 PipedOutputStream 来实现管道流。 队列：线程间可以通过队列来传递数据。一个线程将数据放入队列的一端，另一个线程从队列的另一端取出数据。常用的队列实现包括BlockingQueue、ConcurrentLinkedQueue等。 15、如何实现线程同步和互斥？线程互斥：指某一个资源只能被一个访问者访问，具有唯一性和排他性。但访问者对资源访问的顺序是乱序的。线程同步：指在互斥的基础上使得访问者对资源进行有序访问。线程同步的实现方法： 同步方法 同步代码块 wait()和notify() 使用volatile实现线程同步 使用重入锁实现线程同步 使用局部变量实现线程同步 使用阻塞队列实现线程同步 16、线程安全16.1 什么是线程安全？线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。 16.2 如何保证线程安全？ 使用同步锁。用synchronized关键字或ReentrantLock类对共享资源加锁，保证同一时刻只有一个线程能够访问共享资源。 使用volatile关键字，保证共享变量的可见性和禁止指令重排。 使用线程安全的类。 16.3 线程安全体现在什么方面？ 原子性：对共享变量互斥访问，同一个时刻只能有一个线程对数据操作； 可见性：当一个线程修改主内存后，其他变量能及时看到； 有序性：一个线程中的指令执行是有序的。 17、如何让三个线程T1、T2、T3按顺序执行这类问题？这是一道面试中常考的并发编程代码题，类似的题还有： 三个线程T1、T2、T3轮流打印ABC，打印n次，如ABCABCABC…… 两个线程交替打印1-100的奇偶数 N个线程循环打印1-100 …… 其实这类问题的本质都是线程通信问题，思路基本上都是一个线程执行完，阻塞该线程，唤醒其他线程，然后按顺序执行下一个线程。 17.1 如何按顺序执行三个线程？17.1.1 synchronized + wait&#x2F;notify1234567891011121314151617181920212223242526272829303132private int num;private static final Object LOCK = new Object();private void printABC(String name, int targetNum)&#123; synchronized (LOCK)&#123; //让其他线程陷入阻塞状态 while (num % 3 != targetNum)&#123; try &#123; LOCK.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; num++; System.out.print(name); //唤醒所有线程 LOCK.notifyAll(); &#125;&#125;public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(&quot;A&quot;,0); &#125;, &quot;A&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;B&quot;,1); &#125;, &quot;B&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;C&quot;,2); &#125;, &quot;C&quot;).start();&#125; 17.2 三个线程轮流打印n次ABC这个只需要在上面代码的基础上，加一个n次的循环即可 1234567891011121314151617private void printABC(String name, int targetNum)&#123; //加个循环 for (int i = 0; i &lt; 10; i++) &#123; synchronized (LOCK)&#123; while (num % 3 != targetNum)&#123; try &#123; LOCK.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; num++; System.out.print(name); LOCK.notifyAll(); &#125; &#125;&#125; image.png 基本思路：A B C三个线程同时启动，因为变量num的初始值为0，所以线程B、C拿到锁后，进入while()循环，然后执行wait()方法，线程阻塞，释放锁。只有A拿到锁后，不仅如此while()循环，执行num++，打印字符A，最后唤醒其他两个线程。这个时候变量num为1，所以线程B拿到锁后，不被阻塞，执行num++，打印字符B，最后唤醒其他两个线程。后面打印字符C也是相同的流程。 17.2.1 join()方法join()方法：在A线程中调用了B线程的join()方法时，表示只有当B线程执行完毕时，A线程才能继续执行。基于这个原理，我们可以使得三个线程按照顺序执行，然后循环多次即可。无论三个线程谁先谁后，顺序最后都是A-B-C。 123456789101112131415161718192021222324252627282930static class printABC implements Runnable&#123; private Thread beforeThread; public printABC(Thread beforeThread)&#123; this.beforeThread = beforeThread; &#125; @Override public void run() &#123; if (beforeThread != null)&#123; try &#123; beforeThread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.print(Thread.currentThread().getName()); &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10; i++) &#123; Thread t1 = new Thread(new printABC(null), &quot;A&quot;); Thread t2 = new Thread(new printABC(t1), &quot;B&quot;); Thread t3 = new Thread(new printABC(t2), &quot;C&quot;); t1.start(); t2.start(); t3.start(); Thread.sleep(10); &#125;&#125; 使用join好处就是不论三个线程启动的顺序咋样，线程B只会在A线程执行完后，才会执行，C只会在B执行完后执行。 17.2.2 Lock锁其实原理一样，使用lock锁 123456789101112131415161718192021222324252627private int num; //当前状态值：保证三个线程之间交替打印private Lock lock = new ReentrantLock();private void printABC(String name, int targetNum)&#123; for (int i = 0; i &lt; 10;) &#123; lock.lock(); if (num % 3 == targetNum)&#123; num++; i++; System.out.print(name); &#125; lock.unlock(); &#125;&#125;public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(&quot;A&quot;,0); &#125;, &quot;A&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;B&quot;,1); &#125;, &quot;B&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;C&quot;,2); &#125;, &quot;C&quot;).start();&#125; 17.2.3 Lock+Condition精准唤醒12345678910111213141516171819202122232425262728293031323334353637private int num; //当前状态值：保证三个线程之间交替打印private static Lock lock = new ReentrantLock();private static Condition c1 = lock.newCondition();private static Condition c2 = lock.newCondition();private static Condition c3 = lock.newCondition();private void printABC(String name, int targetNum, Condition currentThread, Condition nextThread)&#123; for (int i = 0; i &lt; 10;) &#123; lock.lock(); try &#123; while (num % 3 != targetNum) &#123; currentThread.await(); &#125; num++; i++; System.out.print(name); nextThread.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125;public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.printABC(&quot;A&quot;,0, c1, c2); &#125;, &quot;A&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;B&quot;,1, c2, c3); &#125;, &quot;B&quot;).start(); new Thread(() -&gt; &#123; main.printABC(&quot;C&quot;,2, c3, c1); &#125;, &quot;C&quot;).start();&#125; 17.3 两个线程交替打印1-100的奇偶数基本思路：也是用synchronized+wait方法进行打印当数字是奇数时，打印数字，然后唤醒另一个线程打印偶数。 123456789101112131415161718192021222324252627282930private int num = 1; //全局计数器，从1开始private final Object Lock = new Object(); //用于线程同步的锁public void print(int targetNum)&#123; synchronized (Lock)&#123; while (num &lt;= 100)&#123; if ((num % 2) == targetNum)&#123; //如果是要求的数，就打印 System.out.print(num + &quot; &quot;); num++; Lock.notifyAll(); //打印完然后唤醒另一个线程 &#125;else&#123; //否则就释放锁，并等待 try &#123; Lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.print(0); &#125;).start(); new Thread(() -&gt; &#123; main.print(1); &#125;).start();&#125; 17.4 N个线程循环打印1-100当N为4时，循环打印1-100，解决方法一样的 123456789101112131415161718192021222324252627282930313233343536private int num = 1; //全局计数器，从1开始private final Object Lock = new Object(); //用于线程同步的锁public void print(int targetNum)&#123; synchronized (Lock)&#123; while (num &lt;= 100)&#123; if ((num % 4) == targetNum)&#123; //如果是要求的数，就打印 System.out.print(num + &quot; &quot;); num++; Lock.notifyAll(); //打印完然后唤醒另一个线程 &#125;else&#123; //否则就释放锁，并等待 try &#123; Lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; Main main = new Main(); new Thread(() -&gt; &#123; main.print(0); &#125;).start(); new Thread(() -&gt; &#123; main.print(1); &#125;).start(); new Thread(() -&gt; &#123; main.print(2); &#125;).start(); new Thread(() -&gt; &#123; main.print(3); &#125;).start();&#125; 18、synchronized关键字18.1 什么是synchronized关键字多个线程同时访问共享资源时会出现一些问题，而synchronized关键字是用来保证线程同步的。 18.2 Java内存的可见性问题在了解 synchronized 关键字的底层原理前，需要先简单了解下 Java 的内存模型，看看 synchronized 关键字是如何起作用的。 内存模型 18.2.1 什么是内存不可见问题？Java中内存不可见问题是指当多个线程访问同一共享变量时，一个线程修改了这个变量的值，其他线程可能无法立即看到修改后的值，从而出现数据不一致的问题。 这是因为每个线程都有自己的工作内存，线程间共享变量时，为了提高性能，JVM会把变量缓存到每个线程的本地工作内存中，而不是直接读取主内存中的值。当一个线程修改了共享变量的值时，修改后的值可能还没有同步到主内存中，其他线程读取的仍是旧值，从而导致数据不一致。 18.2.2 synchronized关键字是怎么解决的？其实 synchronized 就是把在 synchronized 块内使用到的变量从线程的本地内存中擦除，这样在 synchronized 块中再次使用到该变量就不能从本地内存中获取了，需要从主内存中获取，确保变量的修改和读取都在主内存中进行，避免了了内存不可见问题。 18.3 synchronized关键字三大特性？ 原子性：一个或多个操作要么全部执行成功，要么全部执行失败。synchronized关键字可以保证只有一个线程拿到锁，访问共享资源。 可见性：当一个线程对共享变量进行修改之后，其他线程就可以立刻看到。执行synchronized时，会对应执行lock、unlock原子操作，保证可见性。 有序性：程序的执行顺序会按照代码的先后顺序执行。 18.4 synchronized关键字可以实现什么类型的锁？ 悲观锁：每次访问共享资源时都会上锁。 非公平锁：线程获取锁的顺序并不一定是按照线程阻塞的顺序。 可重入锁：已经获取锁的线程可以再次获取锁。 独占锁&#x2F;排他锁：该锁只能被一个线程所持有，其他线程均被阻塞。 18.4.1 可重入锁的原理知道吗？简单来说，当线程请求一个由其它线程持有的对象锁时，该线程会阻塞；而当线程请求由自己持有的对象锁时，如果该锁是重入锁，请求就会成功，否则阻塞。 可重入锁实现的原理是：每一个锁关联一个线程id和重入次数计数器， 当计数器为 0 时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法； 当某一线程请求成功后，JVM会记下锁的持有线程id，并且将计数器置为 1； 如果此时其它线程请求该锁，则必须等待； 如果该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时重入次数计数器会递增； 如果该线程退出同步代码块时，计数器会递减，如果计数器为 0，则释放该锁。 18.5 使用方式 修饰普通同步方法：给当前对象实例加锁； 修饰静态同步方法：给当前类加锁； 修饰同步方法块：给指定对象或类加锁； 18.5.1 修饰普通同步方法123synchronized void method()&#123; //业务代码&#125; 给当前对象实例加锁，进入同步代码前要获得当前对象实例的锁。 18.5.2 修饰静态同步方法123synchronized static void method()&#123; //业务代码&#125; 修饰静态同步方法也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得当前 class 的锁。因为静态成员不属于任何一个实例对象，是类成员(static 表明这是该类的一个静态资源，不管 new 了多少个对象， 只有一份)。所以，如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法是允许的，不会发生互斥现象.因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 18.5.3 修饰同步方法块123synchronized(this)&#123; //业务代码&#125; 修饰同步方法块，表示对给定对象&#x2F;类加锁。synchronized(this|object) 表示进入同步代码库前要获得给定对象的锁。synchronized(类.class)表示进入同步代码前要获得当前 class 的锁。 18.6 底层原理synchronized关键字底层原理属于JVM层面的东西。 18.6.1 修饰同步语块的情况通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class synchronized关键字原理 从上面可以看出synchronized同步语块的实现使用的是monitorenter和monitorexit指令，其中前者指向同步代码块的开始位置，后者指向代码块结束的位置。 当执行monitorenter指令时，线程试图获取锁，也就是获取**对象监视器monitor**的持有权。 另外，wait/notify方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用这两个方法，否则会抛出java.lang.IllegalMonitorStateException异常的原因。 synchronized是可重入锁的实现原理： 当执行monitorenter指令时，线程试图获取锁，如果锁的计数器为0，则表示锁可以被获取，获取后将锁的计数器设为1。 执行monitorenter 对象锁的的拥有者线程才可以执行 monitorexit 指令来释放锁。在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。整个流程与上面获取锁的流程相同。 执行monitorexit 18.6.2 修饰方法的情况synchronized关键字原理 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。 18.6.3 总结 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。 不过两者的本质都是对对象监视器monitor的获取。 18.6.4 能具体说一下Monitor吗？对象监视器monitor存在于每个对象的对象头中，synchronized锁便是通过这种方式获取锁的。 其内部维护了三个变量： WaitSet：保存处于Waiting状态的线程； EntryList：保存处于Blocked状态的线程； Owner：持有锁的线程； 一个线程获取到锁的标志就是在monitor中设置成功了Owner，一个monitor中只能有一个Owner。 在上锁的过程中，如果有其他线程来抢锁，则进入EntryList进行阻塞状态，当获得锁的线程执行完毕，释放了锁，就会唤醒EntryList中等待的线程竞争锁，竞争的过程是非公平的。 18.7 JDK1.6对synchronized做了哪些优化？在 jdk1.6 中，为了减少获得锁和释放锁带来的性能开销，引入了大量优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可一级一级的降级，当锁释放之后会重新回归无锁状态，不会一级一级的往下降，而是直接变成无锁状态，这种策略是为了提高获得锁和释放锁的效率。 偏向锁（Biased Locking）： 偏向锁是在无竞争的情况下对锁进行优化的机制。它的目标是减少无竞争情况下的锁操作的开销。 当一个线程获得了偏向锁后，之后再次进入同步块时无需重新获取锁，而是直接进入。 偏向锁的撤销机制是当其他线程试图竞争偏向锁时，持有偏向锁的线程会被挂起，偏向锁会升级为轻量级锁。 轻量级锁（Lightweight Locking）： 轻量级锁是在有少量竞争的情况下对锁进行优化的机制。 当第一个线程进入同步块时，它会尝试使用 CAS（Compare and Swap）操作将对象头部的标记字段替换为指向锁记录的指针，这个过程是无锁的。 如果 CAS 操作成功，线程就获得了轻量级锁。如果 CAS 操作失败，表示有竞争，线程会膨胀为重量级锁。 重量级锁（Heavyweight Locking）： 重量级锁是在存在激烈竞争或轻量级锁膨胀失败的情况下使用的锁机制。 当一个线程尝试获取一个被重量级锁保护的同步块时，它会被阻塞，进入等待状态。 重量级锁使用操作系统的同步原语来实现，比如使用操作系统的互斥量或监视器锁。 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步代码方法的性能相差无几。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用只有一个线程访问的同步场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程，使用自旋会消耗CPU。 追求响应时间，同步块执行速度非常快。 重量级锁 线程竞争不适用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量，同步块执行时间速度较长。 18.8 synchronized和lock两者的区别 语法层面 synchronized是关键字，源码在JVM中，是由C++实现的，退出同步代码块锁会自动释放； Lock是接口，源码由JDK提供，用JAVA语言实现，需要手动用unlock方法释放锁； 功能层面 二者都属于悲观锁，都具备基本的互斥、同步、锁重入的功能； Lock提供了更多的功能，比如等待状态、公平锁、可打断、可超时等等，同时Lock可以实现不同的场景，比如ReentrantLock等； 性能层面 在没有或竞争少时，synchronized做了许多优化，比如偏向锁、轻量级锁； 在竞争激烈时，Lock的性能会更好； 18.9 了解ReentrantLock吗？ReentrantLock是java并发包下面的Lock接口的一个实现类，其丰富的功能与synchronized对比更加灵活，与synchronized一样都是悲观锁。 ReentrantLock是一个可重入锁，当调用lock方法获取锁之后，再次调用lock时，是不会再阻塞的，内部直接增加重入次数即可，代表这个线程已经重复获取一把锁而不需要等待锁的释放。 ReentrantLock的底层实现原理主要是利用CAS+AQS队列来实现的，默认是非公平锁。 18.10 ReentrantLock和synchronized的区别是什么？相同点： 两者都是可重入锁； 两者都是悲观锁； 不同点： ReentrantLock是显式锁，需要手动调用lock()方法获取锁，再通过unLock()方法释放锁，而synchronized是隐式锁，通过关键字修饰的代码块或方法时自动获取和释放锁。 ReentrantLock可以设置公平锁和非公平锁，但是synchronized是非公平锁。 ReentrantLock可以在等待锁的过程中响应中断请求，synchronized在等待锁的过程中无法响应中断请求。 ReentrantLock可以绑定多个条件。 19、volatile关键字作用：保证线程之间的变量可见性，如果我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。 注意：volatile关键字能保证数据的可见性、有序性，但是不能保证数据的原子性。而synchronized关键字两者都能保证。 19.1 为什么代码会重排？计算机在执行程序的过程中，编译器和处理器通常会对指令进行重排序，这样做的目的是为了提高性能。 代码重排 左边这段代码，不断地交替读取a，b，会导致寄存器频繁交替存储a和b，使得代码的性能下降。 但是如果使用右边的这种重排序方式，避免交替读取a和b，这就是重排序的意义。 指令重排序一般分为编译器优化重排、指令并行重排、内存系统重排三种： 编译器优化重排：编译器在不改变单线程程序语义的情况下，可以对语句的执行顺序进行重新排序。 指令并行重排：对于不存在数据依赖的程序，处理器可以对机器指令的执行顺序进行重新排列。 内存系统重排：因为处理器使用缓存和读&#x2F;写缓冲区，使得加载（load）和 存储（store）看上去像是在乱序执行。 这三种指令重排说明了一个问题，那就是指令重排在单线程下可以提高代码的性能，但是在多线程下会出现问题。 19.2 重排序会引发什么问题？123456789101112int a = 0;boolean flag = false;public void writer()&#123; a = 1; //操作1 flag = true; //操作2&#125;public void reader()&#123; if (flag)&#123; //操作3 int i = a + a; //操作4 &#125;&#125; 假设线程1先执行writer()方法，随后线程2执行reader()方法，最后程序一定能得到正确的结果吗？ 不一定。如果操作1和操作2进行了重排序，线程1先执行操作2，也就是flag = true；然后线程2执行操作3和操作4，在执行操作4时，不能正确读取到a的值，导致最终程序运行结果出问题，这说明在多线程代码中，重排序会破坏多线程的语义。 19.3 volatile实现原理19.3.1 实现可见性原理导致内存不可见的主要原因：Java内存模型中本地内存和主内存之间的值不一致导致的。 volatile可以保证内存可见性的关键是 volatile的读&#x2F;写实现了缓存一致性。 缓存一致性的主要内容为： 每个处理器会通过嗅探总线上的数据来查看自己的数据是否过期，一旦处理器发现自己缓存对应的内存地址被修改，就会将当前处理器的缓存设为无效状态。此时，如果处理器要获取这个数据，必须得重新从主内存将其读取到本地内存。 当处理器写数据时，如果发现操作的是共享变量，会通知其他处理器将该变量的缓存设为无效状态。 那缓存一致性是如何实现的呢？ 可以发现通过 volatile 修饰的变量，在生成汇编指令时会比普通的变量多出一个 Lock指令，这个 Lock 指令就是 volatile 关键字可以保证内存可见性的关键，它主要有两个作用： （1）将当前处理器缓存的数据刷新到主内存。 （2）刷新到主内存时会使得其他处理器缓存的该内存地址的数据无效。 19.3.2 实现有序性原理为了实现 volatile 的内存语义，编译器在生成字节码时会通过插入内存屏障来禁止指令重排序。 内存屏障：是一种 CPU 指令，它的作用是对该指令前和指令后的一些操作产生一定的约束，保证一些操作按顺序执行。 Java内存模型把内存屏障分为4类，分别是LoadLoad、StoreStore、LoadStore、StoreLoad。 根据Java内存模型对编译器指定的重排序规则为： 重排序规则 volatile写操作上面加ss屏障：禁止上面的普通写和下面的volatile写重排序； volatile写操作下面加sl屏障：禁止上面的volatile写和下面可能的volatile读&#x2F;写重排序； volatile读操作下面加ll屏障：禁止上面的volatile读和下面所有的普通读重排序； volatile读操作下面加ls屏障：禁止上面的volatile读和下面所有的普通写重排序； 通过这四个重排序规则，volatile关键字可以禁止指令重排，实现有序性。 面试题：用双重校验锁的方式实现单例模式（线程安全） 12345678910111213141516171819public class Singleton &#123; private volatile static Singleton uniqueInstance; //用private修饰构造函数可以避免被实例化 private Singleton()&#123;&#125; public static Singleton getUniqueInstance()&#123; //先判断对象是否已经实例化过 //没有实例化过才进入加锁代码 if (uniqueInstance == null)&#123; //类对象加锁 synchronized (Singleton.class)&#123; if (uniqueInstance == null)&#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; uniqueInstance = new Singleton();这段代码其实是分三步执行的： 为uniqueInstance分配内存空间； 初始化uniqueInstance; 将uniqueInstance指向分配的内存空间。 但是因为JVM具有指令重排的特性，执行的顺序可能会变成1-&gt;3-&gt;2。在单线程中指令重排不会出问题，但是在多线程的情况下，会导致一个线程获得还没有初始化的实例。比如，线程T1执行了1和3，此时T2调用getUniqueInstance()后发现uniqueInstance不为空，因此返回uniqueInstance，但是此时还进行第2步，也即还未初始化uniqueInstance。使用volatile关键字可以禁止JVM指令重排，从而保证多线程环境下也能正常运行。 20、synchronized和volatile的区别 volatile 主要是保证内存的可见性，即变量在寄存器中的内存是不确定的， 需要从主存中读取。synchronized 主要是解决多个线程访问资源的同步性。 volatile 作用于变量，synchronized 作用于代码块或者方法。 volatile 不能保证数据的原子性。 synchronized 可以保证数据的可见性和原子性。 volatile 不会造成线程的阻塞，synchronized 会造成线程的阻塞。 21、乐观锁和悲观锁乐观锁：乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。 悲观锁：悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。 像 Java 中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 21.1 如何实现乐观锁？版本号机制：一般是在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。 CAS算法：CAS 的全称是 Compare And Swap（比较与交换） ，用于实现乐观锁，被广泛应用于各大框架中。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。 CAS 是一个原子操作（即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成），底层依赖于一条 CPU 的原子指令。 CAS涉及到的三个操作数： V ：要更新的变量值(Var) E ：预期值(Expected) N ：拟写入的新值(New) 当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了V，则当前线程放弃更新。 21.2 乐观锁存在的问题ABA问题：如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 “ABA”问题。 ABA 问题的解决思路是在变量前面追加上版本号或者时间戳。JDK 1.5 以后的 AtomicStampedReference 类就是用来解决 ABA 问题的， 循环时间长开销大：CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。 22、ThreadLocal22.1 什么是ThreadLocal？有哪些应用场景？ThreadLocal 为变量在每个线程中都创建了一个副本，每个线程可以访问自己内部的副本变量， 并且不会和其他线程的局部变量冲突，实现了线程间的数据隔离，同时实现了线程内的资源共享。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 再举个简单的例子：两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么 ThreadLocal 就是用来避免这两个线程竞争的。 应用场景： 使用 ThreadLocal 进行跨函数数据传递（比如传递请求过程中的用户ID、Session、传递HTTP用的请求实例HttpRequest） 使用 ThreadLocal 实现线程间数据隔离 使用 ThreadLocal 实现数据库连接 22.2 ThreadLocal原理image-20230331170315399 每一个 Thread 线程内部都有一个 Map（ThreadLocalMap），如果给一个 Thread 创建多个 ThreadLocal 实例，然后放置本地数据，那么当前线程的 ThreadLocalMap 中就会有多个“Key-Value 对”，其中 ThreadLocal 实例为 Key，本地数据为 Value。 每一个线程在获取本地值时，都会将 ThreadLocal 实例作为 Key 从自己拥有的 ThreadLocalMap 中获取值，别的线程无法访问自己的 ThreadLocalMap 实例，自己也无法访问别人的 ThreadLocalMap 实例， 达到相互隔离，互不干扰。 ThreadLocal 的操作都是基于 ThreadLocalMap 展开的，而 ThreadLocalMap 是 ThreadLocal 的一个静态内部类，其实现了一套简单的 Map 结构（比 HashMap 简单）。其中get() 、 set() 、 remove() 方法都涉及 ThreadLocalMap 的方法调用。 22.3 什么导致了ThreadLocal内存泄露问题？ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。 解决方法：ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法清理。 弱引用：如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 23、线程池23.1 什么是线程池？为什么使用线程池？线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。 使用线程池的好处： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 23.2 如何创建线程池？方式一：通过ThreadPoolExecutor构造函数来创建（推荐）。 方式二：通过 Executor 框架的工具类 Executors 来创建。 newCachedThreadPool创建一个可缓存的线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程； newFixedThreadPool创建一个定长的线程池，可控制线程最大并发数，超出的线程会在队列中等待； newScheduledThreadPool创建一个可以执行延迟任务的线程池，支持定时和周期性任务； newSingleThreadExecutor创建一个单线程化的线程池，只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。 23.2.1 为什么不推荐使用Executors方式创建线程池？ FixedThreadPool 和 SingleThreadExecutor ： 使用的是无界的 LinkedBlockingQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 CachedThreadPool ：使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 ScheduledThreadPool 和 SingleThreadScheduledExecutor : 使用的无界的延迟阻塞队列DelayedWorkQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 23.2.2 线程池核心参数有哪些？如何解释？ThreadPoolExecutor 7 个核心的参数： corePoolSize 核心线程数目: 线程池中会保留的最多线程数； **maximumPoolSize最大线程数目 :**核心线程+救急线程的最大数目。 workQueue阻塞队列: 当没有空闲的核心线程时，新任务会进入次队列排队等待，队列满的话就会创建救急线程执行任务； keepAliveTime生存时间：救急线程的存活时间，如果生存时间内没有新任务，线程资源就会被释放； unit时间单位：救急线程生存时间的单位。 threadFactory线程工厂：定制线程对象的创建。 handler拒绝策略： 当所有线程都在繁忙、阻塞队列也放满时，会触发拒绝策略。 23.2.3 线程池的拒绝策略有哪些？ ThreadPoolExecutor.AbortPolicy： 直接抛出异常来拒绝新任务的处理，默认策略。 ThreadPoolExecutor.CallerRunsPolicy： 用调用者所在的线程来执行任务； ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 丢弃阻塞队列中最靠前的任务，并执行当前任务。 23.2.4 线程池常见的阻塞队列有哪些？新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 不同的线程池会选用不同的阻塞队列，我们可以结合内置线程池来分析。 ArrayBlockingQueue（有界队列）：基于数组结构的有界阻塞队列，FIFO，强制有界，只有一把锁； LinkedBlockingQueue（无界队列）：基于链表结构的无界阻塞队列，FIFO，可以有界，头尾都有锁。 SynchronousQueue（同步队列） ：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。 DelayedWorkQueue（延迟阻塞队列）：是一个优先级队列，可以保证每次出队的任务都是当前队列中执行时间最靠前的； 23.2.5 线程池处理任务的流程（线程池执行原理是什么？）image-20230410154615916 如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。 如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。 如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么会按照当前的拒绝策略来执行。 23.3.6 如何给线程命名？初始化线程池的时候需要显示命名（设置线程池名称前缀），有利于定位问题。 默认情况下创建的线程名字类似 pool-1-thread-n 这样的，没有业务含义，不利于我们定位问题。 给线程池里的线程命名通常有下面两种方式： 1、利用 guava 的 ThreadFactoryBuilder 1234ThreadFactory threadFactory = new ThreadFactoryBuilder() .setNameFormat(threadNamePrefix + &quot;-%d&quot;) .setDaemon(true).build();ExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory) 2、自己实现ThreadFactory 12345678910111213141516171819202122232425262728import java.util.concurrent.Executors;import java.util.concurrent.ThreadFactory;import java.util.concurrent.atomic.AtomicInteger;/** * 线程工厂，它设置线程名称，有利于我们定位问题。 */public final class NamingThreadFactory implements ThreadFactory &#123; private final AtomicInteger threadNum = new AtomicInteger(); private final ThreadFactory delegate; private final String name; /** * 创建一个带名字的线程池生产工厂 */ public NamingThreadFactory(ThreadFactory delegate, String name) &#123; this.delegate = delegate; this.name = name; // TODO consider uniquifying this &#125; @Override public Thread newThread(Runnable r) &#123; Thread t = delegate.newThread(r); t.setName(name + &quot; [#&quot; + threadNum.incrementAndGet() + &quot;]&quot;); return t; &#125;&#125; 23.3.7 如何合理配置线程池大小？ 如果业务是 CPU 密集型的： 该业务需要大量的运算，而没有阻塞，CPU 一直全速运行。因此，应当配置尽可能少的线程数量。一般公式：CPU 核数+1 个线程的线程池。 如果业务是 IO 密集型的 ​\t（1）如 IO 密集型的业务并不是一直在执行任务，则应该配置尽可能多的线程。一般公式：CPU 核数*2。 ​\t（2）IO 密集型，即该任务需要大量的 IO、会有大量的阻塞，比如高并发读取 Redis 或者 MySQL。参考公式：CPU 核数&#x2F;（1-阻塞系数）。阻塞系数在 0.8-0.9 之间。 比如 8 核 CPU： 8 &#x2F; (1-0.9) &#x3D; 80 个线程数。 23.3.8 线程池回收线程的方法有哪些？ 对于核心线程来说：可以设置参数allowCoreThreadTimeOut为true，等待keepAliveTime时间后，线程就会被回收。 对于救急线程来说：等到keepAliveTime后，线程自动会被回收，也可以执行executor.shutdown()方法，立马回收救急线程。 23.3.9 如何判断线程池已经执行完所有任务？ 用isTerminated()方法判断线程池的状态，循环判断该方法的返回值，了解线程池的运行状态；使用该方法的前提是线程池需要调用shutdown方法，不然就会一直运行； 通过判断线程池中的计划执行任务数和已完成任务数来判断任务是否执行完，当两者相等时，说明线程池的人物全部都执行完毕了； 给CountDownLatch赋一个值为N的计数器，N为其中的任务数，每执行完一个任务，就让计数器-1，当计数器为0时，就说明任务都执行完毕。 23.3 线程池原理分析首先创建一个 Runnable 接口的实现类 12345678910111213141516171819202122232425262728public class MyRunnable implements Runnable&#123; private String command; public MyRunnable(String s)&#123; this.command = s; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot;Start. Time = &quot; + new Date()); processCommand(); System.out.println(Thread.currentThread().getName() + &quot;End. Time = &quot; + new Date()); &#125; private void processCommand() &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Override public String toString()&#123; return this.command; &#125;&#125; 编写测试程序，使用ThreadPoolExecutor构造函数自定义参数的方式来创建线程。 123456789101112131415161718192021222324252627282930313233public class ThreadPoolExecutorDemo &#123; private static final int CORE_POOL_SIZE = 5; private static final int MAX_POOL_SIZE = 10; private static final int QUEUE_CAPACITY = 100; private static final long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) &#123; //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy() ); for (int i = 0; i &lt; 10; i++) &#123; //创建workerThread对象 MyRunnable worker = new MyRunnable(&quot;&quot; + i); //执行Runnable executor.execute(worker); &#125; //终止线程池 executor.shutdown(); while (!executor.isTerminated())&#123; &#125; System.out.println(&quot;Finished all thread&quot;); &#125;&#125; 可以看到上面的代码中，指定了： corePoolSize: 核心线程数为 5。 maximumPoolSize ：最大线程数 10 keepAliveTime : 等待时间为 1L。 unit: 等待时间的单位为 TimeUnit.SECONDS。 workQueue：任务队列为 ArrayBlockingQueue，并且容量为 100; handler:饱和策略为 CallerRunsPolicy。 输出结果： 123456789101112131415161718192021pool-1-thread-1Start. Time = Mon Apr 10 16:04:32 CST 2023pool-1-thread-2Start. Time = Mon Apr 10 16:04:32 CST 2023pool-1-thread-4Start. Time = Mon Apr 10 16:04:32 CST 2023pool-1-thread-5Start. Time = Mon Apr 10 16:04:32 CST 2023pool-1-thread-3Start. Time = Mon Apr 10 16:04:32 CST 2023pool-1-thread-5End. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-2End. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-1End. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-2Start. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-1Start. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-4End. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-4Start. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-5Start. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-3End. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-3Start. Time = Mon Apr 10 16:04:37 CST 2023pool-1-thread-5End. Time = Mon Apr 10 16:04:42 CST 2023pool-1-thread-1End. Time = Mon Apr 10 16:04:42 CST 2023pool-1-thread-2End. Time = Mon Apr 10 16:04:42 CST 2023pool-1-thread-3End. Time = Mon Apr 10 16:04:42 CST 2023pool-1-thread-4End. Time = Mon Apr 10 16:04:42 CST 2023Finished all thread 线程池首先会执行5个任务，然后这些任务中，如果有被执行完的任务，就会被拿去新的任务执行。 首先分析一下 execute方法。 在示例代码中，我们使用 executor.execute(worker)来提交一个任务到线程池中去。 这个方法非常重要，下面我们来看看它的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041// 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static int workerCountOf(int c) &#123; return c &amp; CAPACITY;&#125;//任务队列private final BlockingQueue&lt;Runnable&gt; workQueue;public void execute(Runnable command) &#123; // 如果任务为null，则抛出异常。 if (command == null) throw new NullPointerException(); // ctl 中保存的线程池当前的一些状态信息 int c = ctl.get(); // 下面会涉及到 3 步 操作 // 1.首先判断当前线程池中执行的任务数量是否小于 corePoolSize // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2.如果当前执行的任务数量大于等于 corePoolSize 的时候就会走到这里，表明创建新的线程失败。 // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态并且队列可以加入任务，该任务才会被加入进去 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果当前工作线程数量为0，新创建一个线程并执行。 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 // 传入 false 代表增加线程时判断当前线程数是否少于 maxPoolSize //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。 else if (!addWorker(command, false)) reject(command);&#125; 在 execute 方法中，多次调用 addWorker 方法。addWorker 这个方法主要用来创建新的工作线程，如果返回 true 说明创建和启动工作线程成功，否则的话返回的就是 false。 23.4 几个常见的对比23.4.1 Runnable和CallableRunnable自 Java 1.0 以来一直存在，但Callable仅在 Java 1.5 中引入,目的就是为了来处理Runnable不支持的用例。 Runnable 接口不会返回结果或抛出检查异常，但是 Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。 工具类 Executors 可以实现将 Runnable 对象转换成 Callable 对象。（Executors.callable(Runnable task) 或 Executors.callable(Runnable task, Object result)）。 23.4.2 excute()和submit()execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法的话，如果在 timeout 时间内任务还没有执行完，就会抛出 java.util.concurrent.TimeoutException。 23.4.3 shutdown()和shutdownNow()shutdown() :关闭线程池，线程池的状态变为 SHUTDOWN。线程池不再接受新任务了，但是队列里的任务得执行完毕。 shutdownNow() :关闭线程池，线程的状态变为 STOP。线程池会终止当前正在运行的任务，并停止处理排队的任务并返回正在等待执行的 List 23.4.4 isTerminated()和isShutdown() isTerminated 当调用 shutdown() 方法后，并且所有提交的任务完成后返回为 true isShutDown 当调用 shutdown() 方法后返回为 true。 24、CASCAS(Compare And Swap)是CPU指令级的原子操作，并且处于用户态下，所以其开销较小，性能更高。 是一种乐观锁技术，属于非阻塞算法。 24.1 CAS的自旋过程？CAS 是一种无锁算法，该算法关键依赖三个值——当前值、期望值和更新值，底层 CPU 利用原子操作判断当前值与期望值是否相等，如果相等就给内存地址赋更新值，否则不做任何操作。使用 CAS 进行无锁编程的步骤大致如下： 获得字段的当前值和期望值； 计算更新值； 通过CAS将更新值替换成当前值上，如果CAS失败，就重复第1步，一直到CAS成功，这就是CAS自旋。 24.2 CAS存在什么问题？如何解决？ ABA问题，在乐观锁中有介绍。可以通过版本号来判断变量的值是否发生了变化，在CAS操作时同时比较版本号是否一致。 高并发下，自旋时间过长导致时间开销太大，性能很低。可以通过限制自旋次数来解决。 只能保证一个共享变量的原子操作。可以结合ReentrantLock和synchronized关键字来保证多个变量的原子性。 25、Atomic原子类Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 所谓原子类说简单点就是具有原子&#x2F;原子操作特征的类。 并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下 根据操作的数据类型，可以将 JUC 包中的原子类分为 4 类 25.1 基本类型 AtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 25.2 数组类型 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray ：引用类型数组原子类 25.3 引用类型 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicMarkableReference ：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来。 25.4 对象的属性修改类型 AtomicIntegerFieldUpdater:原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater ：原子更新引用类型里的字段的更新器 要想原子地更新对象的属性需要两步。 第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。 第二步，更新的对象属性必须使用 public volatile 修饰符。 26、AQS26.1 什么是AQS？AQS 的全称是 AbstractQueuedSynchronizer，是一个用来构建锁和同步器的框架，像 ReentrantLock，Semaphore，FutureTask 都是基于 AQS 实现的。 26.2 AQS的原理简单来说，AQS 就是维护了一个共享资源，然后使用队列来保证线程排队获取资源的一个过程。 AQS 的原理图如下 image-20230410171701107 AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是基于 CLH 锁 （Craig, Landin, and Hagersten locks） 实现的。 CLH 锁是对自旋锁的一种改进，是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系），暂时获取不到锁的线程将被加入到该队列中。AQS 将每条请求共享资源的线程封装成一个 CLH 队列锁的一个结点（Node）来实现锁的分配。在 CLH 队列锁中，一个节点表示一个线程，它保存着线程的引用（thread）、 当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）。 AQS 使用 int 成员变量 state 表示同步状态，通过内置的 线程等待队列 来完成获取资源线程的排队工作。 12// 共享变量，使用volatile修饰保证线程可见性private volatile int state; 状态信息 state 可以通过 protected 类型的getState()、setState()和compareAndSetState() 进行操作。并且，这几个方法都是 final 修饰的，在子类中无法被重写。 123456789101112//返回同步状态的当前值protected final int getState() &#123; return state;&#125;//设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 26.3 AQS资源共享方式 Exclusive：独占，只有一个线程可以执行，如ReentrantLock Share：共享，可以多个线程同时执行，如Semaphore，CountDownLatch 26.4 AQS是如何实现独占锁和共享锁的？ 以独占式的 ReentrantLock 为例： AQS使用双向队列（CLH队列）来保存等待获取锁的线程。当一个线程尝试获取锁时，如果锁已被其他线程占用，该线程会被加入到等待队列中，等待获取锁。 在独占锁模式下，AQS会按照FIFO顺序唤醒等待队列中的线程，先到先得。 当持有锁的线程释放锁时，AQS会唤醒等待队列中的第一个线程，使其有机会获取锁。 以共享式的 CountDownLatch 以例： 在共享锁模式下，多个线程可以同时持有同一个锁，实现资源的共享访问。 AQS使用计数器来记录锁的持有情况。当一个线程尝试获取锁时，如果失败，则会进入队列等待，如果获取成功，则会让计数器+1，并通知队列中下一个线程，以实现共享的功能。 持有共享锁的线程在释放锁时，会递减计数器。当计数器归零时，表示没有线程持有该锁，其他线程可以尝试获取锁。 AQS 也支持自定义同步器同时实现独占和共享两种方式，如 ReentrantReadWriteLock","tags":["Java","八股","基础","面试"],"categories":["Java八股","基础"]},{"title":"2.Java集合","path":"/2023/06/16/2-Java集合/","content":"1、集合框架1.1 集合框架image.png 2、哪些集合类是线程安全的？2.1 线程安全的集合类 Vector：就比 arraylist 多了个同步化机制（线程安全），因为效率较低， 现在已经不太建议使用。在 web 应用中，特别是前台页面，往往效率（页面响应速度）是优先考虑的。 Statck：堆栈类，先进后出。 HashTable：就比 HashMap 多了个线程安全。 ConcurrentHashMap：线程安全的集合类。 enumeration：枚举，相当于迭代器。 3、集合类线程不安全举例3.1 ArrayList为什么是线程不安全的请编写一个ArrayList不安全的案例并给出解决方案？ 1234567891011public class Main&#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;= 30; i++) &#123; new Thread(() -&gt;&#123; list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; 故障现象：这段代码创建了 30 个线程，每个线程都向一个共享的列表 list ，并且向其中添加一个长度为 8 的随机字符串，然后输出当前列表内容。由于多个线程同时对 list 进行操作，因此会出现线程安全问题。 结果会报java.util.ConcurrentModificationException异常 解决方案： 使用线程安全的数据结构，比如说Vector或者CopyOnWriteArrayList。 使用 Collections.synchronizedList() 方法将非线程安全的 ArrayList 转换成线程安全的。 在修改共享数据时，使用同步锁保证线程安全。其中使用同步锁时，要注意锁定的对象应该是所有线程共享的，而不是县城内部的局部变量。 1234567891011public class Main&#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); for (int i = 0; i &lt; 30; i++) &#123; synchronized (list)&#123; list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); &#125; &#125; &#125;&#125; 建议：在读多写少时，推荐使用CopyOnWriteArrayList，因为这个类里面是通过lock锁来实现线程同步的。 3.2 CopyOnWrite了解吗？CopyOnWrite就是写时复制（也就是读写分离的思想）：在读取数据时，不加锁；在写入和删除时加锁，底层实现机制是：volatile + ReentrantLock； 具体过程：当往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后向新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。 优点： 提高并发，解决了并发场景下的安全问题，因为我们在CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 缺点： 内存占用：因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存），可能导致GC。 一致性：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。【当执行add或remove操作没完成时，get获取的仍然是旧数组的元素】 3.3 HashSetHashSet底层数据结构是HashMap，那么为什么HashSet在执行add方法时，只添加1个元素，而不是HashMap中同时添加key和value呢？ 通过查看源码： 123456789private static final Object PRESENT = new Object();public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 可以发现，HashSet底层其实就是用HashMap实现的，Set在使用add添加元素的时候，用的就是HashMap的put方法，只不过在添加的时候，将需要添加的元素e作为key添加，而Value是一个默认的用final修饰的Object对象PRESENT。 4、ArrayList和LinkedList的区别4.1 ArrayList和LinkedList的区别 线程安全：两者都不同步，线程都不安全。 底层数据结构：ArrayList底层使用的是Object数组；LinkedList底层使用的是双向链表。 插入删除元素：ArrayList采用数组存储；LinkedList采用链表存储，所以与数据结构中数组和链表特性相同。 快速访问：ArrayList可以通过元素序号快速访问对象；LinkedList不支持高效的元素访问。 内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间； LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 5、ArrayList的扩容机制5.1 ArrayList扩容机制image.png ArrayList的底层采用Object数组来存储数据，在往 ArrayList 里面添加元素时，才会涉及到扩容机制。 由于采用的是数组存储，所以会给数组设置默认长度10。 当数组中没有元素时，是不会设置为默认长度10 的，此时数组是一个空数组。只有要添加元素时，会进入 ensureCapacityInternal()进行判断，如果数据数组为空数组，在添加第一个元素时才将数组长度扩容为默认值10，如果数组不为空数组 ， 就在 ensureCapacityInternal()里 面 调 用 ensureExplicitCapacity()来判断是否需要扩容。 如果需要扩容，才调用 grow()方法进行扩容。在grow()方法里面，会通过右移位运算将数组长度的新长度扩容为**原来的 1.5倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右)**。 扩容后如果新容量不能满足所需容量，就将新容量扩大为所需容量。也即新容量大于 MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8，就调用hugeCapacity()方法来比较 minCapacity 和 MAX_ARRAY_SIZE 的大小，如果 minCapacity 大于默认最大容量，则新容量设为则为 Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE，即为 Integer.MAX_VALUE - 8。如果最大容量大于Integer.MAX_VALUE，那么就会转为负数，然后抛出异常。 最后将原数组中的元素拷贝到扩容后的新数组， 并将原数组的引用设置为拷贝后的数组。 5.2 如果new ArrayList&lt;&gt;(20)，此时需要扩容几次？此时不会扩容，因为如果通过构造函数直接指定了ArrayList的长度，初始化时就会直接分配给ArrayList指定大小的容量，而不会触发扩容机制。 6、HashSet如何检查重复？6.1 HashSet去重原理把对象添加到HashSet中时， HashSet会计算对象的hashCode值，来判断对象加入的位置，同时也会与其他加入的对象hashCode值作比较； 如果没有相同的hashcode，HashSet会假设对象没有重复出现； 如果有相同的hashCode，会调用equals来检查hashCode相同的对象是否真的相同； 如果用equals比较之后，两者相同，那么HashSet就不会让这个元素加入。 简单总结：首先比较hashCode是否相等，再使用equals比较值是否相等。 7、HashMap的底层实现7.1 JDK 1.8之前image.png 底层采用数组+链表，HashMap 通过它的hash()方法获取 key 对应的hashCode值，然后通过(n-1) &amp; hash 判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存入的 hash 值以及 key 是否相同，如果相同就直接覆盖，不相同的话，就通过拉链法解决 hash 冲突，将元素存放到链表中。 7.2 JDK 1.8之后image.png JDK1.8 之后底层采用的是数组+（链表和红黑树），主要不同在于解决hash冲突时，当链表长度超过设定的阈值长度时（默认为 8），会先判断数组的长度是否小于 64(初始最大容量)，如果小于的话，并不是直接转为红黑树，而是进行扩容，只有当数组长度大于 64 时，才会将对应的链表转换为红黑树。 7.2.1 为什么HashMap的底层要用红黑树，而不是平衡树呢？因为HashMap中需要频繁的新增或删除数据，一旦树中节点需要改变，那必然导致树的结构需要调整。而红黑树不像平衡树那样追求“完全平衡”，红黑树只需要部分达到平衡即可，所以其增删节点时旋转的次数会比平衡树降低很多，这也就意味着红黑树的调整效率比平衡树高很多，同样也更好设计和实现。 7.3 put的具体过程image.png 判断键值对数组 table[i]是否为空或为null，若是，则执行 resize()进行扩容；否则进行下一步 ； 根据 key计算hash 值得到插入的数组索引 i，如果 table[i]&#x3D;&#x3D;null，直接新建节点添加，如果 table[i]不为空，则进行下一步； 判断 table[i]的首个元素是否和 key 一样，如果相同直接覆盖 value，否则进行下一步，这里的相同指的是 hashCode 以及 equals； 判断 table[i] 是否为 treeNode，即 table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则操作链表； 遍历 table[i]，判断链表长度是否大于 8，大于 8 的话就准备将链表转换为红黑树，（当红黑树内节点数 &lt;&#x3D; 6时，会将红黑树退化成链表）在将链表转换为红黑树之前，会进行判断是否真的转为红黑树。 如果当前数组的长度小于64，那么会先进行数组的扩容，否则才会真的转红黑树，然后在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现 key 已经存在直接覆盖 value 即可； 插入成功后，判断实际存在的键值对数量 size 是否超过了最大容量 threshold(数组长度*0.75)，如果超过，进行扩容。 7.4 为什么负载因子是0.75？loadFactor 太大导致查找元素效率低，存放的数据拥挤，hash冲突概率大大提升；太小会导致数组的利用率低，存放的数据会很分散。 loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值，可以保证查询性能和空间利用效率之间取得平衡。 7.5 讲一讲HashMap的扩容机制 初始化或达到扩容阈值（数组长度 * 0.75）时，调用resize()方法进行扩容，第一次添加数据初始化数组长度为16； 创建新的数组，新数组长度是原来数组长度的2倍； 将原数组上的数据移到新数组上，其中没有Hash冲突的key，直接计算其在新数组中的索引位置添加； 如果存在Hash冲突的key，先采用链地址法解决，如果是红黑树，则直接在红黑树中添加；如果是链表，则需要拆分链表，要么该元素留在原来的位置，要么移动到原来位置+增加的数组大小这个位置上。 所有的元素移动完毕后，原数组的引用替换为新数组的引用，完成扩容操作。 8、HashMap的长度为什么是2的幂次方？当我们往 HashMap 里面 put元素的时候，会通过 hashMap 的 hash 方法，获取 key 对应的 hashCode 值，然后拿这个值去判断该元素要存放在那个地方。 这里采用的是(n-1) &amp; hash，也即右移16位，其中 n 为 HashMap 的长度，这个操作只有当 n 是 2 的幂次方时，(n-1) &amp; hash 才和 hash % n 表示的是一个意思，这样才能找到这个 key 在数组中对应的位置。 如果不是 2 的幂次方， (n-1) &amp; hash 是不等于 hash%n 的，之所以采用位运算的好处是：相较于%操作，它的计算效率更高，能保证散列均匀分布。 9、HashMap有哪几种常见的遍历方式？ 迭代器（Iterator）方式遍历 123456789101112131415// entrySet遍历Iterator&lt;Map.Entry&lt;Integer, String&gt;&gt; iterator = map.entrySet().iterator();while (iterator.hasNext()) &#123; Map.Entry&lt;Integer, String&gt; entry = iterator.next(); System.out.println(entry.getKey()); System.out.println(entry.getValue());&#125;// keySet遍历Iterator&lt;Integer&gt; iterator = map.keySet().iterator();while (iterator.hasNext()) &#123; Integer key = iterator.next(); System.out.println(key); System.out.println(map.get(key));&#125; For Each方式遍历 1234567891011// entrySet遍历for (Map.Entry&lt;Integer, String&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue());&#125;// keySet遍历for (Integer key : map.keySet()) &#123; System.out.println(key); System.out.println(map.get(key));&#125; Lambda表达式遍历 12345// lambda表达式遍历map.forEach((key, value) -&gt; &#123; System.out.println(key); System.out.println(value);&#125;); Streams API遍历 12345678910// 单线程遍历map.entrySet().stream().forEach((entry) -&gt; &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue());&#125;);// 多线程遍历map.entrySet().parallelStream().forEach((entry) -&gt; &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue());&#125;); 9.1 性能测试entrySet的性能比keySet的性能好，尽量使用entrySet来遍历Map集合。 KeySet 在循环时使用了 map.get(key)，而 map.get(key) 相当于又遍历了一遍 Map 集合去查询 key 所对应的值。 为什么要用“又”这个词？ 那是因为在使用迭代器或者 for 循环时，其实已经遍历了一遍 Map 集合了，因此再使用 map.get(key) 查询时，相当于遍历了两遍。而 EntrySet 只遍历了一遍 Map 集合，之后通过代码“Entry&lt;Integer, String&gt; entry = iterator.next()”把对象的 key 和 value 值都放入到了 Entry 对象中，因此再获取 key 和 value 值时就无需再遍历 Map 集合，只需要从 Entry 对象中取值就可以了。 所以，EntrySet 的性能比 KeySet 的性能高出了一倍，因为 KeySet 相当于循环了两遍 Map 集合，而 EntrySet 只循环了一遍。 9.2 安全性能我们不能在遍历中使用集合 map.remove() 来删除数据，这是非安全的操作方式，但我们可以使用迭代器的 iterator.remove() 的方法来删除数据，这是安全的删除集合的方式。同样的我们也可以使用 Lambda 中的 removeIf 来提前删除数据，或者是使用 Stream 中的 filter 过滤掉要删除的数据进行循环，这样都是安全的，当然我们也可以在 for 循环前删除数据在遍历也是线程安全的。所以，尽量使用迭代器（Iterator）来遍历EntrySet的遍历方式操作Map集合 10、有哪些解决哈希冲突的方法？ 开放定址法：在发生冲突时，会去寻找一个新的空地址存放； 线性探测法：如果冲突了，就往后找空的地方放； 平方探测法：如果冲突了，进行平方，向前或向后找空地方放； 再Hash法：如果发生冲突，那就再进行hash计算，直到没有发生冲突为止； 链地址法。HashMap用的就是这种方法； 11、为什么HashMap中String、Integer这样的包装类适合作为Key？String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效地减少Hash碰撞的几率。 因为这些包装类都是final类型，具有不可变性，可以保证存储的key具有不可更改性，不会存在获取hash值不同的情况。而同时，这些包装类的内部已经重写equals、hashCode等方法，遵守了HashMap内部的规范，不容易出现hash值计算错误的情况。 12、ConcurrentHashMap和HashTable的区别？底层数据结构：ConcurrentHashMap在JDK1.8之前，采用的是数组+链表来实现；而在JDK1.8及之后的版本，采用的是数组+链表&#x2F;红黑树。HashTable采用的是数组+链表实现的。实现线程安全的方式： 在 JDK1.7 的时候，ConcurrentHashMap（分段锁 ReentrantLock） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 image.png 到了 JDK1.8 的时候已经摒弃了 Segment 的概念，而是直接用 Node 数组 + 链表 + 红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 对 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的 数据结构，但是已经简化了属性，只是为了兼容旧版本； image.png HashTable(同一把锁) : 使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈，效率也会越低。 image.png 13、ConcurrentHashMap的线程安全是怎么实现的？13.1 JDK1.8之前首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; 一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的个数一旦初始化就不能改变。 Segment 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。 Segment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 的锁。 也就是说，对同一 Segment 的并发写入会被阻塞，不同 Segment 的写入是可以并发执行的。 13.2 JDK1.8之后ConcurrentHashMap 取消了 Segment 分段锁，采用 Node + CAS + synchronized 来保证并发安全。 数据结构跟 HashMap 1.8 的结构类似，数组+链表&#x2F;红黑二叉树。 Java 8 在链表长度超过一定阈值（8）时，会判断数组长度是否64，是的话就将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。 Java 8 中，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。 13.3 总结 线程安全实现方式 ：JDK 1.7 采用 Segment 分段锁来保证安全， Segment 是继承自 ReentrantLock。JDK1.8 放弃了 Segment 分段锁的设计，采用 Node + CAS + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。 Hash 碰撞解决方法 : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。 并发度 ：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。 13.4 ConcurrentHashMap已经用了synchronized为什么还要用CAS呢？简单来说，都是保证了多线程下的原子性。CAS用于在数组中插入新节点，因为CAS操作是乐观锁，并没有加锁，而且实现比较简单，适用于无竞争的情况。而**synchronized用于在链表中或红黑树中插入删除节点**，如果到了要插入链表或者红黑树的地步，那说明竞争就比较激烈了，所以用synchronized锁首节点。 当数组中当前位置为空的时候，可以通过CAS把新的节点写到数组中对应的位置； 当数组中当前位置不为空时，通过synchronized来添加或删除节点。如果当前位置是链表，就遍历链表找到合适的位置插入或删除节点。如果当前位置是红黑树，就按照红黑树的规则插入或删除节点； 当链表长度大于阈值（默认为8）时，就把链表转换为红黑树。当红黑树节点数小于等于阈值（默认为6）时，就把红黑树转换为链表。 13.5 ConcurrentHashMap的put操作的流程？ 计算key的hash值； 如果当前table还没有初始化就会调用initTable方法进行初始化； 如果table对应的位置为空，那么直接用CAS操作直接插入即可； 如果检测到内部正在进行扩容操作，该线程就会帮它一起扩容； 如果table对应的位置不为空，会先用synchronized锁住链表或红黑树的头元素。然后再继续对链表或红黑树执行添加操作； 如果链表长度已经大于8（默认），就会判断是否要转为红黑树。（操作和HashMap一样） 如果添加成功就调用addCount()方法统计size，并检查是否需要扩容。 13.6 ConcurrentHashMap是怎么扩容的？需要扩容的情况： 当前容量超过阈值； 当链表元素大于8个，并且数组长度小于64的时候； 当其他线程扩容时，会帮助一起扩容； 扩容过程：通过CAS设置sizeCtl、transferindex等变量，协调多个线程并发扩容，其中无锁的关键就是CAS操作。 需要扩容时，假设此时原table数组长度是64，那么此时记录transferindex = 63，sizeCtl = 48（sizeCtl的含义指的是扩容的阈值），若要进行扩容操作，会使得sizeCtl = -2（-2表示此时的hash桶正在处于扩容的过程中，这里用来记录当前并发扩容线程的数量）； 创建一个新数组newTable，长度为原数组table的两倍，也即128； 扩容线程A会先划分区间，让transferindex - 16 = 47，然后线程A会将table[63]到table[47]这个区间的hash桶向newTable中倒序进行数据迁移； 迁移时，会将桶内的链表或红黑树，按照一定的算法拆分成两份，分别插入到newTable[i]和newTable[n + i]的位置上（其中n为原数组的长度，这里就是64）。 该桶内的元素迁移完毕之后，会被设置为ForwardingNode节点，目的是告诉后来的其他线程，这个节点已经数据迁移完毕了，没有节点了； 若此时线程B访问到了这个ForwardingNode节点。 如果线程B执行的是put等写操作，会先协助扩容，线程B去到transferindex标记的位置，重复上述线程A的操作，将transferindex减16，然后对自己负责的这部分区间进行倒序数据迁移，此时的sizeCtl = sizeCtl - 1 = -3表示新来了个线程。 如果线程B执行的是get等读操作，则会调用ForwardingNode中的find方法，去newTable中找自己需要的元素，此时不会帮忙扩容； 注：线程B和线程A此时是同步进行扩容迁移操作的，因为两个线程负责的是不同的区间，所以他们之间是互不干扰的； 如果线程A先执行完原本区间的迁移工作，就会到transferindex 的位置，又会继续上面的过程，继续执行扩容迁移操作，直到transferindex的值等于0结束，才表示这个线程的扩容操作已经结束。每一个线程走到transferindex = 0的位置，就会让sizeCtl的值+1。 只有当transferindex = 0并且sizeCtl = -1时，才表示整个扩容的流程结束，然后会重新初始化，将table &#x3D; newTable，并且sizeCtl &#x3D; 128 * 0.75 &#x3D; 96。 13.7 迁移时会按一定的算法将红黑树和链表拆分为两份，这个算法具体是什么？13.7.1 链表迁移 首先会锁住Node节点，然后再进行迁移操作； 先找到lastRun节点，将其设置为hn链表的节点； 从首节点开始遍历链表，将蓝色的节点设置为ln链表中的节点，红色的节点设置为hn链表中的节点； 依次循环上述步骤，直到原链表被拆分为hn链表和ln节点链表两个链表，这样就拆分为两个链表了； 注：lastRun节点保证了后面的节点与自己的与运算结果相同，避免了没有必要的循环，所以到lastRun开始就不循环了。从这开始后面要不然全是红的，要不然全是蓝的； 13.7.2 红黑树迁移 首先会锁住数组上的TreeBin节点，再进行迁移； 还是一样以链表的方式遍历红黑树，将其拼接到hn和ln两个链表上； 不满足红黑树条件的，将其转换为普通的链表； 满足红黑树条件的将其转换为红黑树； 13.8 如果一个ConcurrentHashMap在被多个线程同时操作，这个时候进行扩容会有几个线程在处理？这个要分类讨论，假设一个ConcurrentHashMap在同时被10个线程操作，此时进行扩容操作： 如果其中有5个线程执行的是put等写操作，那么扩容的时候就会有5个线程在一起进行扩容； 如果剩下的5个线程执行的时get等读操作，这些线程是不会协助扩容的。 简单来说：只有执行写操作的线程才会帮忙扩容，读操作的线程并不会执行协助扩容操作。 13.9 ConcurrentHashMap在get时会加锁吗？为什么？get 方法不需要加锁，因为 Node 的元素 val 和指针 next 是用 volatile 修饰的，在多线程环境下线程A修改结点的val或者新增节点的时候是对线程B可见的。 13.10 ConcurrentHashMap为什么不允许key和value为null？HashMap允许吗？HashMap允许key和value为null，但是只允许一个key为null，不能有多个。 因为ConcurrentHashMap的应用场景一般都是多线程，如果map.get(key)得到的结果是null，就会出问题，因为无法判断是这个key对应的value本来就是null，还是没有找到对应的key才返回的null，这就有了二义性。 而HashMap可以这么操作是因为HashMap的应用场景是单线程情况下，可以用containsKey(key)判断map内是否存在了这个key。 14、了解HashMap在1.7中多线程死循环问题吗？因为HashMap在1.7中的底层数据结构采用的是数组＋链表实现的，在插入新元素的时候采用的是头插法。而在数组进行扩容的时候，会进行数据迁移，这个过程中有可能会导致死循环。 比如说，现在有两个线程。 线程一：读取到当前HashMap数据中的一个链表，在准备进行扩容的时候，线程二介入。 线程二：读取HashMap，直接进行扩容。因为插入元素采用的是头插法，所以链表的顺序会倒过来，比如原来是AB，扩容后会变成BA，线程二执行结束。 当线程一再回来继续执行的时候就会导致链表出现环结构，从而出现死循环问题。 在1.8中，插入链表的方法更改为尾插法，保持了与扩容前一样的顺序，就避免了出现死循环问题。 大厂面试爱问的HashMap死锁问题，看这一篇就够了_hashmap的死锁问题_wildyuhao的博客-CSDN博客 15、HashMap和HashTable的区别 线程是否安全：HashMap线程不安全，HashTable线程安全； 效率：因为HashTable是线程安全的，内部的方法基本都经过synchronized 修饰，所以其效率是不如HashMap的； 是否支持null的key：HashMap支持存null的key和value，但是只支持一个null的key，而HashTable不允许有null的key和value； 底层数据结构不同：HashMap是数组+链表&#x2F;红黑树，而HashTable是数组+链表； 默认初始容量和扩容大小不同：HashMap数组的默认初始容量是16，每次扩容为2n，而HashTable默认初始容量大小为11，扩容为2n+1。 16、HashMap和TreeMap的区别TreeMap比HashMap多了对集合中的元素根据键排序的能力，以及对集合内元素的搜索能力。","tags":["Java","八股","基础","面试"],"categories":["Java八股","基础"]},{"title":"1.Java基础","path":"/2023/06/15/1-Java基础/","content":"1、基础1.1 JDK JRE JVM的关系 JDK（Java Development Kit）是针对 Java 开发员的产品，是整个 Java 的核心，包括了 Java 运行环境 JRE、Java 工具和 Java 基础类库。 JRE（Java Runtime Environment）是运行 Java 程序所必须的环境的集合，包 含 JVM 标准实现及 Java 核心类库。 JVM（Java Virtual Machine）Java 虚拟机，是整个 java 实现跨平台的最核心 的部分，能够运行以 Java 语言写作的软件程序。 简单来说， JDK 是 Java 的开发工具；JRE 是 Java 程序运行所需的环境， JVM是Java虚拟机。它们之间的关系是JDK包含JRE和JVM，JRE包含JVM。 1.2 编译过程image.png javac还要检查语言规范，编译后转换为.class字节码文件 1.3 Java和C++的区别 Java可以通过虚拟机实现跨平台的特性，C++依赖于特定的平台； Java没有指针，它的引用可以理解为安全指针，C++有指针； Java支持自动垃圾回收，C++需要手动回收； Java不支持多重继承，只能通过实现多个接口来达到相同目的，C++支持多重继承； 1.4 Java 8有什么新特性？ Lambda表达式：允许把函数作为一个方法的参数，也即函数作为参数传递到方法中； 函数式接口：一个有且精油一个抽象方法，但是可以有多个非抽象方法的接口，这样的接口可以隐式转换为Lambda表达式； Stream API：把真正的函数式编程风格引入到Java中； Date Time API：加强对日期和时间的处理。 1.5 Java支不支持运算符重载？为什么？不支持。 简单性和清晰性。清晰性是 Java 设计者的目标之一。设计者不是只想复制语言，而是希望拥有一种清晰，真正面向对象的语言。添加运算符重载比没有它肯定会使设计更复杂，并且它可能导致更复杂的编译器, 或减慢 JVM，因为它需要做额外的工作来识别运算符的实际含义，并减少优化的机会, 以保证 Java 中运算符的行为。 避免编程错误。因为如果允许程序员进行运算符重载，将为同一运算符赋予多种含义，这将使任何开发人员的学习曲线变得陡峭，事情变得更加混乱。 JVM复杂性。从JVM的角度来看，支持运算符重载使问题变得更加困难。通过更直观，更干净的方式使用方法重载也能实现同样的事情，因此不支持 Java 中的运算符重载是有意义的。与相对简单的 JVM 相比，复杂的 JVM 可能导致 JVM 更慢，并为保证在 Java 中运算符行为的确定性从而减少了优化代码的机会。 2、数据类型image.png 1.1 自动装箱与拆箱装箱：将基本类型用包装器类型包装起来。拆箱：将包装器类型转换为基本类型。装箱其实就是调用了包装类的valueOf()方法。拆箱其实就是调用了xxxValue()方法。比如：Integer i = 10等价于Integer i = Integer.valueOf(10); int n = i等价于int n = i.intValue(); 有了基本数据类型，为什么还要有包装类？Java 是一个面向对象的语言，而基本类型不具备面向对象的特性。 这是一 个设计缺陷，自动装箱与拆箱是为了补救这个缺陷。 包装类里面有一些很有用的方法和属性，如 HashCode，ParseInt。 基本类型不能赋 null 值，但某些场合又需要。 有些地方不能直接用基本类型，比如集合的泛型里面。 因此，光有基本数据类型是不行的，引入包装类，弥补基本数据类型的缺陷。 1.2 常量池缓存技术在 Java 中基本类型的包装类的大部分都实现了常量池技术。比如： Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在[0,127]范围的缓存数据， Boolean 直接返回 True Or False 。两种浮点数类型的包装类 Float，Double没有实现常量池技术。 12345678910111213141516171819public static void main(String[] args) &#123; Integer e = 1; // 整型变量，存储在栈中 Integer f = new Integer(1); // 整型对象，存储在堆中 Integer g = new Integer(128); System.out.println(e == f); //这里&#x27;==&#x27;比较的是他们在内存中的地址，而不是值，所以不同 System.out.println(e.equals(f));//要比较值，需要用equals方法，比较的是内容 System.out.println(g == f); System.out.println(&quot;---------------------------&quot;); Double a = 1.0; Double b = 1.0; Double c = 2.0; Double d = 2.0; System.out.println(a == b); // 浮点数是以二进制形式存储的，在数值计算时会产生精度误差 System.out.println((c - 0) == (d - 0)); // 最好的方法是通过与定值作差，进行比较&#125; image.png 包装类里面引入缓存技术的好处是什么？有助于节省内存，提高性能 1.3 String(不是基本数据类型) 在 Java 8 中，String 内部使用 char 数组存储数据。并且被声明为 final，因此它不可被继承。 image.png 1.3.1 为什么String要设计成不可变（不可变性的好处）1、可以缓存hash值因为String的hash值经常被使用，例如用String作为HashMap的key。String的不可变性可以使得hash值不可变，因此只需要一次计算。2、常量池优化String在创建对象后，会在字符串常量池中进行缓存，如果下次创建同样的对象时，会直接返回缓存的引用。3、线程安全String的不可变性天生具备线程安全的特性，可以在多个线程中安全地使用。 1.3.2 什么是字符串常量池 字符串常量池位于方法区中，专门用来存储字符串常量，可以提高内存的使用率，避免开辟多块空间存储相同的字符串。在创建字符串时 JVM 会首先检查字符串常量池，如果该字符串已经存在池中，则返回它的引用；如果不存在， 则实例化一个字符串放到池中，并返回其引用。Q：String str = new String(&quot;A&quot;+&quot;B&quot;);会创建多少对象？A：会创建两个对象：一个是”AB”，另一个是new String()对象，其中包含值”AB”。具体来说，”A”和”B”都是字符串常量，它们会在编译时会被JVM优化，被合并为一个字符串常量”AB”。然后，使用这个常量来创建一个新的String对象。因此，总共会创建两个对象。 1.3.3 String、StringBuffer、StringBuilder之间区别1、可变性String不可变；StringBuffer和StringBuilder是可变的。2、线程安全性String由于不可变性，所以是线程安全的；StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的；StringBuilder没有加同步锁，不是线程安全的。3、性能StringBuilder &gt; StringBuffer &gt; String4、各自适合使用的场景String：操作少量数据；StringBuffer：多线程操作字符串缓冲区下操作大量数据；StringBuilder：单线程操作字符串缓冲区下操作大量数据； 1.4 StringBuilder的底层是什么？通过无参构造，append()添加元素时。数组的默认长度为16，每次扩容为数组原长度的2倍+2(value.length&lt;&lt;1+2)。 通过含参构造添加元素时。 直接添加一个长度。数组的初始长度为该长度； 添加一个字符串。数组的初始长度为该字符串的长度+16（str.length+16）。每次扩容为数组原长度的2倍+2（和上述append()方法相同，因为也是通过append()添加元素的） 1.5 为什么基本数据类型正数取值范围要-1呢？以byte数据类型为例，占用内存是1个字节，每个字节占8位。 正值范围为：0000 0000 ~ 0111 1111 负值范围为：1000 0000 ~ 1111 1111 其中第一位是符号位，后面七位才表示数值，所以正数的范围是0 ~ 127，负数的范围是-0 ~ -127； 那么就会出现正零（0000 0000）和负零（1000 0000）两种情况，而实际中，只需要一个0即可。 所以将-0（1000 0000）的第一位既看作符号位又看成数值位，转换成二进制就是-128，于是byte数据类型的取值范围就是-128 ~ 127。 1.6 为什么Java中double类型操作精度会丢失？因为我们的计算机是二进制的。浮点数没有办法使用二进制进行精确表示。 计算机的 CPU 表示浮点数由两个部分组成：指数和尾数，这样的表示方法一般都会失去一定的精确度，有些浮点数运算也会产生一定的误差。 浮点运算很少是精确的，只要是超过精度能表示的范围就会产生误差。往往产生误差不是因为数的大小，而是因为数的精度。因此，产生的结果接近但不等于想要的结果。尤其在使用 float 和 double 作精确运算的时候要特别小心。 1.7 如何解决精度丢失的问题呢？ 可以用BigDecimal类。 用 float 或者 double 变量转为字符串，然后再构建 BigDecimal 对象。通常使用 BigDecimal(String val)的构造方法把基本类型的变量构建成 BigDecimal 对象。 通过调用 BigDecimal 的加，减，乘，除等相应的方法进行算术运算。 最后把 BigDecimal 对象转换成 float，double，int 等类型。 可以用整数代替浮点数，二进制整数可以完整的表示所有十进制整数，不存在精度丢失问题，因此我们可以将小数位数固定或者较少的数字转换成整数存储。比如存储货币金额，如果存储单位是元，则需要保留两位小数，例如23.45元。如果将单位改成分，则可以完全使用整数存储，例如2345分。 3、关键字和修饰符3.1 static作用：方便在没有创建对象时，调用方法和变量、优化程序性能。 3.1.1 static变量用 static 修饰的变量被称为静态变量，也被称为类变量，可以直接通过类名来访问它。静态变量被所有的对象共享，在内存中只有一个副本，仅当在类初次加载时会被初始化，而非静态变量在创建对象的时候被初始化，并且存在多个副本，各个对象拥有的副本互不影响。 3.1.2 static方法static 方法不依赖于任何对象就可以进行访问，在 static 方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法&#x2F;变量都是必须依赖具体的对象才能够被调用，但是在非静态成员方法中是可以访问静态成员方法&#x2F;变量的。 123456789101112131415161718public class Test &#123; //静态变量 public static String s1 = &quot;s1&quot;; //非静态变量 public String s2 = &quot;s2&quot;; //非静态方法 public void fun1()&#123; System.out.println(s1); System.out.println(s2); &#125; //静态方法 public static void fun2()&#123; System.out.println(s1); System.out.println(s2); //直接报错，静态方法中不能调用非静态变量s2 &#125;&#125; 3.1.3 static代码块静态代码块的主要用途是可以用来优化程序的性能，因为它只会在类加载时加载一次，很多时候会将一些只需要进行一次的初始化操作都放在 static 代码 块中进行。如果程序中有多个 static 块，在类初次被加载的时候，会按照 static 块的顺序来执行每个 static 块。 123456789public class Test &#123; static &#123; System.out.println(&quot;Hello world!&quot;); &#125; public static void main(String[] args) &#123; Test t = new Test(); &#125;&#125; 3.1.4 初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。如果存在继承关系的话，初始化顺序为： 父类中的静态变量和静态代码块 子类中的静态变量和静态代码块 父类中的实例变量和普通代码块 父类的构造函数 子类中的实例变量和普通代码块 子类的构造函数 总结：静态优于普通，父类优于子类 3.2 final 类：被修饰的类不可以被继承 方法：被修饰的方法不可以被重写 变量：被修饰的变量是基本类型，变量的数值不能改变；被修饰的变量是引用类型，变量便不能再引用其他对象，但变量所引用的对象本身是可改变的。 12345678910public class Test &#123; int a = 1; public static void main(String[] args) &#123; final int b = 1; b = 2;//直接报错，因为b变量被final修饰了，不能改变 final Test t = new Test(); t.a = 2;//不报错，因为可以改变引用类型变量所指的对象 &#125;&#125; 3.2.1 final、finally、finalize之间区别 final：主要用于修饰类、变量、方法； finally：一般用在try-catch中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。 finalize：属于Object类中的一个方法， 该方法一般由垃圾回收器来调用，当我们调用 System.gc()方法的时候，由垃圾回收器调用 finalize()， 回收垃圾。但 finalize()方法不一定会被执行。 3.2.2 为什么finalize方法不一定会被执行？因为JVM并不保证会在任何时刻都执行垃圾回收操作，所以也就无法保证finalize()方法会被调用。另外，finalize()方法的执行也可能被延迟或者被中断，这可能会导致finalize()方法不被执行。因此，我们不能依赖于finalize()方法来进行重要的清理工作，尤其是对于需要确保资源正确释放的程序。相反，应该使用try-with-resources语句或者显式地在程序中调用**close()**方法来确保资源得到正确释放。 3.3 this3.3.1 引用当前类的实例变量主要用于形参与成员变量重名的时候，用this来区分 1234567String name;int age;public void Person(String name, int age)&#123; this.name = name; this.age = age;&#125; 3.3.2 调用当前类方法1234567891011121314public class Test &#123; public void fun1()&#123; System.out.println(&quot;fun1&quot;); &#125; public void fun2()&#123; this.fun1();//其实这里this可以省略 &#125; public static void main(String[] args) &#123; Test test = new Test(); test.fun2(); &#125;&#125; 3.3.3 调用当前类的构造函数注意！this()一定要放在构造函数的第一行，否则编译不通过。 12345678910111213141516public class Person &#123; private String name; private int age; public Person()&#123; &#125; public Person(String name)&#123; this.name = name; &#125; public Person(String name, int age)&#123; this(name);//一定要放在构造函数的第一行 this.age = age; &#125;&#125; 3.3.4 可以通过this访问静态成员变量吗？可以。this代表当前对象，可以访问静态成员变量，而静态方法中是不能访问非静态变量，也不能用this引用。 3.4 super1、 super 可以用来引用直接父类的实例变量。和 this 类似，主要用于区分父类和子类中相同的字段；2、 super 可以用来调用直接父类构造函数。(注意：super()一定要放在构造函数的第一行) ；3、 super 可以用来调用直接父类方法。 3.5 this和super的区别相同点： 都必须在构造函数的第一行调用； 都指的是对象，均不可以在static环境中使用。 不同点： super是对父类构造函数的调用，而this是对重载构造函数的调用； super在继承了父类的子类的构造函数中使用，属于不同类间使用，而this是在同一类的不同构造函数中使用。 123456789101112131415161718192021222324252627282930313233public class Main &#123; public static void main(String[] args) &#123; Child child = new Child(&quot;Father&quot;, &quot;Child&quot;); child.test(); &#125;&#125;class Father&#123; protected String name; public Father(String name)&#123; this.name = name; &#125; public void say()&#123; System.out.println(&quot;hello，child&quot;); &#125;&#125;class Child extends Father&#123; private String name; public Child(String name1, String name2)&#123; super(name1);//直接调用父类的构造函数 this.name = name2; &#125; public void test()&#123; System.out.println(this.name); System.out.println(super.name);//引用直接父类的实例变量 super.say();//调用直接父类的方法 &#125;&#125; 运行结果 3.6 修饰符 default (即默认，什么也不写）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类） public : 对所有类可见。使用对象：类、接口、变量、方法 protected : 对同一包内的类和所有子类可见。使用对象：变量、方法。 注意：不能修饰类（外部类）。 4、面向对象4.1 面向对象和面向过程的区别面向对象和面向过程是两种编程的思想。 面向对象的编程方式使得每一个类都只做一件事，像雇佣了一群职员，每个人做一件小事，各司其职，最终合作共赢。 面向过程会让一个类越来越全能，就像一个管家一样，一个做了所有的事。 面向对象： 优点：易维护、易复用、易扩展； 缺点：性能比面向过程低。； 面向过程： 优点：性能比面向对象高。 缺点：但没有面向对象易维护、易复用、易扩展，开销比较大，比较消耗资源。 4.2 封装、继承、多态 封装：封装就是隐藏对象的属性和实现细节，仅对外公开接口，控制在程序中属性的读和修改的访问级别。（private&#x2F;get&#x2F;set 方法）。就好像我们看不到挂在墙上的空调的内部的零件信息（也就是属性），但是可以通过遥控器（方法）来控制空调。 继承：继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为。 通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。 多态：表示一个对象具有多种的状态，具体表现为父类的引用指向子类的实例。 对象类型和引用类型之间具有继承（类）&#x2F;实现（接口）的关系； 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定； 多态不能调用“只在子类存在但在父类不存在”的方法； 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。 在 Java 中实现多态的三个必要条件：继承、重写、向上转型。继承和重写很好理解，向上转型是指在多态中需要将子类的引用赋给父类对象。 12345678910111213141516171819public class Main &#123; public static void main(String[] args) &#123; Father father = new Child(); //向上转型，将子类引用赋予父类对象 father.run(); &#125;&#125;class Father&#123; public void run()&#123; System.out.println(&quot;Father run&quot;); &#125;&#125;class Child extends Father&#123; //继承 @Override public void run()&#123; //重载 System.out.println(&quot;Child run&quot;); &#125;&#125; 运行结果 4.3 如何打破一个类的封装得到其方法、属性等信息？ 反射（Reflection）：Java提供了反射机制，允许在运行时获取类的信息，包括方法、属性、构造函数等。通过Class类和相关反射类，可以获取类的所有成员信息并进行调用。这是一种高级技术，需要注意不要滥用，因为它可以绕过封装，导致不安全或不稳定的代码。 继承：如果一个类是可继承的，可以创建它的子类，然后在子类中访问父类的受保护或包级私有成员。但这种方法需要继承的权限，且不适用于final类，所以通过继承来打破封装的行为有局限性。 4.4 面向对象的七大原则 单一职责原则：一个类只负责一个功能领域中的对应职责； 开闭原则：软件实体应对扩展开放，修改关闭； 里氏替换原则：所以引用基类（父类）的地方能够透明地使用其子类对象； 依赖倒转原则：抽象不应该依赖于细节，细节应该依赖于抽象； 接口隔离原则：使用多个专门的接口，而不使用单一的总接口； 合成复用原则：尽量使用对象组合，而不是继承来达到复用的目的； 迪米特法则：软件实体应尽可能少地与其他实体发生相互作用。 5、重载和重写的区别在Java中，方法重载（overloading）和方法重写（overriding）都是实现多态的方式。 重载：是指在同一个类中定义两个或多个方法，它们具有相同的名称，但是参数列表不同。当程序调用这个方法时，Java编译器根据调用时提供的参数类型和数量来确定使用哪个方法。重载的方法不能根据返回类型进行区分。 重写：是指在一个子类中定义一个与父类中同名、同参数的方法，这个方法会覆盖父类中的方法。当程序使用父类的对象调用这个方法时，实际上会调用子类中的方法。子类中重写的方法返回值类型要 ≤ 父类， 抛出的异常 ≤ 父类，访问修饰符 ≥ 父类；如果父类中该方法访问修饰符为 private/final/static则子类中就不能重写。 方法的重写要遵循“两同两小一大” 重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。 重写就是子类对父类的重新改造，外部样子不能变，内部逻辑可以改变。 6、抽象类和接口的对比 抽象类：用来捕捉子类的通用特性的； 接口：抽象方法的集合。 6.1 两者异同相同点： 都不能实例化； 都包含抽象方法，其子类都必须对这些方法进行重写。 都可以有默认实现的方法； 不同点： 接口中只能有抽象方法，抽象类中可以有非抽象的方法。 接口中变量只能是public/static/final 类型，抽象类则不一定。 一个类可以实现多个接口，但是只能继承一个抽象类。 接口的方法默认是 public ，而抽象方法可以有 public、protected、default，但不能用 private 6.2 接口应用场景 类与类之间需要特定的接口进行协调，而不在乎其如何实现。 作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。 需要将一组类视为单一的类，而调用者只通过接口来与这组类发生联系。 需要实现特定的多项功能，而这些功能之间可能完全没有任何联系。 6.3 抽象类应用场景 定义了一组接口，但又不想强迫每个实现类都必须实现所有的接口。可以用抽象类定义一组方法体，甚至可以是空方法体，然后由子类选择自己所感兴趣的方法来覆盖。 某些场合下，只靠纯粹的接口不能满足类与类之间的协调，还需要类中表示状态的变量来区别不同的关系。抽象类的中介作用可以很好地满足这一点。 规范了一组相互协调的方法，其中一些方法是共同的，与状态无关的，可以共享的，无需子类分别实现；而另一些方法却需要各个子类根据自己特定的状态来实现特定的功能。 一句话总结，在既需要统一的接口，又需要实例变量或缺省的方法的情况下，就可以使用它。 7、内部类 内部类包含：成员内部类、局部内部类、匿名内部类和静态内部类。 7.1 成员内部类定义：位于另一个类的内部，成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括 private 成员和静态成员）。 123456789101112131415public class Outer &#123; private double a = 0; public static int b = 1; public Outer(double a)&#123; this.a = a; &#125; class Inner&#123; //内部类 public void fun()&#123; System.out.println(a);//访问private成员 System.out.println(b);//访问静态成员 &#125; &#125;&#125; 当成员内部类拥有和外部类同名的成员变量或者方法时，默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：外部类.this.成员变量 ； 在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问； 成员内部类是依附外部类而存在的，如果要创建成员内部类的对象，前提是必须存在一个外部类的对象。 1234567891011121314151617181920212223242526272829public class Outer &#123; private double a = 0; public static int b = 1; public Outer()&#123; &#125; public Outer(double a)&#123; this.a = a; Inner inner = new Inner(); //创建内部类对象 inner.fun(); //调用内部类方法 &#125; class Inner&#123; //内部类 int b = 2; public void fun()&#123; System.out.println(a); System.out.println(b); //访问内部类成员变量的b System.out.println(Outer.this.b); //访问外部类的成员变量b &#125; &#125;&#125;class Test&#123; public static void main(String[] args) &#123; Outer outer = new Outer(); Outer.Inner inner = outer.new Inner(); //创建内部类对象 &#125;&#125; 7.2 局部内部类定义：是定义在一个方法或者一个作用域里面的类。它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。定义在实例方法中的局部类可以访问外部类的所有变量和方法，定义在静态方法中的局部类只能访问外部类的静态变量和方法。 1234567891011121314151617181920212223242526272829303132public class Outer &#123; private int outer_a = 1; private static int static_b = 2; public void test1()&#123; int inner_c = 3; class Inner &#123; private void fun()&#123; System.out.println(outer_a); System.out.println(static_b); System.out.println(inner_c); &#125; &#125; Inner inner = new Inner(); //创建局部内部类 inner.fun(); &#125; public static void test2()&#123; int inner_d = 3; class Inner&#123; private void fun()&#123; //编译错误 //定义在静态方法中的局部内部类不能访问外部类的实例变量 System.out.println(outer_a); System.out.println(static_b); System.out.println(inner_d); &#125; &#125; Inner inner = new Inner(); //创建局部内部类 inner.fun(); &#125;&#125; 7.3 匿名内部类定义：没有名字的内部类，在日常开发中使用较多。注意：使用匿名内部类的前提条件是必须继承一个父类或者实现一个接口。 12345678910111213interface Person&#123; public void fun();&#125;public class Demo &#123; public static void main(String[] args) &#123; new Person()&#123;\t//匿名内部类 public void fun()&#123; System.out.println(&quot;hello&quot;); &#125; &#125;.fun(); &#125;&#125; 7.4 静态内部类 静态内部类是不需要依赖于外部类的，并且它**不能使用外部类的非 static 成员变量或者方法 **。 7.5 内部类优点 内部类不为同一包的其他类所见，具有很好的封装性； 匿名内部类可以很方便的定义回调。 每个内部类都能独立的继承一个接口的实现，所以无论外部类是否已经继承了某个(接口的)实现，对于内部类都没有影响。 内部类有效实现了“多重继承”，优化 Java语言单继承的缺陷。 8、hashCode和equals8.1 equals先看String中的equals()方法的源码 image.png equals 方法会依次比较引用地址、对象类型、值的内容是否相同，都相同才会返回true。所以equals方法比==比较的范围更大、内容更多。用==判断为true的两个值，用equals判断不一定为true。 1234567891011121314Integer a = 100;Integer b = 100;System.out.println(a == b); // trueSystem.out.println(a.equals(b)); // trueInteger c = 200;Integer d = 200;System.out.println(c == d); // false，因为200超出了常量池缓存的范围，所以此时为falseSystem.out.println(c.equals(d)); // trueString s1 = new String(&quot;hello&quot;);String s2 = new String(&quot;hello&quot;);System.out.println(s1 == s2); // falseSystem.out.println(s1.equals(s2)); // true 8.2 hashCodehashCode 方法返回对象的散列码，返回值是 int 类型的散列码。散列码的作用是确定该对象在哈希表中的索引位置。 关于hashCode有一些约定： 两个对象的值相等，则hashCode一定相同。 两个对象有相同的hashCode值，它们不一定相等。 hashCode()方法默认是对堆上的对象产生独特值，如果没有重写 hashCode()方法，则该类的两个对象的 hashCode 值肯定不同。 8.3 为什么重写equals方法后，hashCode方法也要重写？以 HashSet 为例，HashSet 的特点是存储元素时无序且唯一，在向 HashSet 中添加对象时，首先会计算对象的 HashCode 值来确定对象的存储位置，如果该位置没有其他对象，直接将该对象添加到该位置；如果该存储位置有存储其他对象（此时新添加的对象和该存储位置的对象的HashCode值相同），则会调用 equals 方法判断两 个对象是否相同，如果相同，则添加对象失败，如果不相同，则会将该对象重新散列到其他位置。**所以重写 equals 方法后，hashCode 方法不重写的话，会导致所有对象的 HashCode 值都不相同，都能添加成功，那么 HashSet 中会出现很多重复元素。 ** 9、Java中只存在值传递123456789101112public class Demo &#123; public static void main(String[] args) &#123; int a = 1; printValue(a); System.out.println(&quot;a:&quot; + a); &#125; public static void printValue(int b)&#123; b = 2; System.out.println(&quot;b:&quot; + b); &#125;&#125; 运行结果： 运行结果 可以看到将 a 的值传到 printValue 方法中，并将其值改为 2。但方法调用 结束后，a 的值还是 1，并未发生改变，所以这种情况下为值传递。 值传递：是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递：是指在调用函数时将实际参数的地址直接传递到函数中，那么在 函数中对参数所进行的修改，将影响到实际参数。 可以明显看出，值传递和引用传递的区别在于向方法中传递的是实参的副本还是实参地址。 10、IO流IO流主要可以分为输入流和输出流。 按照操作单元划分，可以划分为字节流和字符流。 按照流的角色划分，可以划分为节点流和处理流。 Java IO流的40多个类都是从四个抽象类基类派生出来的： InputStream：字节输入流 OutputStream：字节输出流 Reader：字符输入流 Writer：字符输出流 10.1 有了字节流为什么还需要字符流？虽然字节流是信息处理的最小单位，但字符流是JVM转换得到，这个过程比较耗时，并且还容易出现乱码问题，因此Java在IO中就提供了可直接操作字符的字符流。 10.2 字节流和字符流区别？使用场景？ 字节流操作的基本单元是字节，字符流操作的基本单元是字符； 字节流默认不使用缓冲区，字符流使用缓冲区； 字节流通常用于处理二进制数据，不支持直接读写字符，字符流通常用于处理文本数据； 在读写文件需要对文本内容进行处理：按行处理、比较特定字符的时候一般会选择字符流；仅仅读写文件，不处理内容，一般选择字节流 11、常见IO模型在操作系统中， 为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为用户空间 （User space）和 内核空间（Kernel space ）。对于一次 IO 访问，数据会先被拷贝到内核的缓冲区中，然后才会从内核的缓冲区拷贝到应用程序的地址空间。 当发起 I&#x2F;O 调用后，会经历两个步骤： 内核等待 I&#x2F;O 设备准备好数据。 内核将数据从内核空间拷贝到用户空间。 由于存在这两个步骤，所以Linux产生了下面五种IO模型（BIO，NIO，IO多路复用，AIO，信号驱动IO），Java中前三种模型比较常见。 11.1 BIO（Blocking IO）BIO属于同步阻塞IO模型，在该模型中， 应用程序发起 read()调用后，会一直阻塞，直到内核把数据拷贝到用户空间。 BIO 在客户端连接数量不高的情况下，这种模式是没问题的。但是，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。因此，我们需要一种更高效的 I&#x2F;O 处理模型来应对更高的并发量。 11.2 NIO（Non-blocking&#x2F;New IO）NIO属于同步非阻塞IO模型， 在 Java 1.4 中就引入了 NIO 的概念， 对应于 java.nio 包，提供了 Channel,Selector,Buffer 等抽象类。 NIO 有三大核心部分：**Channel（通道）、Buffer（缓冲区）、Selector（选择器）** 。 它是一种支持面向缓冲的，基于通道的 I&#x2F;O 操作方法。对于高负载、高并发的（网络） 应用，应使用 NIO 。在同步非阻塞 IO 模型中，应用程序会一直发起 read()调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。 相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。但是，这种 IO 模型同样存在问题：应用程序不断进行 I&#x2F;O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。 NIO 11.2.1 Buffer的优点缓冲区(Buffer)就是在内存中预留指定大小的存储空间用来对输入&#x2F;输出(I&#x2F;O)的数据作临时存储，这部分预留的内存空间就叫做缓冲区： 使用缓冲区有这么两个好处： 减少实际的物理读写次数。 缓冲区在创建时就被分配内存，这块内存区域一直被重用，可以减少动态分配和回收内存的次数。 11.2.2 Channel的优点 Channel是一个通道，可以通过它读取和写入数据，它就像是水管一样，网络数据通过 Channel 进行读取和写入。 通道和流的不同之处在与通道是双向的，流只是在一个方向上移动（一个流必须是 InputStream 或者 OutputStram 的子类），而且通道上可以用于读，写或者同时用于读写。 因为 Channel 是全双工的，所以它可以比流更好的映射底层操作系统的 API。 11.3 IO多路复用IO 多路复用模型是通过一种机制，让一个进程可以监视多个Socket（套接字描述符）一旦某个Socket就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作，这样就不需要每个用户进程不断的询问内核数据准备好了没。 通过减少无效的系统调用，减少了对 CPU 资源的消耗。 IO多路复用 IO 多路复用模型中， 首先将进行IO操作的socket添加到select中； 然后阻塞等待select系统调用返回， 当数据到达时，socket就被激活，select函数返回，用户发起read请求，即可获取数据 select函数避免了NIO轮询等待，创建多个socket，通过不断调用select读取被激活的socket，实现在同一个线程内同时处理多个IO请求。 Selector Java 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。 常用的 IO 多路复用方式有 select、poll 和 epoll 。 11.3.1 IO多路复用的三种方式有什么区别？ select和poll只会通知用户进程有Socket就绪，但是不确定具体是哪个Socket，需要用户进程一个一个去询问； epoll则会在通知用户进程有Socket就绪时，把已就绪的Socket写入用户空间，避免了用户询问的过程； 11.4 AIO（Asynchronous IO）AIO就是异步IO模型，AIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2,它是异步 IO 模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 AIO 11.5 BIO、NIO、AIO的区别举个生活中简单的例子，你妈妈让你烧水 同步阻塞BIO： 小时候你比较笨，坐在水壶旁边傻等着水开（傻傻等待数据的到达） 优点：实现简单； 缺点：线程阻塞，并发能力差； 同步非阻塞NIO： 等你稍微大一点，你知道烧水的空隙可以去玩，只需时不时来看看水开了没有（轮询） 优点：线程不需要阻塞； 缺点：每个线程都需要多次轮询，CPU开销比较大； 异步非阻塞AIO ： 后来你家用上水开会发声的壶，你只需听到响声就知水开了，等待期间可以随便玩（通知） 优点：非阻塞，不需要轮询，并发性高，CPU利用效率高； 缺点：不适合轻量级数据传输，因为性价比的太低。 12、Java反射机制 Java 反射机制指在运行状态中， 对于任意一个类，都能够获取这个类的所有属性和方法； 对于任意一个对象，都能够调用它的任意一个方法和属性。 这种动态获取类信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。 12345678910111213141516171819202122232425262728class Person&#123; public String name = &quot;Jack&quot;; public Person()&#123; &#125;&#125;public class Demo &#123; public static void main(String[] args) throws ClassNotFoundException &#123; //方法1：通过对象实例instance.getClass()获取 Person person1 = new Person(); Class c1 = person1.getClass(); //方法2：知道具体的类名的情况下可以使用类名.class Class c2 = Person.class; //方法3：通过Class.forName()传入类的路径获取 //但这种方法有可能会抛出ClassNotFoundException异常 Class c3 = Class.forName(&quot;Test.Person&quot;); //方法4：通过类加载器xxxClassLoader.loadClass()传入类的路径获取 //需要先创建一个类加载器 Class c4 = ClassLoader.getSystemClassLoader().loadClass(&quot;Test.Person&quot;); System.out.println(c1.equals(c2));\t//true System.out.println(c1.equals(c3));\t//true System.out.println(c1.equals(c4));\t//true &#125;&#125; 因为在一个类在 JVM 中只会有一个 Class 实例，所以对 c1、c2、c3、c4 进行 equals 比较时返回的都是 true 。 12.1 反射机制优缺点优点：可以让代码更加灵活、为各种框架提供开箱即用的功能提供了便利；缺点：增加了安全问题。比如可以无视泛型参数的安全检查；反射的性能也要稍差点。 12.2 为什么反射的性能会差？ 反射需要动态解析类的信息，包括访问修饰符、字段、方法、参数、注解等，因此需要进行大量的运行时检查和解析，会比直接调用代码的执行速度慢。 反射机制在执行时会涉及到许多动态分配对象的操作，这些操作会占用大量的内存，并且需要进行垃圾回收，导致额外的性能损耗。 反射方法的调用通常比直接调用方法慢很多，因为它需要进行许多额外的操作，如方法解析、参数类型检查、安全检查等。 反射方法的调用通常不能进行编译时优化，因此会导致运行时性能低下。 12.3 反射的使用场景 Spring通过反射来帮我们实例化对象，并放入到IoC容器中 ； 使用JDBC链接数据库时加载数据库驱动Class.forName() ； 逆向代码 例如反编译； 利用反射，在泛型为Integer的ArryaList集合中存放一个String类型的对象。 13、Java异常13.1 Java中的异常体系说一下在Java中，所有的异常都有一个共同的祖先java.lang包中的 Throwable 类。Throwable 类有两个重要的子类 Exception（异常）和 Error（错误）。Exception 能被程序本身处理( try/catch )，Error 程序本身⽆法处理，只能尽量避免。 Exception 和 Error 二者都是 Java 异常处理的重要⼦类，各自都包含⼤量⼦类。 13.2 常见异常和错误异常： SQLException 操作数据库异常 ； IOException 输入输出异常 ConcurrentModificationException 并发修改异常 NullPointException 空指针异常 ArrayOutOfBoundsException 数组下标越界异常 ClassCastException 强制类型转换异常 错误： VirtualMachineError JVM运行错误 StackOverFlowError 栈溢出错误 OutOfMemoryError 堆空间不足错误 13.3 异常处理方式有哪些？ try-catch-finally：其中try用来捕获异常，catch用来处理捕获到的异常，finally用来关闭一些资源，无论是否捕获或处理异常，finally都会被执行。 throws：加在方法声明中用来抛出异常，其实并没有处理异常，而是将异常抛给此方法的调用者处理。 自定义异常类，但是必须继承某个异常类，比如编译时异常或运行时异常。 13.4 finally块一定会被执行吗？不一定，当出现以下三种特殊情况，finally块不会被执行： 在try或finally块中用了System.exit(int)退出程序； 程序所在的线程死亡； 关闭CPU。 13.4.1 try里面有return，finally还会被还行吗？会被执行，但是finally里面的语句不会改变return的值。 这是因为在执行的过程中，try执行到return时，会先把返回值存在一个临时变量中，只有当finally被执行完毕后，才会返回return的结果，因此finally哪怕会执行，也无法改变返回结果。 13.4.2 如果finally里面也有return，返回的结果已谁为准呢？如果finally中也有return的话，这时候try里面的return结果就会丢失，只会返回finally中的return结果。 13.5 受检查异常和不受检查异常有什么区别？ 受检查异常：Java 代码在编译过程中，如果受检查异常没有被 catch或者throws 关键字处理的话，就没办法通过编译。 不受检查异常：Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。 RuntimeException 及其子类都统称为非受检查异常，常见的有： NullPointerException(空指针错误) IllegalArgumentException(参数错误比如方法入参类型错误) NumberFormatException（字符串转换为数字格式错误，IllegalArgumentException的子类） ArrayIndexOutOfBoundsException（数组越界错误） ClassCastException（类型转换错误） ArithmeticException（算术错误） SecurityException （安全错误比如权限不够） UnsupportedOperationException(不支持的操作错误比如重复创建同一用户) 除了RuntimeException及其子类以外，其他的Exception类及其子类都属于受检查异常 。常见的受检查异常有：IO 相关的异常、ClassNotFoundException、SQLException… 13.6 Java中常见的OOM异常有哪些？ 当堆内存没有足够空间存放新创建的对象时，就会抛出OOM异常。 当 Java 进程花费 98% 以上的时间执行 GC，但只恢复了不到 2% 的内存，且该动作连续重复了 5 次，就会抛出 java.lang.OutOfMemoryError:GC overhead limit exceeded 错误。简单地说，就是应用程序已经基本耗尽了所有可用内存， GC 也无法回收。 元空间已被用满，通常是因为加载的 class 数目太多或体积太大。 每个 Java 线程都需要占用一定的内存空间，当 JVM 向底层操作系统请求创建一个新的 native 线程时，如果没有足够的资源分配就会报此类错误。 JVM 限制了数组的最大长度，该错误表示程序请求创建的数组超过最大长度限制。 14、Java序列化序列化就是将对象转换成字节流以便存储或传输，反序列化就是将字节流序列转换回对象的过程。 14.1 为什么要序列化和按序列化？将 Java 对象转换成字节序列，这些字节序列更加便于通过网络传输或存储在磁盘上，在需要时可以通过反序列化恢复成原来的对象。 通过序列化与反序列化可以实现不同计算机环境或进程间的数据传输与共享。 14.2 为什么要实现Serializable接口？实现Serializable接口是为了支持序列化和反序列化操作，只是起到一个标记作用。 可以确保只有那些被设计为可序列化的类的对象才能序列化； 规范了类的行为，表示该类的对象可以被序列化； 15、深拷贝、浅拷贝和引用拷贝15.1 Java中的深拷贝、浅拷贝和引用拷贝了解吗？ 引用拷贝：引用拷贝就是复制一个引用，两个不同的引用指向同一个对象； 浅拷贝：浅拷贝会在堆上创建一个新的对象（与引用拷贝的区别）。 对基本数据类型，拷贝的就是基本数据类型的值； 对引用数据类型，拷贝的就是内存地址，只是把内存地址赋给了新对象的成员变量，它们指向的使用一片内存空间。如果改变原对象的内容，浅拷贝的对象内容也会改变； 深拷贝：深拷贝也会在堆上创建一个新的对象，并申请了一个新的内存空间，相当于把复制的对象所引用的对象都复制了一遍。 对基本数据类型，拷贝的就是基本数据类型的值； 对引用数据类型，创建一个新的对象， 并复制其成员变量，两个引用指向两个不同的内存空间，但对象内容相同。改变原始对象的值，深拷贝对象的内容不会改变。 拷贝的区别 15.2 深拷贝实现方式重载clone方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Address implements Cloneable&#123; private String city; public Address(String name)&#123; this.city = name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; //这里的super.clone为浅拷贝 return super.clone(); &#125; public String getName() &#123; return city; &#125; public void setName(String address) &#123; this.city = address; &#125;&#125;class Person implements Cloneable&#123; private String name; private int age; private Address address; public Person(String name, int age, Address address)&#123; this.name = name; this.age = age; this.address = address; &#125; @Override //深拷贝 public Object clone() throws CloneNotSupportedException&#123; Person person = (Person) super.clone(); //调用address.clone重新赋值，因为address为引用类型 person.address = (Address)address.clone(); return person; &#125; public Address getAddress() &#123; return address; &#125; public void setAddress(Address address) &#123; this.address = address; &#125;&#125;public class Main &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Address address = new Address(&quot;天津&quot;); Person person = new Person(&quot;张三&quot;,23,address); System.out.println(&quot;拷贝前的地址：&quot; + person.getAddress().getName()); //深拷贝 Person clonePerson = (Person)person.clone(); clonePerson.getAddress().setName(&quot;北京&quot;); System.out.println(&quot;拷贝后的地址：&quot; + clonePerson.getAddress().getName()); &#125;&#125; image.png 16、常见的Object方法String toString()：返回该对象的字符串表示。 Object clone()：创建与该对象的类相同的新对象。 Class getClass()：返回一个对象运行时的实例类。 boolean equals(Object)：比较两对象是否相等。 int hashCode()：返回该对象的散列码值。 void wait()：在其他线程调用此对象的notify() 方法或 notifyAll()方法前，导致当前线程等待。 void notify()：唤醒等待在该对象的监视器上的一个线程。 void notifyAll()：唤醒等待在该对象的监视器上的全部线程。 void finalize()：当垃圾回收器确定不存在对该对象的更多引用时，对象垃圾回收器调用该方法。 17、泛型17.1 什么是泛型？有什么优缺点？Java 泛型（Generics） 是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性。 编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。 比如 ArrayList&lt;Person&gt; persons = new ArrayList&lt;Person&gt;() 这行代码就指明了该 ArrayList 对象只能传入 Person 对象，如果传入其他类型的对象就会报错。 并且，原生 List 返回类型是 Object ，需要手动转换类型才能使用，使用泛型后编译器自动转换。 优点： 提高Java程序的类型安全。通过变量声明中捕获这一附加的类型信息，泛型允许编译实施这些附加的类型约束。类型错误就可以在编译时被捕获了，而不是在运行时当作ClassCastException展示出来； 消除强制类型转换。可以消除代码中的很多强制类型转换； 提高运行效率，避免很多不必要的装箱、拆箱操作，提高程序的性能。 缺点： 代码复杂性： 有时候泛型代码可能会比非泛型代码更加复杂，特别是当需要处理通配符、边界和类型擦除等特性时。 类型擦除： Java中的泛型是通过类型擦除实现的，这意味着在运行时无法获取泛型的实际类型参数，限制了一些高级的泛型操作。 17.2 说说什么是泛型的类型擦除？下面代码的执行结果是什么？ 12345public static void main(String[] args) &#123; List&lt;String&gt; list1 = new ArrayList&lt;String&gt;(); List&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;(); System.out.println(list1.getClass()==list2.getClass());&#125; 因为getClass()方法获取的是对象运行时的类，那么这个问题就可以转换为ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;的对象在运行时对应的Class是否相同？ 通过运行代码，发现程序会打印true，这也就说明虽然两个List中都声明了具体的泛型，但是两个List对象对应的Class是一样的，所以结果是true。 也就是说，虽然ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;在编译时是不同的类型，但是在编译完成后都被编译器简化成了ArrayList，这一现象，被称为泛型的类型擦除(Type Erasure)。泛型的本质是参数化类型，而类型擦除使得类型参数只存在于编译期，在运行时，jvm是并不知道泛型的存在的。 总结：泛型信息只存在于代码编译阶段，在进入jvm之前，与泛型相关的信息会被擦除。 17.3 为什么要进行泛型的类型擦除呢？主要的目的是避免过多的创建类而造成的运行时过度消耗资源，试想一下，如果用List&lt;A&gt;表示一个类型，再用List&lt;B&gt;表示另一个类型，以此类推，无疑会引起类型的数量爆炸。 17.4 反射能获取泛型的类型吗？反射中的getTypeParameters方法可以获得类、数组、接口等实体的类型参数，但是不能获得真正的泛型类型，只能获取到泛型的参数占位符。 18、动态代理18.1 Java中的动态代理是什么？有哪些应用？当想要给实现了某个接口的类中的方法，额外加一些处理，比如说日志、事务等。可以给这个类传建一个代理，顾名思义就是创建一个新的类，这个类不仅包含原来类方法的功能，而且还在原来的基础上添加了额外的功能。这个代理类并不是定义好的，而是动态生成的，灵活性、扩展性更强。 最经典的应用就是Spring AOP。 18.2 怎么实现动态代理？每个动态代理类都必须要实现InvocationHandler这个接口，并且每个代理类的实例都关联到了一个handler。 当我们通过代理对象调用一个方法时，这个方法的调用就会被转发为由InvocationHandler这个接口的invoke方法来调用。","tags":["Java","八股","基础","面试"],"categories":["Java八股","基础"]},{"title":"常用命令","path":"/2023/04/25/常用命令/","content":"常见的Linux版本：Centos、Ubuntu、RHEL、Fedora、Debian Linux目录 常见的远程连接工具：XShell、FinalShell、SecureCRT、Putty 一、Linux常用命令 进入用户主目录：cd或cd ~ 进入根目录：cd / 返回上级目录：cd .. 返回上两级目录：cd ../.. 切换到上一个操作所在目录：cd - 切换目录：cd/home/admin 查看当前目录下文件：ls 查看当前目录下文件（包含隐藏文件）：ls -a 查看该目录下所有目录和文件的详细信息：ll 创建名为mydirectory的新目录：mkdir mydirectory 列出当前目录及子目录下所有文件和文件夹：find . 在/home目录下查找所有以.txt结尾的文件名：find /home -name &quot;.txt&quot; 显示当前工作目录的路径：pwd 删除名为mydirectory的空目录：rmdir mydirectory 删除名为mydirectory的目录：rm mydirectory 创建文件：touch file 创建两个文件：touch file1 file2 将文件file重命名为file1：mv file file1 将 file.txt 文件复制到 /home 目录下，并重命名为 file.txt（要求提示）：cp -i file.txt /home/file.txt 将 file.txt 文件复制到 /home 目录下，并重命名为 file.txt（不要求提示）：cp file.txt /home/file.txt 将 file.txt 文件移动到 /home 目录下，并重命名为 file.txt：mv file.txt /home/file.txt 删除当前目录下所有文件和文件夹：rm -rf * 查看file文件：cat file 修改文件的内容：vim file（输入wq代表写入内容并退出，即保存；输入q！代表强制退出，不保存） 重启当前系统：reboot 关闭当前系统：shutdown 查看当前系统下的进程信息：ps -aux 打开任务管理器查看进程(动态查看进程)：top 查看当前系统中开放的端口：netstat -anptu 从普通用户切换到root用户：su - 从root用户切换到普通用户：su - admin 查看当前用户名：whoami 查看系统中所有登录用户的信息：who -q 退出当前终端窗口：exit 杀死进程（-9表示强制终止），先用ps查找进程，然后用kill杀掉：kill -9 进程的pid 压缩文件：tar -zcvf file.tar.gz file(打包和压缩是一起的，所以文件的后缀名一般是.tar.gz) 解压文件：tar xvf file.tar.gz 列出所有可安装的软件清单：yum list 查找软件包：yum search 安装指定软件：yum install &lt;package name&gt; 更新指定软件：yum update &lt;package name&gt; 删除指定软件：yum remove &lt;package name&gt; 更新所有软件：yum update 二、Git常用命令git是一个常用的分布式版本管理工具 添加文件到暂存区：git add 提交文件到本地仓库：git commit 将本地仓库的新改变推送到远程仓库：git push 从远程仓库拉取项目到本地：git pull 将远程仓库复制到本地：git clone 抓取：git fetch 合并：git merge 查看工作区情况：git status -s","tags":["Java","八股","基础","面试","Git","命令","Linux"],"categories":["Java八股","扩展内容"]},{"title":"项目技术难点","path":"/2023/01/25/项目技术难点/","content":"一、医院预约挂号管理系统项目难点医院预约挂号管理系统 1、说一说什么是微服务，为什么要用微服务呢？1.1 微服务定义微服务是一种开发软件的架构和组织方法，其中软件由通过明确定义的API进行通信的小型独立服务组成。微服务架构使得应用程序更易于扩展和更快地开发。使用微服务架构可以将应用程序构建为独立的组件，并将每个应用程序进行作为一项服务运行。在对服务进行更新的时候不向整体式架构那样复杂，只需要针对各项服务进行更新、部署和扩展即可。 简单来讲，微服务将一个复杂的应用拆分成多个独立自治的服务，服务和服务之间通过松耦合的形式交互。 1.2 为什么要用微服务？（微服务优点有哪些？）微服务的优点： 不同的服务可以使用不同的技术； 隔离性。一个服务不可用不会导致其他服务不可用； 可扩展性。某个服务出现性能瓶颈，只需对此服务进行升级即可； 简化部署。服务的部署是独立的，哪个服务出现问题，只需对此服务进行修改重新部署； 2、项目中的微服务是怎么划分的呢？我们这个项目的微服务是根据业务功能进行的划分的，比如我负责的就是用户服务、医院服务、订单服务这几个微服务。 考虑到系统的复用性，由于在用户服务模块中的登录功能和订单服务中发送短信功能都用到了阿里云的短信服务，所以也将短信服务独立出来成为一个微服务。 3、那项目中微服务之间如何进行通信的呢？微服务通信方式主要有两种：同步调用和异步调用。 对于同步调用，这个项目中我们使用了SpringCloud中的Feign组件来实现。在不同的微服务之间调用时，我们将调用功能封装到了一个新的client微服务模块中。 在该模块的pom文件中引入openfeign依赖，并新建一个接口用于调用的封装； 然后使用@FeignClient注解来表明需要调用的微服务名称，这个名称就是在Nacos中注册的名称； 然后在接口内部，将要调用的方法直接复制过来，并在Mapping注解中补充完整方法的路径。在参数的@PathVariable注解中也要指定参数的名称。 最后在使用到的微服务模块的微服务中进行调用，在相应的pom文件中引入对应的client依赖，在需要调用的地方使用@Autowired注解注入，至此，使用Feign组件完成了远程调用。 对于异步调用，这个项目中我们用到的是RabbitMQ来实现的。比如在用户模块中的手机验证码登录功能中，需要发送短信，所以需要远程调用短信服务模块中的发送短信功能，可以将短信交给短信队列，用户模块作为生产者，而短信模块作为消费者帮忙发送短信。 4、RPC了解吗？简单说一说RPC调用的过程RPC 即远程过程调用（Remote Procedure Call Protocol，简称RPC），像调用本地服务(方法)一样调用服务器的服务(方法)。RPC是分布式架构的核心，也可以分为：同步调用和异步调用。 4.1 RPC远程调用的过程PRC架构中有四个组件： 客户端(Client)：就是服务的调用方； 客户端存根(Client Stub)：存放服务端地址信息，将客户端的请求参数打包成网络消息，再通过网络发送给服务方； 服务端存根(Server Stub)：接受客户端发送过来的消息并解包，再调用本地服务； 服务端(Server)：真正的服务提供者，也就是被调用方。 客户端以本地调用方式调用服务； 客户端存根接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体，就是序列化的过程； 客户端存根找到服务地址，并将消息通过网络发送到服务端； 服务端存根收到消息后进行解码，就是反序列化的过程； 服务端存根根据解码结果调用本地服务； 服务端执行处理逻辑； 服务端将结果返回给服务端存根； 服务端存根将返回结果打包成消息体，也就是序列化； 服务端存根将打包后的消息通过网络发送至客户端存根； 客户端存根接收到消息，并进行解码，就是反序列化； 客户端得到最终结果。 而RPC框架的目的就是把中间的这些步骤（2-10）封装起来，也就是把调用、编码、解码的过程封装起来，让用户像调用本地服务一样的调用远程服务。 5、什么是跨域问题？用Nginx怎么解决？为什么后面又改用Gateway了？5.1 跨域问题跨域问题是浏览器的同源策略限制，同源策略会阻止一个域的js脚本和另一个域的内容进行交互。所谓的同源就是指两个页面有相同的协议、主机号、端口号。 当一个请求地址中的访问协议、域名(IP地址)、端口号有任何一个与当前页面不一样就会产生跨域问题。（注：如果访问协议、域名和端口号都相同，但是请求路径不同，不属于跨域，比如www.jd.com/item和www.jd.com/goods。 由于微服务中不同的服务端口号不同，用户在各个页面进行跳转时，所以一定会存在跨域问题。 5.2 使用Nginx解决跨域问题Nginx解决跨域问题 由于后台有很多服务模块，每个模块都有对应的访问路径与端口，为了提供统一的api接口，可以使用Nginx作为反向代理服务器。正向与反向，是相对于用户来说的。 正向是用户主动配置代理服务器，比如科学上网。 反向是用户想要访问某些网站，需要先将请求发送到网站的反向代理服务器，由反向代理服务器再转发到真正的服务器。网站对外暴露的是代理服务器的地址，隐藏了真实服务器的地址。 Nginx把客户端的http请求转发到另一个或者一些服务器上。通过把本地一个url前缀映射到要跨域访问的web服务器上，就可以实现跨域访问。 对于浏览器来说，请求访问的就是同源服务器上的一个url。而Nginx通过检测url前缀，把http请求转发到后面真实的物理服务器。并通过rewrite命令把前缀再去掉。这样真实的服务器就可以正确处理请求，并且并不知道这个请求是来自代理服务器的。 如何使用Nginx？ 下载安装Nginx（Windows版）； 编辑Nginx的配置文件nginx.conf，编辑统一个访问端口，然后再编辑每个微服务的访问规则； 123456789101112server &#123; listen 9001; //访问的端口 server_name localhost; //主机名\t//以下是两条访问规则，路径包含hosp、cmn，就分别转发到相应的端口。\t//其中~表示正则匹配。\tlocation ~ /hosp/ &#123; proxy_pass http://localhost:8201;\t&#125;\tlocation ~ /cmn/ &#123; proxy_pass http://localhost:8202;\t&#125;&#125; 前端只需要设置请求路径，让请求先访问定义的统一访问端口，再由Nginx网关根据进行相应规则进行转发； 最后在对应的Controller上添加@CrossOrigin注解，即可解决跨域问题。 5.3 为什么后面改用Gateway解决了呢？随着业务的增多，微服务模块的增多，再继续使用Nginx配置就比较繁琐了。因为每新增一个微服务，就需要去nginx.conf文件中添加访问规则，并且最麻烦的是需要在每个模块里所有的Controller上添加跨域注解。 通过配置的网关信息，既可以解决跨域问题，又可以实现路由转发。使用了gateway就需要把之前接口上的@CrossOrigin注解去掉，否则会出错。 如何使用Gateway？ 搭建service-gateway 模块，在pom.xml中添加gateway依赖，注意 gateway 微服务也需要在 Nacos 中进行注册(添加服务注册依赖)； 修改 application.properties 文件，添加相关配置。比如设置服务端口、服务名、 nacos 服务地址、设置路由等； 添加启动类。 5.4 Gateway是如何实现动态路由的呢？项目里使用的方式是基于Nacos配置中心来做的。 简单来说，我们将路由配置放在Nacos中存储，Nacos会监听各个服务配置的变化，然后将配置更新到gateway中。 5.5 你刚才提到了正向代理和反向代理，能详细说说原理吗？5.5.1 正向代理正向代理：顺着请求的方向进行代理，也即客户端主动让代理服务器帮忙访问目标服务器。 比如说：我们现在在国内想要访问谷歌，但是由于某些众所周知的原因，没有办法直接访问到谷歌，这时候我们可以通过连接一台正向代理服务器，由它将我们的请求提交给谷歌，然后再将谷歌的响应反馈给我们，对于谷歌而言，他只知道有个请求过来，并不知道我是不是直接访问谷歌的。 正向代理 5.5.2 反向代理反向代理：与正向代理相反，客户端并不知道要访问哪个服务器，由反向代理服务器帮忙将请求转发给具体的服务器。 比如说：我们访问百度，百度的代理服务器对外的域名为 https://www.baidu.com 。但具体内部的服务器节点我们不知道。现实中我们通过访问百度的代理服务器后，代理服务器将我们的请求转发到他们N多的服务器节点中的一个，然后给我们进行搜索后将结果返回。此时，代理服务器对我们客户端来说就充当了提供响应的服务器，但是对于目标服务器来说，它只是进行了一个请求和转发的功能。 反向代理 5.5.3 总结 正向代理是代理客户端，服务端不知道实际发起请求的客户端； 反向代理是代理服务端，客户端不知道实际提供服务的服务端； 6、说说什么是Nacos？为什么要用Nacos？什么是注册中心？什么是配置中心？Nacos 是阿里巴巴开源的一个构建云原生应用的动态服务发现、配置管理的平台，可以作为注册中心和配置中心。 由于订单模块中预约挂号功能需要获取医院信息和就诊人信息，而这两个信息分别属于用户模块和医院模块，所以必须要进行远程调用。用到的技术就是使用注册中心和远程调用，而Nacos是一个很好的选择。 每个微服务在Nacos配置中心进行服务注册，然后就可以利用服务名、IP地址及端口号互相进行远程调用。 6.1 什么是注册中心？比如服务A需要调用服务B，但此时服务A并不知道服务B在哪几台服务器上，而且也不知道服务B是正常状态还是下线状态。为了解决这个问题，所以注册中心就出现了。 Nacos注册中心原理 注册中心原理： 服务注册的策略的是每5秒向nacos server发送一次心跳，心跳带上了服务名，服务ip，服务端口等信息。 Nacos服务端也会向客户端主动发起健康检查，支持tcp&#x2F;http检查。 如果15秒内无心跳且健康检查失败则认为这个服务不健康； 如果30秒内健康检查失败则剔除服务。 简单来说：已经在Nacos注册过的服务可以实时感知到其他服务的状态，如果某些服务下线，其他服务也能实时感知，从而避免调用不可用的服务。 6.2 什么是配置中心？每个服务都有大量的配置，并且每个微服务都可能部署在多台机器上。不可避免的就需要经常变更配置，可以让每个微服务通过配置中心获取自己的配置。 配置中心主要用来集中管理微服务的配置信息。 Nacos配置中心原理 如何使用Nacos？ 下载和安装； 在pom文件中引入Nacos依赖； 在配置文件中添加Nacos服务的地址； 在启动类上添加@EnableDiscoveryClient注解，开启服务注册，服务启动后就会在Nacos注册中心进行注册； 7、Feign组件是如何进行远程调用的？Feign远程调用的核心就是通过一系列的封装和处理，将以JAVA注解的方式定义的远程调用API接口，最终转换成HTTP的请求形式发给远程服务，远程服务器处理完之后，将HTTP的请求的响应结果，解码成JAVA Bean，返回给调用者。 Feign远程调用的基本流程，大致如下图所示： Feign远程调用流程 8、说说RPC和HTTP的关系我觉得RPC和HTTP并不是平行的概念，RPC可以采用HTTP协议来实现，也可以采用其他协议来实现。 HTTP协议是应用层的协议，是因特网数据传输的基础，主要服务于网页端和服务端之间的数据传输，而RPC是实现不同计算机应用之间的数据通信； HTTP是已经实现并且成熟的应用层协议，它定义了通信报文的一些格式，而RPC只是定义了不同服务之间数据通信的一个规范； HTTP协议和实现了RPC规范的框架都能实现跨网络节点之间的服务通信，由于RPC只是一种规范，所以只要符合RPC规范的框架都属于RPC框架，RPC也可以使用HTTP协议来实现，比如openFeign底层其实都采用了HTTP协议。 对于具体的应用场景：RPC适合微服务之间的调用，而HTTP协议一般用于api接口和前端进行交互。 9、什么是REST规范？REST是一种软件架构风格，REST通过HTTP协议定义的通用动词方法（GET、POST、PUT、DELETE），以URI对网络资源进行唯一标识，响应端根据请求端不同的需求，通过无状态通信，对其请求的资源进行表述。 简单来说，客户端与服务端之间通过url就知道需要什么资源，通过动词方式就只要需要干什么，通过状态码就知道结果是什么。 Rest架构的主要原则： 网络上的所有事物都被抽象为资源； 每个资源都有一个唯一的资源标识符； 同一个资源具有多种表现形式(xml,json等)； 对资源的各种操作不会改变资源标识符； 所有的操作都是无状态的 RESTful风格体现在 使用了Get请求，就是查询； 使用Post请求,就是新增的请求； 使用Put请求，就是修改的请求； 使用Delete请求，就是删除的请求。 这样做就完全没有必要对crud做具体的描述。 9.1 Rest的优点有哪些？ 统一代码风格，极大简化了前后端对接时间，提高了开发效率； 充分利用HTTP协议自身的语义； 无状态，在调用接口时，不用考虑上下文和当前状态，极大降低了复杂度。 10、SpringCloud的组件有哪些？Eureka —— 服务注册 Ribbon —— 负载均衡 Feign —— 远程调用 Hystrix —— 隔离熔断 Zuul —— 网关路由 10.1 项目里是如何实现负载均衡的？通过Spring Cloud Gateway中自带的负载均衡器实现，只需要在配置文件中设置路由的uri时加上lb://服务名，比如spring.cloud.gateway.routes[0].uri=lb://service-hosp，Gateway就会用自动实现负载均衡。 10.2 你知道哪些负载均衡算法呢？ 轮询，所有的请求被依次分发到每台服务器上； 加权轮询，根据服务器的硬件性能情况，在轮询的基础上，按照权重分配请求； 随机，请求被随机分配到各个服务器上； 最少连接，记录每个服务器正在处理的连接数，将新的请求分发到最少连接的服务器上； 源地址散列，根据请求来源的IP地址进行hash计算，保证来自同一个IP的请求总在一个服务器上。 11、说一说项目里两种登录功能的实现？11.1 如何进行登录校验？在gateway微服务模块中添加fillter用于判断用户登录状态。 通过网关服务中自定义的过滤器filter，先从请求头中获取用户信息； 查看用户id，如果存在表示用户已经登录； 若检查到用户未登录则拒绝请求并提示登录信息。 11.2 说一说项目里短信验证码登录流程 首先整合阿里云短信服务服务。 登录过程中用户点击获取验证码后，会先根据手机号码判断Redis中是否验证码： 如果有，直接判断前端输入的验证码与Redis中的验证码是否一致，一致就允许登录； 如果没有，则需要随机生成1个6位数的验证码，然后采用阿里云的短信发送接口，将验证码发送给手机，并以手机号码为key，验证码为值，将数据写入到Redis，并给短信验证码设置过期时间。 然后进行登录认证，将前端获取到的手机号和验证码，与手机收到的验证码进行比较，如果一致则登录成功，否则提示验证错误。 最后判断当前用户是否为第一次登录，如果是则将该用户信息加入数据库，完成注册，返回登录信息，并将用户的登录信息存入Token，便于登录用户的数据显示以及下次可直接登录。 11.3 介绍一下Token和JWTToken： 用户在完成登录后可以生成一个Token字符串，包含一些用户信息(如用户名)，当用户在进行一些请求操作时，请求头中会携带Token，系统可以通过Token判断用户的登录状态，即查看请求头中是否包含Token，以及Token是不是按规则生成的，满足条件后才让用户进行后续的操作，起到一个鉴别和防伪的功能。 JWT： JWT（Json Web Token）是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。 JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，比如用户登录。JWT最重要的作用就是对Token信息的防伪作用。 JWT生成Token的原理：JWT &#x3D; 公共部分(头信息，加密算法) + 私有部分(实际封装的信息，用户信息）+ 签名部分(哈希，当前服务器IP)。最后由这三者组合进行base64编码得到JWT。 通过签名算法以及服务器端生成的秘钥对base64编码后的公共部分和私有部分进行签名。如果有人用公共部分和私有部分的内容解码之后再生成新的JWT，由于不知道服务器端秘钥，因此服务器端进行JWT校验失败，就可以判断此JWT已经被篡改。 11.4 单点登录了解吗？随着系统微服务化以及应用的形态和设备类型增多，不能用传统的登录方式，核心的技术不是用户名和密码，而是Token，由授权服务器颁发Token，用户使用Token进行登录。 例如在百度旗下的百度贴吧登录后，则百度旗下百度音乐就不需要再登录，所以叫单点登录。 简单来说：所谓单点登录说的就是用户登录多个子系统中的其中一个，就有权访问与其相关的其他系统。 11.5 单点登录有哪些实现方式呢？你这个项目里是怎么实现的？单点登录我所了解的有三种方式： 使用Session广播机制实现 当在一个模块中进行登录后，就用session信息保存用户数据，并在多个模块中进行session复制，比如session.setAtrribute(&quot;user&quot;,user); 使用Cookie+Redis实现 在项目中任何一个模块进行登录，登录后，把数据放到两个地方： Redis：使用唯一随机值(比如用户id等)生成key，并在value中存放用户数据。 cookie: 把Redis里面生成的key值，放到cookie里面。访问项目其他模块时，发送请求带着cookie发送，获取cookie值，再到Redis中进行查询，根据key能够查询到用户数据，就成功登录。 使用Token实现（也是本项目采用的方式） 上面介绍了，通过JWT生成Token，其中包含有用户的信息，然后放在消息的请求头中，Token的方式比上面两种方式更安全。 Token实现登录流程 具体登录流程： 用户在浏览器上点击预约操作，请求会被发送到网关； 网关会拦截请求，验证用户的token是否有效； 如果无效token或token为空，返回给用户授权失败信息； 弹出用户登录窗口，让用户进行登录操作； 通过网关路由到用户微服务模块中的登录功能中； 进行正常用户登录操作； 登录成功后，通过JWT生成token并返回； 客户端将token存到cookie中； 用户继续点击预约下单操作，这次携带了有效地token； 网关拦截请求，验证用户的token有效； 网关路由到订单微服务模块； 进行预约下单操作。 11.6 Token和Session的区别是什么？相同点： 都是用户身份验证的一种识别手段； 都可以设置过期时间。 不同点： Session是存放在服务器端的，可以保存在数据库、Redis中，采用的是空间换时间的策略来进行身份识别，如果Session没有进行持久化，一旦服务器关闭重启，Session的数据就会丢失。 Token是存放在客户端的，比如cookie、localstorage中，采用了时间换空间的策略，通过不同元素的加密，会更安全。而且最重要的是Token比Session更适合分布式环境。 11.7 为什么Token比Session更适合分布式环境？先说说Session的创建过程吧。 因为Session是存储在服务器端的，所以当浏览器第一次请求Web服务器，服务器会产生一个Session存放在服务器里（可持久化到数据库中）； 然后通过响应头的方式将SessionID返回给浏览器写入到Cookie中，浏览器下次请求就会将SessiondID以Cookie形式传递给服务器端； 服务器端获取SessionID后再去寻找对应的Session； 如果找到了则代表用户不是第一次访问，也就记住了用户。 但是如果服务器做了负载均衡或者在分布式系统中有多台服务器，用户的下一次请求有可能会被定向到其他的服务器节点中，如果那台服务器上没有用户的Session信息，就会导致验证失败，所以Session在默认机制下不适合分布式环境。而Token是存在客户端的，就不会有这种问题，不论是哪个服务器节点，拿到Token后都是解析其中的用户信息，然后根据用户信息再去验证是否成功。 11.8 分布式系统的CAP原理知道吗？CAP原理：指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可同时获得(即最多只可得其二)。 一致性（C）：所有节点在同一时间的数据完全一致。 可用性（A）：服务一直可用，每个请求都能接收到一个响应，无论响应成功或失败。 分区容错性（P）：分布式系统在遇到某节点或网络分区障碍的时候，仍然能够对外提供满足一致性和可用性的服务。 CA满足的情况下，P不能满足的原因：数据同步(C)需要时间，还需要在正常时间内响应(A)，那么节点数量就要少，所以P就不满足。例如超市收银系统、图书管理系统。 CP满足的情况下，A不能满足的原因：数据同步(C)需要时间，节点数量也要求多(P)，但是通常性能不是特别高，所以A不满足。例如火车售票系统。 AP满足的情况下，C不能满足的原因：要求正常的时间内响应(A)，节点数量也要多(P)，那么数据就不能及时同步到其他节点，所以C不满足。例如博客系统，保证数据的最终一致性。NoSQL大多是典型的AP类型数据库。 11.8.1 Redis的主从模式是什么思想呢？Redis的主从模式实现的是AP思想，也即保障可用性和分区容错性，允许延迟一致性。 11.9 说一说项目里微信登录流程微信登录流程 第一步：在页面点击微信登录后，会请求一个Controller方法，这个Controller方法用于设置生成二维码所需的参数并返回，前端获取到这些参数后就可以在页面显示生成的二维码。 第二步：用户扫描登录二维码并确认授权后，微信后台会重定向到第三方应用(本项目)，并带上授权临时票据code (相当于设置了过期时间的验证码)； 第三步：通过code和设置的appid、appsecret，请求微信提供的固定地址(使用到了HttpClient工具)，换取access_token和openid(授权用户唯一标识)； 第四步：通过access_token和openid，请求微信提供的固定地址(使用到了HttpClient工具)，获取扫码人(用户)的基本信息； 第五步：将获取到的微信用户基本信息添加到数据库。(添加之前根据openid判断数据库是否存在扫描人的微信信息) 第六步：返回用户名、Token(由用户id和用户名生成)和openid。 第七步：重定向到前端页面，后台根据请求中的openid参数进行判断，是否第一次登录，如果是则需要绑定手机号。 12、订单模块的问题12.1 预约的时候如果并发量较大出现超抢问题怎么办？我们的项目里用的是Redis + RabbitMQ来解决高并发问题下的超抢问题，Redis主要用来减库存，而MQ用来实现异步下单： 当用户集中下单时，在Redis中通过对库存值加分布式锁，减少预约数量，保证高并发情况下线程安全问题，同时通过Redis也能减少数据库所直接承受的访问数量，避免数据库直接宕机。但是Redis的负载也不是无限的，所以加了一个标记变量专门记录是否还可以继续预约，如果此时可预约数为0，就直接返回预约失败，不让后续请求继续访问Redis； Redis中预约数量减少后，将消息推送到RabbitMQ中，然后由监听消息队列的消费者，根据接受到的消息，将消息队列中的订单写入数据库，实现异步下单操作，同步到数据库中； 在项目中我们还额外增加了两个限制： 对于同一个账号发送多次请求的情况，我们在预约挂号时，做了限制，一个账号每天只能预约两次，分别是上午和下午，将预约日期+时间段作为key，用户ID作为value，以ZSet数据结构形式存入Redis中，对其预约的次数做了限制，做到一人一天两单，这样可以避免同一个账号采用软件发送大量请求的情况； 对于大量账号发送请求的情况，我们也做了限制，引入了实名认证的功能，只有上传身份证的用户才能进行预约挂号操作，这样可以避免大量注册的小号预约挂号。 12.2 说说Redis的分布式锁怎么实现的？主要利用了Redis分布式锁中SETNX命令，作用是如果key不存在，就set进去。 获取锁命令：SET lock value NX EX 10； 释放锁命令：DEL key; 12.2.1 Redis实现分布式锁如何合理的控制有效时长？ 根据业务执行时间进行预估，但是这个时间不太好控制；（不推荐） 给锁续时长，这个就可以用Redisson来实现。 12.2.2 Redisson实现分布式锁的执行流程Redisson实现分布式锁流程 线程1尝试加锁，加锁成功的话可以直接操作Redis，同时会设置一个看门狗，每隔(releaseTime / 3)的时间对锁做一次续期操作，release默认是30s； 线程1手动释放锁时，也会通知看门狗，让它不用再做续期操作了； 当线程2尝试加锁时，如果加锁成功的话，就与线程1操作一样，如果加锁失败，就会循环判断(有个阈值，当循环次数超过阈值时，就会加锁失败)，不断尝试获取到锁。 12.2.3 如果线程释放锁操作异常，没能释放锁该怎么办？如果线程1释放锁异常，就会导致释放锁失败，看门狗仍然会一直对锁进行续期操作，其他线程也获取不到锁。 但是在Redisson中获取锁的方式是tryLock()而不是我们常规意义上的Lock()，在tryLock(long waitTime, long leaseTime, TimeUnit unit)方法中有三个参数，分别是最大等待时间、自动释放时间、时间单位。 如果在方法内没有传入释放时间，Redisson会自动添加一个定时任务，定时刷新失效时间，如果释放锁失败，就会自动释放锁； 如果在方法内传入了释放时间，就不会添加定时任务，到期时看门狗就不会续期，而是到期就自动释放锁； 12.2.4 Redisson实现的分布式锁是可重入的吗？为什么？Redis实现的分布式锁是不可重入的，但是Redisson实现的分布式锁是可重入的。 与Java多线程中的Reentrantlock实现原理差不多，都是通过线程ID判断是否是当前线程持有锁，并且记录可重入次数； Redis中利用Hash结构记录线程id和重入次数。 可重入锁原理 12.2.4 Redisson实现的分布式锁可以实现主从一致吗？Redisson中提供了RedLock（红锁），可以解决集群情况下分布式锁的可靠性。 红锁的基本思路是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。 这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。 加锁成功需要同时满足两个条件： 客户端从超过半数的Redis节点上成功获取到了锁； 客户端从大多数节点获取锁的总耗时 &lt; 锁设置的过期时间； 但是不建议使用红锁，因为实现复杂、性能差、运维繁琐。 12.3 还有其他方法解决超抢问题吗？说一说？还可以对数据库加锁，比如悲观锁和乐观锁： 悲观锁，就是在修改预约数量的时候，采用悲观锁，锁住下单请求方法，是的查询操作和更新操作组装为一个原子操作。但是这种方式的缺点就是，当并发请求数量太多的情况下，大量没有持有锁的线程都会进入到阻塞状态，导致请求的响应时间场，严重影响用户体验。 乐观锁，由于乐观锁的思想是认为在操作数据的时候不会被其他数据干扰，所以不会对数据加锁。在更新预约数量时，通过CAS机制来判断数据是否被其他线程更改过，如果没有更改，那么就执行-1操作；如果其他线程更改过，则执行策略，比如报错、重试等。 悲观锁的用户体验不好，用户需要等待时间过长，乐观锁只适合竞争不激烈的情况，并不适用于高并发情况。 12.3 怎么通过RabbitMQ的延迟队列解决超时订单自动取消？解决这个问题的方法很多，可以通过Redis中的ZSet、Spring Task来解决，但是这里我们用了RabbitMQ中的延迟队列来解决这个问题。 延迟队列是通过消息队列中的TTL（消息存活时间）和DLX（死信交换机）这两个属性间接实现。 我们的将订单消息是发送到消费队列中，并会设置消息的存活时间为15分钟，当15分钟到了之后，如果消息仍然没有被消费（就说明这个订单15分钟内仍然没有支付），所以订单消息就成了Dead Letter（死信）。就会通过死信交换机，将这个死信转发到延迟队列中，然后后台监听处理这个延迟队列中的消息，再实现更新订单的支付状态为未支付即可。这种方法需要两个队列，一个是主队列，也即消费队列，另一个是延迟队列，用来处理延迟消息的。 你提到可以用ZSet，说说看具体怎么实现？可以通过Redis的Zset来实现延迟队列，通过zadd score value的命令向内存中生产消息，并且利用设置好的时间戳作为score,然后将score从小到大排序，每次只获取ZSet中的第一条数据，也就是最早预约的订单号，这时候就有两种情况： 如果这个订单未超时，那么剩下的订单必然未超时； 如果这个订单超时了，那么就在ZSet中删除这个订单，并且在数据库中更新这个订单的支付状态。 12.4 RabbitMQ的结构了解吗？ 生产者：消息的发送方，需要注明发送方服务标识、队列名称、发送内容； 交换机：接收发送方的消息，根据路由规则转发到对应的队列中； 队列：用于暂时存储消息； 消费者：定义消息处理器方法，在方法上添加@RabbitListener监听消息并执行方法。 生产者（发消息） ——&gt; 交换机（消息转发） ——&gt; 消息队列 ——&gt; 消费者（监听并处理）。 12.5 说一说微信支付的流程下面是完整的微信支付流程，但是其中绝大部分工作都由微信支付系统帮我们完成了。 简单总结一下： 首先是用户在前端点击进行支付请求； 在我们的后台请求进行处理，下订单、生成订单号； 封装微信支付平台所需要的信息，将信息转换为XML格式； 将XML格式的信息从我们后台发送给微信支付平台的地址； 微信向我们后台返回XML格式的数据，将其转换为Map形式的数据，获取到其中的交易连接，将连接存入Redis中； 我们后台将交易链接发给前端，前端使用js将其转换成二维码图片，然后将二维码图片展示给用户； 用户使用微信扫一扫进行支付(这一部分就是用户与微信交互了，跟后台没有什么关系)； 用户支付成功后，微信平台会异步通知后台订单支付结果； 后台收到支付结果后，必须向微信回复接收情况，通知微信我们已经收到了支付的消息了； 同时前端界面也会定时（每3秒）调用查询支付状态的方法，及时更新展示支付信息。 12.6 怎么处理支付的状态的呢？后端写一个查询当前支付状态的方法，前端每3秒调用一次该方法去微信支付平台查询。 如果返回的结果集为空，说明支付出错；如果返回的结果不为空，就可以根据返回的结果判断支付的状态。 当返回的状态为支付成功时，就可以去订单库中更新订单的支付状态。 12.7 说一说项目里面退款的流程吧 首先要从数据库里获取到需要退款的这个订单号； 查询订单是否存在，以及查询订单的状态是否已经退过款了； 如果前面判断都没问题，确实需要退款，设置需要的参数，封装appid、商户号、退款金额等信息，调用微信接口，将封装好的信息发送给微信支付平台，同时需要设置退款证书； 接收微信支付平台返回的数据，同样将XML格式的数据转为Map，判断返回结果是否为不空且状态为成功，如果是则修改订单的支付状态为已退款。 13、定时就医短信提醒怎么实现的？ 创建定时任务微服务模块，通过Spring Task来实现定时任务的功能、通过RabbitMQ来实现短信发送功能，创建定时任务类和任务队列。 定时任务类中需要用到cron表达式，通过cron表达式就可以实现定时功能，在指定时间将消息发送到任务队列中。 在订单微服务模块中创建监听类，监听任务队列，然后去订单库中查找当天有预约的就诊人，在当天八点给他们发送就医短信提醒。 14、项目里的Redis是怎么使用的？用来干什么？ 用户登录时存取手机短信验证码，并设置验证码过期时间； 用户进行微信支付时，存取生成的支付二维码的返回结果，并设置二维码的有效时间； 解决高并发环境下，生成预减库，在Redis中实现预约数量减少的功能； 解决高并发环境下，一人一天两单限制的问题，将预约时间+时间段（上午或下午）作为key，用户ID作为value存入Redis中ZSet数据结构中，因为ZSet数据结构能避免解决重复预约并且能够自动排序的问题。 14.1 怎么使用Redis的呢？ 在Redis配置类RedisConfig上添加@EnableCaching注解开启缓存; 注入RedisTemplate，调用其中的opsForValue方法存取数据，比如redisTemplate.opsForValue().set(phone, code, 2, TimeUnit.MINUTES); 14.2 为什么用Redis而不用其他的？比如Memcached来做缓存？ Memcached 仅支持简单的 key-value 结构的数据类型，Redis 支持五种基本数据类型； 当物理内存用完时，Redis 可以将一些很久没用到的 value 交换到磁盘，而Mencached不行。； Redis 支持内存数据的持久化的，而且提供两种主要的持久化策略：RDB 快照和 AOF 日志。而 memcached 是不支持数据持久化操作的； Memcached 本身并不支持分布式，因此只能在客户端实现分布式存储，Redis 更偏向于在服务器端构建集群进行分布式存储。 14.3 你提到用Redis中ZSet来解决一人一天两单问题，具体怎么设置的呢？在我们项目中，每个用户可以预约接下来七天的日期进行就医，为了解决用户重复预约同一个天同一时间段订单的问题，我们将预约时间+时间段作为score，用户ID作为value存入Zset集合中。 比如用户ID是userId，当天时间为20230820，时间段是定义上午为1，下午为2。 ZADD order 202308201 userId 设置过期时间为7天，然后使用ZRANGE命令将ZSet中的成员按照score从小到大排序。 每次查询时，以当前时间为准，去除当前时间之前的数据，这样就能保证当前存储的数据都是7天内用户预约的数据，通过查询ZSet就能很快地判断，该用户有没有重复预约的问题。 15、项目中有哪些角色？系统的数据库又是怎么设计的？项目为预约前台和管理后台两个部分，所以也对应了两种角色：用户和管理人员。 至于数据库的设计，我们采用的是每一个微服务对应一个独立的数据库，比如订单服务模块，对应的就是订单数据库，其中包含有订单信息表、支付信息表、退款信息表三种，分别存放的是所有订单、已支付的订单和需要退款的订单。至于其中的字段则是根据具体的业务需求来设计的。 16、分布式数据库如何生成唯一且递增的ID？16.1 UUID（不符合要求，无法生成递增ID）核心思想：机器的网卡+当地时间+随机数，生成一个32位的英文和数字 + 4位连字号，但是一般都会将连字号去掉。 优点： 简单，本地生成且无网络消耗，具有唯一性； 缺点： 无序的字符串，不具备趋势的自增特性； 没有具体的业务含义； 无序性的UUID作为主键会导致数据位置频繁变动，严重影响性能。 16.2 主从模式核心思想：由主节点负责生成唯一且递增的ID，然后分配给各个从节点使用。 优点： 简单，本地生成； 缺点： 不利于后续扩容，本质还是由一个数据库生成，无法满足高并发的场景； 16.3 雪花算法核心思想：采用bigint（64位）作为id生成类型，并且将64位分为四段。 雪花算法 第一段：1位，表示符号位，正数是0，负数是1，但是由于id一般都是正数，所以一般都为0不变； 第二段：41位，表示时间戳，注意这里并不是当前时间戳，而是时间戳差值（当前时间戳 - 开始时间戳），其中开始时间戳由我们自己定义； 第三段：10位，表示工作机器的id，因为是分布式场景，所以可以允许最多布置1024个节点的分布式情况； 第四段：12位，表示毫秒内的计数，支持每个节点每毫秒，也即同一机器、同一时间产生的4096个id序列号； 优点： 整体上按照时间递增的顺序生成，后续插入索引的时候性能较好； 整个分布式系统内不会产生ID碰撞，因为最多支持1024个分布式节点； 本地生成，且不依赖于数据库，没有网络消耗，效率很高，每秒能生成26万个ID左右； 缺点： 由于雪花算法是高度依赖于时间的，所以在分布式环境下，如果发生时钟回拨，可能引起ID重复、ID乱序、服务不可用等情况。 解决方案： 将ID生成交给少量服务器，并关闭时钟同步； 直接抛出异常，交给业务层处理； 如果回拨时间很短，可以等待回拨时长之后再生成； 如果回拨时间很长，可以匀出1-2位作为回拨位，一旦时钟回拨，就将回拨位+1，就可以得到不一样的ID，如果还是超出，那还是需要抛出异常。 17、项目中线程池问题17.1 项目中有用到线程池吗？讲一讲怎么做的我们这个项目因为用到了RabbitMQ来解决定时任务模块中就医提醒的短信发送和订单模块中的超时订单自动取消的功能，处理方法都是将短信或者订单信息发送到消息队列中，然后后台对专门的队列进行监听，并处理信息。 以解决超时订单功能举例，刚开始延迟队列里消息不多的时候，其实一切都还挺正常的，但是一旦超时订单多了之后，发现使用消息队列发送信息的时候，一个消息队列的监听只能处理完一次发送之后，才能获取第二个消息内容，这样速度就会明显慢很多。所以我就想着能不能用线程池来批量消费RabbitMQ里的任务。 因为我们是在Spring框架中开发的项目，所以直接使用ThreadPoolTaskExecutor（ThreadPoolTaskExecutor其实是对ThreadPoolExecutor的一种封装）创建线程池，并把它注入到IoC容器中，全局都可以使用。 首先配置线程池的参数，包括核心线程数：4，最大线程数：16，救急线程存活时间为：120s，阻塞队列用的是有界队列，长度为80； 然后创建TreadPoolConfig类，通过@configuration注解将其注入到IoC容器中； 最后在订单模块中用线程池处理延迟队列里的超时订单信息，可以极大地提升消费者处理消息的速度。 17.2 如何避免消息被重复消费呢？ 每条消息设置一个唯一的标识id，通过id可以保证消息不会被重复消费； 通过幂等方案解决，比如分布式锁或者数据库锁。 17.3 如何保证消息队列里的消息不丢失呢？ 开启生产者确认机制，确保生产者的消息能到达队列，如果报错可以先记录到日志中，再去修复数据。 开启持久化功能，确保消息未消费前，在队列中不会丢失，其中的交换机、队列和消息都要做持久化。 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack，也要设置一定的重试次数（一般是3次），如果重试之后仍然没有收到消息，就将失败后的消息投递到异常交换机。 17.4 如何防止消息队列里的消息被重复消费呢？有三种思路： 如果数据是要写到数据库里的，那么可以在写数据之前用主键查一下数据库，如果数据库已经存在，就不插入，而是update； 如果数据是要写到Redis里面，那更简单了，直接用SETNX，保证原子性； 还有一种方法就是生产者发送每条数据时，给每个消息生成一个全局唯一ID，根据这个ID就可以保证消息不会被重复消费。 18、项目中事务的问题18.1 项目里有没有用事务？怎么用的？ 方法上加入@Transactional注解后，这个方法就成为了事务方法，如果对于注解的一些属性不做特殊配置的话，方法中如果出现了RuntimeException（运行时异常），事务会进行回滚，如果出现了checkedException(编译时异常)，则不会回滚。那么对于这类不会回滚的异常，我们的做法是手动配置@Transactional(rollbackFor = Exception.class)，这样也可以回滚了。 如果我们在事务方法中，手动捕获了异常，并没有让事务抛出去，也没有手动指定需要回滚，那么事务方法即使出现异常，也会提交事务。 对于异常回滚的处理，我们是定义了一个全局异常处理类，把catch到的异常按照定义的格式进行抛出。 二、校园跑腿系统校园跑腿系统 1、为什么要用ThreadLocal保存用户信息？不用行不行？因为如果每次都要解析token然后一层层传递会导致代码过于耦合，所以可以将从token中读取到的用户信息保存在线程中，当请求结束后把保存的信息清除。 这样可以方便在开发时直接从全局的ThreadLocal中很方便的获取用户信息。 创建拦截器，从请求头中获取token，然后解析token获得用户id，再保存到ThreadLocal中。 2、讲讲项目里的WebSocket2.1 什么是WebSocket？WebSocket是一种在单个 TCP 连接上进行全双工通信的协议，它允许客户端和服务器之间进行实时数据交换。 与传统的HTTP请求相比，WebSocket具有更低的延迟和更高的并发性，适用于实时通信场景，如即时聊天、弹幕、实时游戏、实时数据更新等。 2.2 WebSocket是怎么和客户端建立连接的？ 客户端发起WebSocket连接：客户端通过在浏览器中创建WebSocket对象，并使用WebSocket构造函数传入服务器的WebSocket地址发起连接； 服务器接收WebSocket连接请求：服务器端接收到客户端的连接请求后，会生成一个WebSocket实例，并保持与客户端的连接； WebSocket握手：在连接建立时，客户端与服务器会进行WebSocket握手，以确保双方都支持WebSocket协议，并建立双向通信； 双向通信：一旦握手成功，客户端和服务器就可以建立双向的通信，可以通过WebSocket对象的send()方法发送消息，通过onmessage事件接收消息； 维持链接：WebSocket连接一旦建立，客户端与服务端的通信通道就会一直保持打开状态，直到其中一方主动关闭连接或异常情况。 总结：WebSocket连接的建立过程是通过WebSocket对象的构造函数发起连接请求，服务器接受连接请求后进行握手，握手成功后建立双向通信通道，保持连接状态，实现实时双向通信的功能。 2.3 WebSocket断线之后有什么措施呢？ 重新连接：断开连接后，客户端会尝试重新连接； 错误处理：在连接断开后，可以监听onerror事件，并在事件处理程序中进行错误处理，比如输出错误日志； 显示断开提醒：可以直接在界面上提醒用户连接已断开，并提供相应的操作，比如重新连接； 自动重连：可以在连接断开时自动触发重连机制，不用用户手动操作重连。 2.4 WebSocket和常用的HTTP有什么区别呢？ 相同点： 都是基于TCP连接的，都是可靠的传输协议； 都是应用层的协议； 不同点： HTTP是短连接，而WebSocket是长连接； HTTP通信是单向的，基于请求响应模式，而WebSocket是双向通信协议，双方都可以发送和接收消息； HTTP是浏览器发起向服务器的连接，而WebSocket是浏览器和服务器握手建立的双相连接。 2.5 项目里具体是怎么实现催单提醒的呢？ 首先与其他的服务一样，需要在nginx.conf文件中配置webSocket的地址，让Nginx帮我们把webSocket的请求转发到localhost:8080上； 当用户点击催单按钮时，首先通过Controller拿到前端传过来的订单id，调用orderService中的催单方法； 先根据订单id查询数据库，判断是否存在该订单； 然后再封装订单的id和具体的提示内容； 再直接调用webSocketServer中创建的send()方法，以JSON格式向后台系统的浏览器客户端发送催单消息。","tags":["工作","项目","面经","难点"],"categories":["Java八股","扩展内容"]},{"title":"项目总结","path":"/2022/11/13/项目总结/","content":"1、项目总结1.1 后台管理系统功能总结1.1.1 医院设置管理 医院设置列表、添加、锁定、删除 医院列表、详情、排班、下线 1.1.2 数据管理 数据字典的树形显示、导入、导出 1.1.3 用户管理 用户列表、查看、锁定 认证用户审批 1.1.4 订单管理 订单列表、详情 1.1.5 统计管理 预约统计 1.2 前台用户系统功能总结1.2.1 首页数据显示 医院列表 1.2.2 医院详情显示 医院科室显示 1.2.3 用户登录功能 手机验证码登录 微信扫码登录 1.2.4 用户实名认证1.2.5 就诊人管理 就诊人列表、添加、详情、删除 1.2.6 预约挂号 显示排班和挂号的详情信息 确认挂号信息 创建预约挂号订单 订单微信支付 取消预约订单 1.2.7 就医提醒1.3 后端技术点1.3.1 SpringBoot1.3.2 SpringCloud nacos注册中心 Feign远程调用 Gateway网关 1.3.3 Redis 使用Redis缓存数据字典 短信验证码的有效时间、微信支付二维码有效时间 1.3.4 MongoDB 存储医院的相关信息 1.3.5 EasyExcel 对excel表格进行读写操作 1.3.6 MyBatis-Plus1.3.7 RabbitMQ 订单相关操作，发送mq消息 1.3.8 Docker 下载镜像 创建容器 1.3.9 阿里云OSS文件存储服务器 1.3.10 阿里云短信服务1.3.11 微信登录和支付1.3.12 定时任务1.4 前端技术点1.4.1 Vue1.4.2 Element-UI1.4.3 Nuxt1.4.4 npm1.4.5 ECharts","tags":["工作","Java","项目"],"categories":["Java技术","医院在线预约系统"]},{"title":"微信支付","path":"/2022/07/24/微信支付/","content":"一、支付流程 生成微信支付二维码 微信扫码 查询微信支付状态 支付中 支付成功 支付失败 支付成功后，更新订单状态 在支付记录表中添加记录 调用医院接口实现订单信息更新 二、具体开发2.1 引入依赖在service-order中引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.wxpay&lt;/groupId&gt; &lt;artifactId&gt;wxpay-sdk&lt;/artifactId&gt; &lt;version&gt;0.0.3&lt;/version&gt;&lt;/dependency&gt; 2.2 添加配置123456#关联微信公众号appidweixin.appid=wx74862e0dfcf69954#商户号weixin.partner=1558950191#商户keyweixin.partnerkey=T6m9iK73b0kn9g5v426MKfHQH7X8rKwb 2.3 引入工具类1ConstantPropertiesUtils 和 HttpClient 2.4 添加Controller2.5 实现具体业务三、退款流程 已预约，未付款：直接通知医院更新取消预约状态即可 已付款：先退款给用户，然后通知医院取消预约状态 四、具体开发4.1 配置证书将下载的证书放在service-order模块下的&#x2F;resources&#x2F;cert文件夹下 在配置文件中配置证书路径 12#退款证书weixin.cert=cert\\\\apiclient_cert.p12 4.2 添加获取支付记录的接口","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"微信登录","path":"/2022/07/22/微信登录/","content":"微信登录网站应用微型登录开发指南： 参考文档：https://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Wechat_Login.html 1. 返回微信登录参数 添加配置 1234wx.open.app_id=wxed9954c01bb89b47wx.open.app_secret=a7482517235173ddb4083788de60b90ewx.open.redirect_url=http://localhost:8160/api/ucenter/wx/callbackAR.baseUrl=http://localhost:3000 添加配置类 123456789101112131415161718192021222324252627282930@Componentpublic class ConstantWxPropertiesUtils implements InitializingBean &#123; @Value(&quot;$&#123;wx.open.app_id&#125;&quot;) private String appId; @Value(&quot;$&#123;wx.open.app_secret&#125;&quot;) private String appSecret; @Value(&quot;$&#123;wx.open.redirect_url&#125;&quot;) private String redirect_url; @Value(&quot;$&#123;AR.baseUrl&#125;&quot;) private String ARBaseUrl; public static String WX_OPEN_APP_ID; public static String WX_OPEN_APP_SECRET; public static String WX_OPEN_REDIRECT_URL; public static String AR_BASE_URL; @Override public void afterPropertiesSet() throws Exception &#123; WX_OPEN_APP_ID = appId; WX_OPEN_APP_SECRET = appSecret; WX_OPEN_REDIRECT_URL = redirect_url; AR_BASE_URL = ARBaseUrl; &#125;&#125; 添加接口 123456789101112131415161718192021/** * 返回生成二维码需要的参数 * @return */@GetMapping(&quot;getLoginParam&quot;)@ResponseBodypublic Result genQrConnect()&#123; try &#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;appid&quot;, ConstantWxPropertiesUtils.WX_OPEN_APP_ID); map.put(&quot;scope&quot;,&quot;snsapi_login&quot;); String wxOpenRedirectUrl = ConstantWxPropertiesUtils.WX_OPEN_REDIRECT_URL; wxOpenRedirectUrl = URLEncoder.encode(wxOpenRedirectUrl, &quot;utf-8&quot;); map.put(&quot;redirectUri&quot;,wxOpenRedirectUrl); map.put(&quot;state&quot;,System.currentTimeMillis()+&quot;&quot;); return Result.ok(map); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); return null; &#125;&#125; 前端封装api请求 123456789101112import request from &#x27;@/utils/request&#x27;const api_name = `/api/ucenter/wx`export default &#123; getLoginParam() &#123; return request(&#123; url: `$&#123;api_name&#125;/getLoginParam`, method: `get` &#125;) &#125;&#125; 引入微信js 12345//初始化微信jsconst script = document.createElement(&#x27;script&#x27;)script.type = &#x27;text/javascript&#x27;script.src = &#x27;https://res.wx.qq.com/connect/zh_CN/htmledition/js/wxLogin.js&#x27;document.body.appendChild(script) 添加组件 12345678910111213141516weixinLogin() &#123; this.dialogAtrr.showLoginType = &#x27;weixin&#x27; WechatApi.getLoginParam().then(response =&gt; &#123; var obj = new WxLogin(&#123; self_redirect:true, id: &#x27;weixinLogin&#x27;, // 需要显示的容器id appid: response.data.appid, // 公众号appid wx******* scope: response.data.scope, // 网页默认即可 redirect_uri: response.data.redirectUri, // 授权成功后回调的url state: response.data.state, // 可设置为简单的随机数加session用来校验 style: &#x27;black&#x27;, // 提供&quot;black&quot;、&quot;white&quot;可选。二维码的样式 href: &#x27;&#x27; // 外部css文件url，需要https &#125;) &#125;)&#125; 2. 处理微信回调 添加HttpClient工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256public class HttpClientUtils &#123; public static final int connTimeout=10000; public static final int readTimeout=10000; public static final String charset=&quot;UTF-8&quot;; private static HttpClient client = null; static &#123; PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(); cm.setMaxTotal(128); cm.setDefaultMaxPerRoute(128); client = HttpClients.custom().setConnectionManager(cm).build(); &#125; public static String postParameters(String url, String parameterStr) throws ConnectTimeoutException, SocketTimeoutException, Exception&#123; return post(url,parameterStr,&quot;application/x-www-form-urlencoded&quot;,charset,connTimeout,readTimeout); &#125; public static String postParameters(String url, String parameterStr,String charset, Integer connTimeout, Integer readTimeout) throws ConnectTimeoutException, SocketTimeoutException, Exception&#123; return post(url,parameterStr,&quot;application/x-www-form-urlencoded&quot;,charset,connTimeout,readTimeout); &#125; public static String postParameters(String url, Map&lt;String, String&gt; params) throws ConnectTimeoutException, SocketTimeoutException, Exception &#123; return postForm(url, params, null, connTimeout, readTimeout); &#125; public static String postParameters(String url, Map&lt;String, String&gt; params, Integer connTimeout,Integer readTimeout) throws ConnectTimeoutException, SocketTimeoutException, Exception &#123; return postForm(url, params, null, connTimeout, readTimeout); &#125; public static String get(String url) throws Exception &#123; return get(url, charset, null, null); &#125; public static String get(String url, String charset) throws Exception &#123; return get(url, charset, connTimeout, readTimeout); &#125; /** * 发送一个 Post 请求, 使用指定的字符集编码. * * @param url * @param body RequestBody * @param mimeType 例如 application/xml &quot;application/x-www-form-urlencoded&quot; a=1&amp;b=2&amp;c=3 * @param charset 编码 * @param connTimeout 建立链接超时时间,毫秒. * @param readTimeout 响应超时时间,毫秒. * @return ResponseBody, 使用指定的字符集编码. * @throws ConnectTimeoutException 建立链接超时异常 * @throws SocketTimeoutException 响应超时 * @throws Exception */ public static String post(String url, String body, String mimeType,String charset, Integer connTimeout, Integer readTimeout) throws ConnectTimeoutException, SocketTimeoutException, Exception &#123; HttpClient client = null; HttpPost post = new HttpPost(url); String result = &quot;&quot;; try &#123; if (StringUtils.isNotBlank(body)) &#123; HttpEntity entity = new StringEntity(body, ContentType.create(mimeType, charset)); post.setEntity(entity); &#125; // 设置参数 Builder customReqConf = RequestConfig.custom(); if (connTimeout != null) &#123; customReqConf.setConnectTimeout(connTimeout); &#125; if (readTimeout != null) &#123; customReqConf.setSocketTimeout(readTimeout); &#125; post.setConfig(customReqConf.build()); HttpResponse res; if (url.startsWith(&quot;https&quot;)) &#123; // 执行 Https 请求. client = createSSLInsecureClient(); res = client.execute(post); &#125; else &#123; // 执行 Http 请求. client = HttpClientUtils.client; res = client.execute(post); &#125; result = IOUtils.toString(res.getEntity().getContent(), charset); &#125; finally &#123; post.releaseConnection(); if (url.startsWith(&quot;https&quot;) &amp;&amp; client != null&amp;&amp; client instanceof CloseableHttpClient) &#123; ((CloseableHttpClient) client).close(); &#125; &#125; return result; &#125; /** * 提交form表单 * * @param url * @param params * @param connTimeout * @param readTimeout * @return * @throws ConnectTimeoutException * @throws SocketTimeoutException * @throws Exception */ public static String postForm(String url, Map&lt;String, String&gt; params, Map&lt;String, String&gt; headers, Integer connTimeout,Integer readTimeout) throws ConnectTimeoutException, SocketTimeoutException, Exception &#123; HttpClient client = null; HttpPost post = new HttpPost(url); try &#123; if (params != null &amp;&amp; !params.isEmpty()) &#123; List&lt;NameValuePair&gt; formParams = new ArrayList&lt;NameValuePair&gt;(); Set&lt;Entry&lt;String, String&gt;&gt; entrySet = params.entrySet(); for (Entry&lt;String, String&gt; entry : entrySet) &#123; formParams.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; UrlEncodedFormEntity entity = new UrlEncodedFormEntity(formParams, Consts.UTF_8); post.setEntity(entity); &#125; if (headers != null &amp;&amp; !headers.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : headers.entrySet()) &#123; post.addHeader(entry.getKey(), entry.getValue()); &#125; &#125; // 设置参数 Builder customReqConf = RequestConfig.custom(); if (connTimeout != null) &#123; customReqConf.setConnectTimeout(connTimeout); &#125; if (readTimeout != null) &#123; customReqConf.setSocketTimeout(readTimeout); &#125; post.setConfig(customReqConf.build()); HttpResponse res = null; if (url.startsWith(&quot;https&quot;)) &#123; // 执行 Https 请求. client = createSSLInsecureClient(); res = client.execute(post); &#125; else &#123; // 执行 Http 请求. client = HttpClientUtils.client; res = client.execute(post); &#125; return IOUtils.toString(res.getEntity().getContent(), &quot;UTF-8&quot;); &#125; finally &#123; post.releaseConnection(); if (url.startsWith(&quot;https&quot;) &amp;&amp; client != null &amp;&amp; client instanceof CloseableHttpClient) &#123; ((CloseableHttpClient) client).close(); &#125; &#125; &#125; /** * 发送一个 GET 请求 */ public static String get(String url, String charset, Integer connTimeout,Integer readTimeout) throws ConnectTimeoutException,SocketTimeoutException, Exception &#123; HttpClient client = null; HttpGet get = new HttpGet(url); String result = &quot;&quot;; try &#123; // 设置参数 Builder customReqConf = RequestConfig.custom(); if (connTimeout != null) &#123; customReqConf.setConnectTimeout(connTimeout); &#125; if (readTimeout != null) &#123; customReqConf.setSocketTimeout(readTimeout); &#125; get.setConfig(customReqConf.build()); HttpResponse res = null; if (url.startsWith(&quot;https&quot;)) &#123; // 执行 Https 请求. client = createSSLInsecureClient(); res = client.execute(get); &#125; else &#123; // 执行 Http 请求. client = HttpClientUtils.client; res = client.execute(get); &#125; result = IOUtils.toString(res.getEntity().getContent(), charset); &#125; finally &#123; get.releaseConnection(); if (url.startsWith(&quot;https&quot;) &amp;&amp; client != null &amp;&amp; client instanceof CloseableHttpClient) &#123; ((CloseableHttpClient) client).close(); &#125; &#125; return result; &#125; /** * 从 response 里获取 charset */ @SuppressWarnings(&quot;unused&quot;) private static String getCharsetFromResponse(HttpResponse ressponse) &#123; // Content-Type:text/html; charset=GBK if (ressponse.getEntity() != null &amp;&amp; ressponse.getEntity().getContentType() != null &amp;&amp; ressponse.getEntity().getContentType().getValue() != null) &#123; String contentType = ressponse.getEntity().getContentType().getValue(); if (contentType.contains(&quot;charset=&quot;)) &#123; return contentType.substring(contentType.indexOf(&quot;charset=&quot;) + 8); &#125; &#125; return null; &#125; /** * 创建 SSL连接 * @return * @throws GeneralSecurityException */ private static CloseableHttpClient createSSLInsecureClient() throws GeneralSecurityException &#123; try &#123; SSLContext sslContext = new SSLContextBuilder().loadTrustMaterial(null, new TrustStrategy() &#123; public boolean isTrusted(X509Certificate[] chain,String authType) throws CertificateException &#123; return true; &#125; &#125;).build(); SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(sslContext, new X509HostnameVerifier() &#123; @Override public boolean verify(String arg0, SSLSession arg1) &#123; return true; &#125; @Override public void verify(String host, SSLSocket ssl) throws IOException &#123; &#125; @Override public void verify(String host, X509Certificate cert) throws SSLException &#123; &#125; @Override public void verify(String host, String[] cns, String[] subjectAlts) throws SSLException &#123; &#125; &#125;); return HttpClients.custom().setSSLSocketFactory(sslsf).build(); &#125; catch (GeneralSecurityException e) &#123; throw e; &#125; &#125;&#125; 在controller中添加回调接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081//微信扫码后回调方法@GetMapping(&quot;callback&quot;)public String callBack(String code, String state)&#123; if (StringUtils.isEmpty(state) || StringUtils.isEmpty(code)) &#123; log.error(&quot;非法回调请求&quot;); throw new AppointmentRegisterException(ResultCodeEnum.ILLEGAL_CALLBACK_REQUEST_ERROR); &#125; //使用code和appid以及appscrect换取access_token StringBuffer baseAccessTokenUrl = new StringBuffer() .append(&quot;https://api.weixin.qq.com/sns/oauth2/access_token&quot;) .append(&quot;?appid=%s&quot;) .append(&quot;&amp;secret=%s&quot;) .append(&quot;&amp;code=%s&quot;) .append(&quot;&amp;grant_type=authorization_code&quot;); String accessTokenUrl = String.format(baseAccessTokenUrl.toString(), ConstantWxPropertiesUtils.WX_OPEN_APP_ID, ConstantWxPropertiesUtils.WX_OPEN_APP_SECRET, code); //使用httpClient请求这个地址 try &#123; String accessTokenInfo = HttpClientUtils.get(accessTokenUrl); //从返回的json数据中 拿到access_token 和 openid JSONObject jsonObject = JSONObject.parseObject(accessTokenInfo); String access_token = jsonObject.getString(&quot;access_token&quot;); String openid = jsonObject.getString(&quot;openid&quot;); //根据openid判断数据库中是否存在扫码人的信息 UserInfo userInfo = userInfoService.selectWxInfoOpenId(openid); if(userInfo == null)&#123; //通过两个值获取扫码人的信息 String baseUserInfoUrl = &quot;https://api.weixin.qq.com/sns/userinfo&quot; + &quot;?access_token=%s&quot; + &quot;&amp;openid=%s&quot;; String userInfoUrl = String.format(baseUserInfoUrl, access_token, openid); String resultInfo = HttpClientUtils.get(userInfoUrl); JSONObject resultUserInfoJson = JSONObject.parseObject(resultInfo); //解析用户昵称和头像 String nickname = resultUserInfoJson.getString(&quot;nickname&quot;); String headimgurl = resultUserInfoJson.getString(&quot;headimgurl&quot;); //获取扫码人的信息添加到数据库中 userInfo = new UserInfo(); userInfo.setNickName(nickname); userInfo.setOpenid(openid); userInfo.setStatus(1); userInfoService.save(userInfo); &#125; //返回name和token字符串 Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String name = userInfo.getName(); if(StringUtils.isEmpty(name)) &#123; name = userInfo.getNickName(); &#125; if(StringUtils.isEmpty(name)) &#123; name = userInfo.getPhone(); &#125; map.put(&quot;name&quot;, name); //判断userInfo中是否有手机号，如果为空，则返回openid //如果不为空，则返回openid值是空字符串 //前端判断：如果openid不为空，绑定手机号，如果openid为空，则不需要绑定手机号 if(StringUtils.isEmpty(userInfo.getPhone())) &#123; map.put(&quot;openid&quot;, userInfo.getOpenid()); &#125; else &#123; map.put(&quot;openid&quot;, &quot;&quot;); &#125; //使用JWT生成token字符串 String token = JwtHelper.createToken(userInfo.getId(), name); map.put(&quot;token&quot;, token); //跳转到前端页面中 return &quot;redirect:&quot; + ConstantWxPropertiesUtils.AR_BASE_URL + &quot;/weixin/callback?token=&quot;+map.get(&quot;token&quot;)+&quot;&amp;openid=&quot;+map.get(&quot;openid&quot;)+&quot;&amp;name=&quot;+ URLEncoder.encode(map.get(&quot;name&quot;),&quot;utf-8&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125;&#125; 根据openid查询用户是否注册，编写service 12345678//根据openid查询@Overridepublic UserInfo selectWxInfoOpenId(String openid) &#123; QueryWrapper&lt;UserInfo&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;openid&quot;,openid); UserInfo userInfo = baseMapper.selectOne(queryWrapper); return userInfo;&#125; 添加回调页面 根据返回路径&#x2F;weixin&#x2F;callback 12345678910111213141516171819202122&lt;template&gt; &lt;!-- header --&gt; &lt;div&gt; &lt;/div&gt; &lt;!-- footer --&gt;&lt;/template&gt;&lt;script&gt;export default &#123; layout: &quot;empty&quot;, data() &#123; return &#123; &#125; &#125;, mounted() &#123; let token = this.$route.query.token let name = this.$route.query.name let openid = this.$route.query.openid // 调用父vue方法 window.parent[&#x27;loginCallback&#x27;](name, token, openid) &#125;&#125;&lt;/script&gt; 在myheader.vue中的mounted中添加方法 123456// 微信登录回调处理let self = this;window[&quot;loginCallback&quot;] = (name,token, openid) =&gt; &#123; debugger self.loginCallback(name, token, openid);&#125; 12345678910loginCallback(name, token, openid) &#123; // 打开手机登录层，绑定手机号，改逻辑与手机登录一致 if(openid != null) &#123; this.userInfo.openid = openid this.showLogin() &#125; else &#123; this.setCookies(name, token) &#125;&#125; 服务器绑定手机号 我们根据openid判断需不需要绑定手机号，修改UserInfoServiceImpl方法 12345678910111213141516171819202122232425262728//绑定手机号码UserInfo userInfo = null;if(!StringUtils.isEmpty(loginVo.getOpenid())) &#123; userInfo = this.selectWxInfoOpenId(loginVo.getOpenid()); if(null != userInfo) &#123; userInfo.setPhone(loginVo.getPhone()); this.updateById(userInfo); &#125; else &#123; throw new AppointmentRegisterException(ResultCodeEnum.DATA_ERROR); &#125;&#125;//如果userInfo为空，进行正常手机登录if (userInfo == null)&#123; //4 判断是否为第一次登录：根据手机号查询数据库，如果不存在数据，那么就是第一次登录 QueryWrapper&lt;UserInfo&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(&quot;phone&quot;,phone); userInfo = baseMapper.selectOne(wrapper); if (null == userInfo)&#123; //第一次登录 //添加信息到数据库中 userInfo = new UserInfo(); userInfo.setName(&quot;&quot;); userInfo.setPhone(phone); userInfo.setStatus(1); baseMapper.insert(userInfo); &#125;&#125; 最后就可以实现微信登录功能","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"阿里云短信服务","path":"/2022/07/20/阿里云短信服务/","content":"阿里云短信服务短信服务（Short Message Service）是广大企业客户快速触达手机用户所优选使用的通信能力。调用API或用群发助手，即可发送验证码、通知类和营销类短信；国内验证短信秒级触达，到达率最高可达99%；国际&#x2F;港澳台短信覆盖200多个国家和地区，安全稳定，广受出海企业选用。 进入阿里云开通短信服务 现在阿里云已经不支持个人申请未上线的业务，可以去云市场买第三方的短信服务 直接拿来用就可以 引入依赖 123456789101112&lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 123456789101112131415161718192021# 服务端口server.port=8204# 服务名spring.application.name=service-msm#返回json的全局时间格式spring.jackson.date-format=yyyy-MM-dd HH:mm:ssspring.jackson.time-zone=GMT+8spring.redis.host=192.168.134.134spring.redis.port=6379spring.redis.database= 0spring.redis.timeout=1800000spring.redis.lettuce.pool.max-active=20spring.redis.lettuce.pool.max-wait=-1#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-idle=5spring.redis.lettuce.pool.min-idle=0# nacos服务地址spring.cloud.nacos.discovery.server-addr=localhost:8848 添加启动类 12345678@SpringBootApplication(exclude = DataSourceAutoConfiguration.class) //取消数据源自动配置@EnableDiscoveryClient@ComponentScan(basePackages = &#123;&quot;com.CPG&quot;&#125;)public class ServiceMsmApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceMsmApplication.class,args); &#125;&#125; 创建HttpUtils工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283public class HttpUtils &#123; /** * get * * @param host * @param path * @param method * @param headers * @param querys * @return * @throws Exception */ public static HttpResponse doGet(String host, String path, String method, Map &lt;String, String&gt; headers, Map&lt;String, String&gt; querys) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpGet request = new HttpGet(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; return httpClient.execute(request); &#125; /** * post form * * @param host * @param path * @param method * @param headers * @param querys * @param bodys * @return * @throws Exception */ public static HttpResponse doPost(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys, Map &lt;String, String&gt; bodys) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpPost request = new HttpPost(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; if (bodys != null) &#123; List &lt;NameValuePair&gt; nameValuePairList = new ArrayList &lt;NameValuePair&gt;(); for (String key : bodys.keySet()) &#123; nameValuePairList.add(new BasicNameValuePair(key, bodys.get(key))); &#125; UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(nameValuePairList, &quot;utf-8&quot;); formEntity.setContentType(&quot;application/x-www-form-urlencoded; charset=UTF-8&quot;); request.setEntity(formEntity); &#125; return httpClient.execute(request); &#125; /** * Post String * * @param host * @param path * @param method * @param headers * @param querys * @param body * @return * @throws Exception */ public static HttpResponse doPost(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys, String body) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpPost request = new HttpPost(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; if (StringUtils.isNotBlank(body)) &#123; request.setEntity(new StringEntity(body, &quot;utf-8&quot;)); &#125; return httpClient.execute(request); &#125; /** * Post stream * * @param host * @param path * @param method * @param headers * @param querys * @param body * @return * @throws Exception */ public static HttpResponse doPost(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys, byte[] body) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpPost request = new HttpPost(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; if (body != null) &#123; request.setEntity(new ByteArrayEntity(body)); &#125; return httpClient.execute(request); &#125; /** * Put String * * @param host * @param path * @param method * @param headers * @param querys * @param body * @return * @throws Exception */ public static HttpResponse doPut(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys, String body) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpPut request = new HttpPut(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; if (StringUtils.isNotBlank(body)) &#123; request.setEntity(new StringEntity(body, &quot;utf-8&quot;)); &#125; return httpClient.execute(request); &#125; /** * Put stream * * @param host * @param path * @param method * @param headers * @param querys * @param body * @return * @throws Exception */ public static HttpResponse doPut(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys, byte[] body) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpPut request = new HttpPut(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; if (body != null) &#123; request.setEntity(new ByteArrayEntity(body)); &#125; return httpClient.execute(request); &#125; /** * Delete * * @param host * @param path * @param method * @param headers * @param querys * @return * @throws Exception */ public static HttpResponse doDelete(String host, String path, String method, Map &lt;String, String&gt; headers, Map &lt;String, String&gt; querys) throws Exception &#123; HttpClient httpClient = wrapClient(host); HttpDelete request = new HttpDelete(buildUrl(host, path, querys)); for (Map.Entry &lt;String, String&gt; e : headers.entrySet()) &#123; request.addHeader(e.getKey(), e.getValue()); &#125; return httpClient.execute(request); &#125; private static String buildUrl(String host, String path, Map &lt;String, String&gt; querys) throws UnsupportedEncodingException &#123; StringBuilder sbUrl = new StringBuilder(); sbUrl.append(host); if (!StringUtils.isBlank(path)) &#123; sbUrl.append(path); &#125; if (null != querys) &#123; StringBuilder sbQuery = new StringBuilder(); for (Map.Entry &lt;String, String&gt; query : querys.entrySet()) &#123; if (0 &lt; sbQuery.length()) &#123; sbQuery.append(&quot;&amp;&quot;); &#125; if (StringUtils.isBlank(query.getKey()) &amp;&amp; !StringUtils.isBlank(query.getValue())) &#123; sbQuery.append(query.getValue()); &#125; if (!StringUtils.isBlank(query.getKey())) &#123; sbQuery.append(query.getKey()); if (!StringUtils.isBlank(query.getValue())) &#123; sbQuery.append(&quot;=&quot;); sbQuery.append(URLEncoder.encode(query.getValue(), &quot;utf-8&quot;)); &#125; &#125; &#125; if (0 &lt; sbQuery.length()) &#123; sbUrl.append(&quot;?&quot;).append(sbQuery); &#125; &#125; return sbUrl.toString(); &#125; private static HttpClient wrapClient(String host) &#123; HttpClient httpClient = new DefaultHttpClient(); if (host.startsWith(&quot;https://&quot;)) &#123; sslClient(httpClient); &#125; return httpClient; &#125; private static void sslClient(HttpClient httpClient) &#123; try &#123; SSLContext ctx = SSLContext.getInstance(&quot;TLS&quot;); X509TrustManager tm = new X509TrustManager() &#123; public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125; public void checkClientTrusted(X509Certificate[] xcs, String str) &#123; &#125; public void checkServerTrusted(X509Certificate[] xcs, String str) &#123; &#125; &#125;; ctx.init(null, new TrustManager[]&#123;tm&#125;, null); SSLSocketFactory ssf = new SSLSocketFactory(ctx); ssf.setHostnameVerifier(SSLSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER); ClientConnectionManager ccm = httpClient.getConnectionManager(); SchemeRegistry registry = ccm.getSchemeRegistry(); registry.register(new Scheme(&quot;https&quot;, 443, ssf)); &#125; catch (KeyManagementException ex) &#123; throw new RuntimeException(ex); &#125; catch (NoSuchAlgorithmException ex) &#123; throw new RuntimeException(ex); &#125; &#125;&#125; 创建MsmUtils工具类 12345678910111213141516171819202122232425262728293031public class MsmUtils &#123; /** * 发送验证码 * @param mobile 手机号 * @param code 发送的验证码 */ public static void sendMessage(String mobile,String code)&#123; String host = &quot;https://dfsns.market.alicloudapi.com&quot;; String path = &quot;/data/send_sms&quot;; String method = &quot;POST&quot;; String appcode = &quot;03e878fdb9054763afe0143f50b3526a&quot;; Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); //最后在header中的格式(中间是英文空格)为Authorization:APPCODE 83359fd73fe94948385f570e3c139105 headers.put(&quot;Authorization&quot;, &quot;APPCODE &quot; + appcode); //根据API的要求，定义相对应的Content-Type headers.put(&quot;Content-Type&quot;, &quot;application/x-www-form-urlencoded; charset=UTF-8&quot;); Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); Map&lt;String, String&gt; bodys = new HashMap&lt;String, String&gt;(); bodys.put(&quot;content&quot;, &quot;code:&quot;+ code +&quot;,expire_at:2&quot;); bodys.put(&quot;phone_number&quot;, mobile); bodys.put(&quot;template_id&quot;, &quot;TPL_0001&quot;); try &#123; HttpResponse response = HttpUtils.doPost(host, path, method, headers, querys, bodys); System.out.println(response.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 创建RandomUtils工具类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class RandomUtils &#123; private static final Random random = new Random(); private static final DecimalFormat fourdf = new DecimalFormat(&quot;0000&quot;); private static final DecimalFormat sixdf = new DecimalFormat(&quot;000000&quot;); //生成四位验证码 public static String getFourBitRandom() &#123; return fourdf.format(random.nextInt(10000)); &#125; //生成六位验证码 public static String getSixBitRandom() &#123; return sixdf.format(random.nextInt(1000000)); &#125; /** * 给定数组，抽取n个数据 * @param list * @param n * @return */ public static ArrayList getRandom(List list, int n) &#123; Random random = new Random(); HashMap&lt;Object, Object&gt; hashMap = new HashMap&lt;Object, Object&gt;(); // 生成随机数字并存入HashMap for (int i = 0; i &lt; list.size(); i++) &#123; int number = random.nextInt(100) + 1; hashMap.put(number, i); &#125; // 从HashMap导入数组 Object[] robjs = hashMap.values().toArray(); ArrayList r = new ArrayList(); // 遍历数组并打印数据 for (int i = 0; i &lt; n; i++) &#123; r.add(list.get((int) robjs[i])); System.out.print(list.get((int) robjs[i]) + &quot;\\t&quot;); &#125; System.out.print(&quot; &quot;); return r; &#125;&#125; controller 12345678910111213141516171819202122//发送手机验证码@GetMapping(&quot;send/&#123;phone&#125;&quot;)public Result sendCode(@PathVariable String phone)&#123; //从Redis中获取验证码，如果可以获取到，返回ok //key：手机号 value：验证码 String code = redisTemplate.opsForValue().get(phone); if (!StringUtils.isEmpty(code))&#123; return Result.ok(); &#125; //如果获取不到，生成验证码，通过整合短信服务进行发送 code = RandomUtils.getSixBitRandom(); //整合阿里云短信服务进行发送 boolean isSend = msmService.send(phone,code); //生成的验证码放到redis中，设置有效时间 if (isSend)&#123; redisTemplate.opsForValue().set(phone,code,2, TimeUnit.MINUTES); return Result.ok(); &#125;else &#123; return Result.fail().message(&quot;发送短信失败！&quot;); &#125;&#125; service 1234567891011//发送手机验证码@Overridepublic boolean send(String phone, String code) &#123; //判断手机号是否为空 if (StringUtils.isEmpty(phone))&#123; return false; &#125; //整合阿里云短信服务，设置相关参数 MsmUtils.sendMessage(phone,code); return true;&#125;","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"阿里云OSS","path":"/2022/07/19/阿里云OSS/","content":"阿里云OSS用户认证需要上传证件图片、首页轮播也需要上传图片，因此我们要做文件服务，阿里云oss是一个很好的分布式文件服务系统，所以只需要集成阿里云oss即可 1. 开通”对象存储OSS”服务1.1 创建Bucket类似于包 选择：低频访问存储、公共读、不开通 1.2 上传默认头像可以创建专门的文件夹，用来存放用户头像 2. 使用sdk文档参考文档：https://help.aliyun.com/document_detail/32011.html 3. 整合3.1 搭建service-oss模块 引入依赖 1234567891011&lt;!-- 阿里云oss依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 日期工具依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置文件 12345678910111213141516171819202122232425262728# 服务端口server.port=8205# 服务名spring.application.name=service-oss#返回json的全局时间格式spring.jackson.date-format=yyyy-MM-dd HH:mm:ssspring.jackson.time-zone=GMT+8spring.redis.host=192.168.134.134spring.redis.port=6379spring.redis.database= 0spring.redis.timeout=1800000spring.redis.lettuce.pool.max-active=20spring.redis.lettuce.pool.max-wait=-1#最大阻塞等待时间(负数表示没限制)spring.redis.lettuce.pool.max-idle=5spring.redis.lettuce.pool.min-idle=0# nacos服务地址spring.cloud.nacos.discovery.server-addr=localhost:8848aliyun.oss.endpoint=oss-cn-chengdu.aliyuncs.comaliyun.oss.accessKeyId=LTAI5tFx8hiRkEwAVhiLCE9Faliyun.oss.secret=719P8hAbQJL20VnQkbmUrLOey4i8NCaliyun.oss.bucket=appointment-register-cpgspring.servlet.multipart.max-file-size=50MB 创建启动类 12345678@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@ComponentScan(basePackages = &#123;&quot;com.CPG&quot;&#125;)public class ServiceOssApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceOssApplication.class,args); &#125;&#125; 在网关中配置 123456#设置路由idspring.cloud.gateway.routes[5].id=service-oss#设置路由的urispring.cloud.gateway.routes[5].uri=lb://service-oss#设置路由断言,代理servicerId为auth-service的/auth/路径spring.cloud.gateway.routes[5].predicates= Path=/*/oss/** 3.2 测试SDK1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) throws Exception &#123; // Endpoint以华东1（杭州）为例，其它Region请按实际情况填写。 String endpoint = &quot;https://oss-cn-chengdu.aliyuncs.com&quot;; // 阿里云账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM用户进行API访问或日常运维，请登录RAM控制台创建RAM用户。 String accessKeyId = &quot;LTAI5tFx8hiRkEwAVhiLCE9F&quot;; String accessKeySecret = &quot;719P8hAbQJL20VnQkbmUrLOey4i8NC&quot;; // 填写Bucket名称，例如examplebucket。 String bucketName = &quot;appointment-register-cpg&quot;; // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); try &#123; // 创建存储空间。 ossClient.createBucket(bucketName); &#125; catch (OSSException oe) &#123; System.out.println(&quot;Caught an OSSException, which means your request made it to OSS, &quot; + &quot;but was rejected with an error response for some reason.&quot;); System.out.println(&quot;Error Message:&quot; + oe.getErrorMessage()); System.out.println(&quot;Error Code:&quot; + oe.getErrorCode()); System.out.println(&quot;Request ID:&quot; + oe.getRequestId()); System.out.println(&quot;Host ID:&quot; + oe.getHostId()); &#125; catch (ClientException ce) &#123; System.out.println(&quot;Caught an ClientException, which means the client encountered &quot; + &quot;a serious internal problem while trying to communicate with OSS, &quot; + &quot;such as not being able to access the network.&quot;); System.out.println(&quot;Error Message:&quot; + ce.getMessage()); &#125; finally &#123; if (ossClient != null) &#123; //关闭ossClient ossClient.shutdown(); &#125; &#125;&#125; 3.2 编写接口 创建ConstantOssPropertiesUtils工具类 1234567891011121314151617181920212223242526272829@Componentpublic class ConstantOssPropertiesUtils implements InitializingBean &#123; @Value(&quot;$&#123;aliyun.oss.endpoint&#125;&quot;) private String endpoint; @Value(&quot;$&#123;aliyun.oss.accessKeyId&#125;&quot;) private String accessKeyId; @Value(&quot;$&#123;aliyun.oss.secret&#125;&quot;) private String secret; @Value(&quot;$&#123;aliyun.oss.bucket&#125;&quot;) private String bucket; public static String END_POINT; public static String ACCESS_KEY_ID; public static String SECRET; public static String BUCKET; @Override public void afterPropertiesSet() throws Exception &#123; END_POINT = endpoint; ACCESS_KEY_ID = accessKeyId; SECRET = secret; BUCKET = bucket; &#125;&#125; 创建接口实现类 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Servicepublic class FileServiceImpl implements FileService &#123; @Override public String upload(MultipartFile file) &#123; // Endpoint以华东1（杭州）为例，其它Region请按实际情况填写。 String endpoint = ConstantOssPropertiesUtils.END_POINT; // 阿里云账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM用户进行API访问或日常运维，请登录RAM控制台创建RAM用户。 String accessKeyId = ConstantOssPropertiesUtils.ACCESS_KEY_ID; String accessKeySecret = ConstantOssPropertiesUtils.SECRET; // 填写Bucket名称，例如examplebucket。 String bucketName = ConstantOssPropertiesUtils.BUCKET; // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); InputStream inputStream = null; try &#123; inputStream = file.getInputStream(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; // 填写Object完整路径，完整路径中不能包含Bucket名称，例如exampledir/exampleobject.txt。 String objectName = file.getOriginalFilename(); //生成随机唯一值，使用uuid，添加到文件名称里 String uuid = UUID.randomUUID().toString().replaceAll(&quot;-&quot;,&quot;&quot;); objectName = uuid+objectName; //按照当前日期创建文件夹，并将文件上传到创建的文件夹中 String timeUrl = new DateTime().toString(&quot;yyyy/MM/dd&quot;); objectName = timeUrl+&quot;/&quot;+objectName; // 创建PutObject请求,调用方法实现上传。 ossClient.putObject(bucketName, objectName, inputStream); //关闭OSSClient ossClient.shutdown(); //上传后文件路径 String url = &quot;https://&quot;+bucketName+&quot;.&quot;+endpoint+&quot;/&quot;+objectName; return url; &#125;&#125; 创建controller接口 123456789101112131415@RestController@RequestMapping(&quot;/api/oss/file&quot;)public class FileApiController &#123; @Autowired private FileService fileService; //上传文件到阿里云oss @PostMapping(&quot;fileUpload&quot;) public Result fileUpload(MultipartFile file)&#123; //获取上传的文件 String url = fileService.upload(file); return Result.ok(url); &#125;&#125;","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"JWT技术","path":"/2022/07/13/JWT技术/","content":"JWT技术1. JWT介绍 JWT工具： JWT（Json Web Token）是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。 JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。比如用在用户登录上 JWT最重要的作用就是对 token信息的防伪作用。 JWT的原理： 一个JWT由三个部分组成：公共部分、私有部分、签名部分。最后由这三者组合进行base64编码得到JWT。 公共部分 主要是该JWT的相关配置参数，比如签名的加密算法、格式类型、过期时间等等。 私有部分 用户自定义的内容，根据实际需要真正要封装的信息。 userInfo&#123;用户的Id，用户的昵称nickName&#125; 签名部分 SaltiP: 当前服务器的Ip地址!&#123;linux 中配置代理服务器的ip&#125; 主要用户对JWT生成字符串的时候，进行加密{盐值} 最终组成 key+salt+userInfo -&gt; token! base64编码，并不是加密，只是把明文信息变成了不可见的字符串。但是其实只要用一些工具就可以把base64编码解成明文，所以不要在JWT中放入涉及私密的信息。 2. JWT整合 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt;&lt;/dependency&gt; 添加工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class JwtHelper &#123; //token过期时间，单位ms private static long tokenExpiration = 24*60*60*1000; //签名秘钥 private static String tokenSignKey = &quot;123456&quot;; /** * 根据参数生成token * @param userId * @param userName * @return */ public static String createToken(Long userId, String userName) &#123; String token = Jwts.builder() .setSubject(&quot;AR-USER&quot;) .setExpiration(new Date(System.currentTimeMillis() + tokenExpiration)) .claim(&quot;userId&quot;, userId) .claim(&quot;userName&quot;, userName) .signWith(SignatureAlgorithm.HS512, tokenSignKey) .compressWith(CompressionCodecs.GZIP) .compact(); return token; &#125; /** * 根据token字符串得到用户id * @param token * @return */ public static Long getUserId(String token) &#123; if(StringUtils.isEmpty(token)) return null; Jws&lt;Claims&gt; claimsJws = Jwts.parser().setSigningKey(tokenSignKey).parseClaimsJws(token); Claims claims = claimsJws.getBody(); Integer userId = (Integer)claims.get(&quot;userId&quot;); return userId.longValue(); &#125; /** * 根据token字符串得到用户名 * @param token * @return */ public static String getUserName(String token) &#123; if(StringUtils.isEmpty(token)) return &quot;&quot;; Jws&lt;Claims&gt; claimsJws = Jwts.parser().setSigningKey(tokenSignKey).parseClaimsJws(token); Claims claims = claimsJws.getBody(); return (String)claims.get(&quot;userName&quot;); &#125; public static void main(String[] args) &#123; String token = JwtHelper.createToken(1L, &quot;55&quot;); System.out.println(token); System.out.println(JwtHelper.getUserId(token)); System.out.println(JwtHelper.getUserName(token)); &#125;&#125; 3. 在service中使用123//使用Jwt生成tokenString token = JwtHelper.createToken(userInfo.getId(), name);map.put(&quot;token&quot;,token);","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"MyBatis-Plus 乐观锁","path":"/2022/07/13/Mybatis-Plus 乐观锁/","content":"Mybatis-Plus 乐观锁主要适用场景：当要更新一条记录的时候，希望这条记录没有被别人更新，也就是说实现线程安全的数据更新 乐观锁实现方式： 取出数据时，获取当前version 更新时，带上version的值 执行更新时，set version = newVersion where version = oldVersion 如果version不对，那么就更新失败 乐观锁实现流程1. 修改实体类添加@Version注解 2. 创建配置文件在config包中，创建MybatisPlusConfig.java 此时可以删除主类中的@MapperScan扫描注解，直接放在MybatisPlusConfig中就行了 3. 注册乐观锁插件在MybatisPlusConfig中注册Bean 1234@Beanpublic OptimisticLockInterceptor optimisticLockInterceptor()&#123; return new OptimisticLockInterceptor();&#125;","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"MyBatis-Plus","path":"/2022/07/13/MyBatisPlus/","content":"MyBatisPlus1. 基本CRUD1.1 BaseMapperMyBatis-Plus中的基本CRUD在内置的BaseMapper中都已得到了实现，我们可以直接使用，接口如 下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132/** * Mapper 继承该接口后，无需编写 mapper.xml 文件，即可获得CRUD功能 * &lt;p&gt;这个 Mapper 支持 id 泛型&lt;/p&gt; * * @author hubin * @since 2016-01-23 */public interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt; &#123; /** * 插入一条记录 * * @param entity 实体对象 */ int insert(T entity); /** * 根据 ID 删除 * * @param id 主键ID */ int deleteById(Serializable id); /** * 根据 columnMap 条件，删除记录 * * @param columnMap 表字段 map 对象 */ int deleteByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap); /** * 根据 entity 条件，删除记录 * * @param wrapper 实体对象封装操作类（可以为 null） */ int delete(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; wrapper); /** * 删除（根据ID 批量删除） * * @param idList 主键ID列表(不能为 null 以及 empty) */ int deleteBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList); /** * 根据 ID 修改 * * @param entity 实体对象 */ int updateById(@Param(Constants.ENTITY) T entity); /** * 根据 whereEntity 条件，更新记录 * * @param entity 实体对象 (set 条件值,可以为 null) * @param updateWrapper 实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句） */ int update(@Param(Constants.ENTITY) T entity, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; updateWrapper); /** * 根据 ID 查询 * * @param id 主键ID */ T selectById(Serializable id); /** * 查询（根据ID 批量查询） * * @param idList 主键ID列表(不能为 null 以及 empty) */ List&lt;T&gt; selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList); /** * 查询（根据 columnMap 条件） * * @param columnMap 表字段 map 对象 */ List&lt;T&gt; selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap); /** * 根据 entity 条件，查询一条记录 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ T selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 Wrapper 条件，查询总记录数 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ Integer selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 entity 条件，查询全部记录 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List&lt;T&gt; selectList(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录 * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List&lt;Map&lt;String, Object&gt;&gt; selectMaps(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录 * &lt;p&gt;注意： 只返回第一个字段的值&lt;/p&gt; * * @param queryWrapper 实体对象封装操作类（可以为 null） */ List&lt;Object&gt; selectObjs(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 entity 条件，查询全部记录（并翻页） * * @param page 分页查询条件（可以为 RowBounds.DEFAULT） * @param queryWrapper 实体对象封装操作类（可以为 null） */ &lt;E extends IPage&lt;T&gt;&gt; E selectPage(E page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** * 根据 Wrapper 条件，查询全部记录（并翻页） * * @param page 分页查询条件 * @param queryWrapper 实体对象封装操作类 */ &lt;E extends IPage&lt;Map&lt;String, Object&gt;&gt;&gt; E selectMapsPage(E page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);&#125; 1.2 插入123456789@Testpublic void testInsert()&#123; User user = new User(null, &quot;张三&quot;, 23, &quot;zhangsan@atguigu.com&quot;); //INSERT INTO user ( id, name, age, email ) VALUES ( ?, ?, ?, ? ) int result = userMapper.insert(user); System.out.println(&quot;受影响行数：&quot;+result); //1475754982694199298 System.out.println(&quot;id自动获取：&quot;+user.getId());&#125; 最终执行的结果，所获取的id为1475754982694199298 这是因为MyBatis-Plus在实现插入数据时，会默认基于雪花算法的策略生成id 1.3 删除 通过id删除记录 1234567@Testpublic void testDeleteById()&#123; //通过id删除用户信息 //DELETE FROM user WHERE id=? int result = userMapper.deleteById(1475754982694199298L); System.out.println(&quot;受影响行数：&quot;+result);&#125; 通过id批量删除记录 12345678@Testpublic void testDeleteBatchIds()&#123; //通过多个id批量删除 //DELETE FROM user WHERE id IN ( ? , ? , ? ) List&lt;Long&gt; idList = Arrays.asList(1L, 2L, 3L); int result = userMapper.deleteBatchIds(idList); System.out.println(&quot;受影响行数：&quot;+result);&#125; 通过map条件删除记录 12345678910@Testpublic void testDeleteByMap()&#123; //根据map集合中所设置的条件删除记录 //DELETE FROM user WHERE name = ? AND age = ? Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;age&quot;, 23); map.put(&quot;name&quot;, &quot;张三&quot;); int result = userMapper.deleteByMap(map); System.out.println(&quot;受影响行数：&quot;+result);&#125; 1.4 修改1234567@Testpublic void testUpdateById()&#123; User user = new User(4L, &quot;admin&quot;, 22, null); //UPDATE user SET name=?, age=? WHERE id=? int result = userMapper.updateById(user); System.out.println(&quot;受影响行数：&quot;+result);&#125; 1.5 查询 根据id查询用户信息 1234567@Testpublic void testSelectById()&#123; //根据id查询用户信息 //SELECT id,name,age,email FROM user WHERE id=? User user = userMapper.selectById(4L); System.out.println(user);&#125; 根据多个id查询多个用户信息 12345678@Testpublic void testSelectBatchIds()&#123; //根据多个id查询多个用户信息 //SELECT id,name,age,email FROM user WHERE id IN ( ? , ? ) List&lt;Long&gt; idList = Arrays.asList(4L, 5L); List&lt;User&gt; list = userMapper.selectBatchIds(idList); list.forEach(System.out::println);&#125; 通过map条件查询用户信息 12345678910@Testpublic void testSelectByMap()&#123; //通过map条件查询用户信息 //SELECT id,name,age,email FROM user WHERE name = ? AND age = ? Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;age&quot;, 22); map.put(&quot;name&quot;, &quot;admin&quot;); List&lt;User&gt; list = userMapper.selectByMap(map); list.forEach(System.out::println);&#125; 查询所有数据 1234567@Testpublic void testSelectList()&#123; //查询所有用户信息 //SELECT id,name,age,email FROM user List&lt;User&gt; list = userMapper.selectList(null); list.forEach(System.out::println);&#125; 通过观察BaseMapper中的方法，大多方法中都有Wrapper类型的形参，此为条件构造器，可针 对于SQL语句设置不同的条件，若没有条件，则可以为该形参赋值null，即查询（删除&#x2F;修改）所有数据 1.6 通用Service说明： 通用的Service CRUD封装IService接口，进一步封装CRUD采用get 查询单行``remove 删除``list 查询集合``page 分页前缀命名方式区分Mapper层以避免混淆。 泛型T为任意实体对象。 建议如果存在自定义通用Service方法的可能，请创建自己的IBaseService继承MybatisPlus所提供的基类 。 IService MyBatis-Plus中有一个接口 IService和其实现类 ServiceImpl，封装了常见的业务层逻辑 详情查看源码IService和ServiceImpl 创建Service接口和实现类 12345/*** UserService继承IService模板提供的基础功能*/public interface UserService extends IService&lt;User&gt; &#123;&#125; 1234567/*** ServiceImpl实现了IService，提供了IService中基础功能的实现* 若ServiceImpl无法满足业务需求，则可以使用自定的UserService定义方法，并在实现类中实现*/@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123;&#125; 测试查询记录数 1234567@Autowiredprivate UserService userService;@Testpublic void testGetCount()&#123; long count = userService.count(); System.out.println(&quot;总记录数：&quot; + count);&#125; 2. 常用注解2.1 @TableName在实体类类型上添加@TableName(“t_user”)，标识实体类对应的表，即可成功执行SQL语句 也可以通过全局配置解决： 12345678mybatis-plus:\tconfiguration: # 配置MyBatis日志 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl\tglobal-config: db-config: # 配置MyBatis-Plus操作表的默认前缀 table-prefix: t_ 使用MyBatis-Plus提供的全局配置，为实体类所对应的表名设置默认的前缀，那么就 不需要在每个实体类上通过@TableName标识实体类对应的表 2.2 @TableId在实体类中uid属性上通过@TableId将其标识为主键，即可成功执行SQL语句 同样也可以通过type属性来定义主键策略： 1. IdType.ASSIGN_ID（默 认） ：基于雪花算法生成id 1. IdType.AUTO ：使用数据库自增策略 2.3 @TableField当实体类中的属性名和数据库中的字段名不一致时，可以使用这个注解 2.4 @TableLogic该注解的功能是实现逻辑删除 物理删除：真实删除，将对应数据从数据库中删除，之后查询不到此条被删除的数据 逻辑删除：假删除，将对应数据中代表是否被删除字段的状态修改为“被删除状态”，之后在数据库 中仍旧能看到此条数据记录 优点：可以进行数据恢复 注意：使用逻辑删除真正执行的SQL是update语句 3. 条件构造器和常用接口3.1 wrapper介绍 Wrapper：条件构造抽象类，最顶端的父类 AbstractWrapper ： 用于查询条件封装，生成 sql 的 where 条件 QueryWrapper ： 查询条件封装 UpdateWrapper ： Update 条件封装 AbstractLambdaWrapper ： 使用Lambda 语法 LambdaQueryWrapper ：用于Lambda语法使用的查询Wrapper LambdaUpdateWrapper ： Lambda 更新封装Wrapper 3.2 QueryWrapper3.2.1 组装查询条件123456789101112@Testpublic void test01()&#123; //查询用户名包含a，年龄在20到30之间，并且邮箱不为null的用户信息 //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 AND (username LIKE ? AND age BETWEEN ? AND ? AND email IS NOT NULL) QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.like(&quot;username&quot;, &quot;a&quot;) .between(&quot;age&quot;, 20, 30) .isNotNull(&quot;email&quot;); List&lt;User&gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println);&#125; 3.2.2 组装排序条件1234567891011@Testpublic void test02()&#123; //按年龄降序查询用户，如果年龄相同则按id升序排列 //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE is_deleted=0 ORDER BY age DESC,id ASC QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.orderByDesc(&quot;age&quot;) .orderByAsc(&quot;id&quot;); List&lt;User&gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println);&#125; 3.2.3 组装删除条件12345678910@Testpublic void test03()&#123; //删除email为空的用户 //DELETE FROM t_user WHERE (email IS NULL) QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.isNull(&quot;email&quot;); //条件构造器也可以构建删除语句的条件 int result = userMapper.delete(queryWrapper); System.out.println(&quot;受影响的行数：&quot; + result);&#125; 3.2.4 条件的优先级12345678910111213141516@Testpublic void test04() &#123; QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); //将（年龄大于20并且用户名中包含有a）或邮箱为null的用户信息修改 //UPDATE t_user SET age=?, email=? WHERE (username LIKE ? AND age &gt; ? OR email IS NULL) queryWrapper .like(&quot;username&quot;, &quot;a&quot;) .gt(&quot;age&quot;, 20) .or() .isNull(&quot;email&quot;); User user = new User(); user.setAge(18); user.setEmail(&quot;user@atguigu.com&quot;); int result = userMapper.update(user, queryWrapper); System.out.println(&quot;受影响的行数：&quot; + result);&#125; 123456789101112131415@Testpublic void test04() &#123; QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); //将用户名中包含有a并且（年龄大于20或邮箱为null）的用户信息修改 //UPDATE t_user SET age=?, email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL)) //lambda表达式内的逻辑优先运算 queryWrapper .like(&quot;username&quot;, &quot;a&quot;) .and(i -&gt; i.gt(&quot;age&quot;, 20).or().isNull(&quot;email&quot;)); User user = new User(); user.setAge(18); user.setEmail(&quot;user@atguigu.com&quot;); int result = userMapper.update(user, queryWrapper); System.out.println(&quot;受影响的行数：&quot; + result);&#125; 3.2.5 组装select子句12345678910@Testpublic void test05() &#123; //查询用户信息的username和age字段 //SELECT username,age FROM t_user QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.select(&quot;username&quot;, &quot;age&quot;); //selectMaps()返回Map集合列表，通常配合select()使用，避免User对象中没有被查询到的列值为null List&lt;Map&lt;String, Object&gt;&gt; maps = userMapper.selectMaps(queryWrapper); maps.forEach(System.out::println);&#125; 3.2.6 实现子查询123456789@Testpublic void test06() &#123; //查询id小于等于3的用户信息 //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (id IN (select id from t_user where id &lt;= 3)) QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.inSql(&quot;id&quot;, &quot;select id from t_user where id &lt;= 3&quot;); List&lt;User&gt; list = userMapper.selectList(queryWrapper); list.forEach(System.out::println);&#125; 3.3 UpdateWrapper1234567891011121314151617181920@Testpublic void test07() &#123; //将（年龄大于20或邮箱为null）并且用户名中包含有a的用户信息修改 //组装set子句以及修改条件 UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;(); //lambda表达式内的逻辑优先运算 updateWrapper .set(&quot;age&quot;, 18) .set(&quot;email&quot;, &quot;user@atguigu.com&quot;) .like(&quot;username&quot;, &quot;a&quot;) .and(i -&gt; i.gt(&quot;age&quot;, 20).or().isNull(&quot;email&quot;)); //这里必须要创建User对象，否则无法应用自动填充。如果没有自动填充，可以设置为null //UPDATE t_user SET username=?, age=?,email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL)) //User user = new User(); //user.setName(&quot;张三&quot;); //int result = userMapper.update(user, updateWrapper); //UPDATE t_user SET age=?,email=? WHERE (username LIKE ? AND (age &gt; ? OR email IS NULL)) int result = userMapper.update(null, updateWrapper); System.out.println(result);&#125; 3.4 Condition在真正开发的过程中，组装条件是常见的功能，而这些条件数据来源于用户输入，是可选的，因 此我们在组装这些条件时，必须先判断用户是否选择了这些条件，若选择则需要组装该条件，若 没有选择则一定不能组装，以免影响SQL执行的结果 思路一 12345678910111213141516171819202122@Testpublic void test08() &#123; //定义查询条件，有可能为null（用户未输入或未选择） String username = null; Integer ageBegin = 10; Integer ageEnd = 24; QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); //StringUtils.isNotBlank()判断某字符串是否不为空且长度不为0且不由空白符(whitespace) 构成 if(StringUtils.isNotBlank(username))&#123; queryWrapper.like(&quot;username&quot;,&quot;a&quot;); &#125; if(ageBegin != null)&#123; queryWrapper.ge(&quot;age&quot;, ageBegin); &#125; if(ageEnd != null)&#123; queryWrapper.le(&quot;age&quot;, ageEnd); &#125; //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (age &gt;= ? AND age &lt;= ?) List&lt;User&gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println);&#125; 思路二： 上面的实现方案没有问题，但是代码比较复杂，我们可以使用带condition参数的重载方法构建查 询条件，简化代码的编写 12345678910111213141516@Testpublic void test08UseCondition() &#123; //定义查询条件，有可能为null（用户未输入或未选择） String username = null; Integer ageBegin = 10; Integer ageEnd = 24; QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); //StringUtils.isNotBlank()判断某字符串是否不为空且长度不为0且不由空白符(whitespace) 构成 queryWrapper .like(StringUtils.isNotBlank(username), &quot;username&quot;, &quot;a&quot;) .ge(ageBegin != null, &quot;age&quot;, ageBegin) .le(ageEnd != null, &quot;age&quot;, ageEnd); //SELECT id,username AS name,age,email,is_deleted FROM t_user WHERE (age &gt;= ? AND age &lt;= ?) List&lt;User&gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println);&#125; 3.5 LambdaQueryWrapper123456789101112131415@Testpublic void test09() &#123; //定义查询条件，有可能为null（用户未输入） String username = &quot;a&quot;; Integer ageBegin = 10; Integer ageEnd = 24; LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); //避免使用字符串表示字段，防止运行时错误 queryWrapper .like(StringUtils.isNotBlank(username), User::getName, username) .ge(ageBegin != null, User::getAge, ageBegin) .le(ageEnd != null, User::getAge, ageEnd); List&lt;User&gt; users = userMapper.selectList(queryWrapper); users.forEach(System.out::println);&#125; 3.6 LambdaUpdateWrapper12345678910111213@Testpublic void test10() &#123; //组装set子句 LambdaUpdateWrapper&lt;User&gt; updateWrapper = new LambdaUpdateWrapper&lt;&gt;(); updateWrapper .set(User::getAge, 18) .set(User::getEmail, &quot;user@atguigu.com&quot;) .like(User::getName, &quot;a&quot;) .and(i -&gt; i.lt(User::getAge, 24).or().isNull(User::getEmail)); //lambda表达式内的逻辑优先运算 User user = new User(); int result = userMapper.update(user, updateWrapper); System.out.println(&quot;受影响的行数：&quot; + result);&#125; 4. 插件4.1 分页插件MyBatis Plus自带分页插件，只要简单的配置即可实现分页功能 添加配置类Config 1234567891011@Configuration@MapperScan(&quot;com.atguigu.mybatisplus.mapper&quot;) //可以将主类中的注解移到此处public class MybatisPlusConfig &#123; @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; &#125;&#125; 测试 123456789101112131415@Testpublic void testPage()&#123; //设置分页参数 Page&lt;User&gt; page = new Page&lt;&gt;(1, 5); userMapper.selectPage(page, null); //获取分页数据 List&lt;User&gt; list = page.getRecords(); list.forEach(System.out::println); System.out.println(&quot;当前页：&quot;+page.getCurrent()); System.out.println(&quot;每页显示的条数：&quot;+page.getSize()); System.out.println(&quot;总记录数：&quot;+page.getTotal()); System.out.println(&quot;总页数：&quot;+page.getPages()); System.out.println(&quot;是否有上一页：&quot;+page.hasPrevious()); System.out.println(&quot;是否有下一页：&quot;+page.hasNext());&#125; 4.2 xml自定义分页 UserMapper中定义接口方法 1234567/*** 根据年龄查询用户列表，分页显示* @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位* @param age 年龄* @return*/IPage&lt;User&gt; selectPageVo(@Param(&quot;page&quot;) Page&lt;User&gt; page, @Param(&quot;age&quot;) Integer age); UserMapper.xml中编写SQL 123456&lt;!--SQL片段，记录基础字段--&gt;&lt;sql id=&quot;BaseColumns&quot;&gt;id,username,age,email&lt;/sql&gt;&lt;!--IPage&lt;User&gt; selectPageVo(Page&lt;User&gt; page, Integer age);--&gt;&lt;select id=&quot;selectPageVo&quot; resultType=&quot;User&quot;&gt;\tSELECT &lt;include refid=&quot;BaseColumns&quot;&gt;&lt;/include&gt; FROM t_user WHERE age &gt; #&#123;age&#125;&lt;/select&gt; 测试 123456789101112131415@Testpublic void testSelectPageVo()&#123; //设置分页参数 Page&lt;User&gt; page = new Page&lt;&gt;(1, 5); userMapper.selectPageVo(page, 20); //获取分页数据 List&lt;User&gt; list = page.getRecords(); list.forEach(System.out::println); System.out.println(&quot;当前页：&quot;+page.getCurrent()); System.out.println(&quot;每页显示的条数：&quot;+page.getSize()); System.out.println(&quot;总记录数：&quot;+page.getTotal()); System.out.println(&quot;总页数：&quot;+page.getPages()); System.out.println(&quot;是否有上一页：&quot;+page.hasPrevious()); System.out.println(&quot;是否有下一页：&quot;+page.hasNext());&#125; 5. 通用枚举表中的有些字段值是固定的，例如性别（男或女），此时我们可以使用MyBatis-Plus的通用枚举来实现 数据库表汇总添加sex字段 创建通用枚举类型 12345678910111213141516import com.baomidou.mybatisplus.annotation.EnumValue;import lombok.Getter;@Getterpublic enum SexEnum &#123; MALE(1, &quot;男&quot;), FEMALE(2, &quot;女&quot;); @EnumValue private Integer sex; private String sexName; SexEnum(Integer sex, String sexName) &#123; this.sex = sex; this.sexName = sexName; &#125;&#125; 配置扫描通用枚举 12345678910111213mybatis-plus: configuration: # 配置MyBatis日志 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: # 配置MyBatis-Plus操作表的默认前缀 table-prefix: t_ # 配置MyBatis-Plus的主键策略 id-type: auto # 配置扫描通用枚举 type-enums-package: com.CPG.mybatisplus.enums 测试 1234567891011@Testpublic void testSexEnum()&#123; User user = new User(); user.setName(&quot;Enum&quot;); user.setAge(20); //设置性别信息为枚举项，会将@EnumValue注解所标识的属性值存储到数据库 user.setSex(SexEnum.MALE); //INSERT INTO t_user ( username, age, sex ) VALUES ( ?, ?, ? ) //Parameters: Enum(String), 20(Integer), 1(Integer) userMapper.insert(user);&#125; 6. 代码生成器6.1 引入依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.31&lt;/version&gt;&lt;/dependency&gt; 6.2 快速生成12345678910111213141516171819202122public class FastAutoGeneratorTest &#123; public static void main(String[] args) &#123; FastAutoGenerator.create(&quot;jdbc:mysql://127.0.0.1:3306/mybatis_plus?characterEncoding=utf-8&amp;userSSL=false&quot;, &quot;root&quot;, &quot;123456&quot;) .globalConfig(builder -&gt; &#123; builder.author(&quot;CPG&quot;) // 设置作者 //.enableSwagger() // 开启 swagger 模式 .fileOverride() // 覆盖已生成文件 .outputDir(&quot;D://mybatis_plus&quot;); // 指定输出目录 &#125;) .packageConfig(builder -&gt; &#123; builder.parent(&quot;com.CPG&quot;) // 设置父包名 .moduleName(&quot;mybatisplus&quot;) // 设置父包模块名 .pathInfo(Collections.singletonMap(OutputFile.mapperXml, &quot;D://mybatis_plus&quot;));// 设置mapperXml生成路径 &#125;) .strategyConfig(builder -&gt; &#123; builder.addInclude(&quot;t_user&quot;) // 设置需要生成的表名 .addTablePrefix(&quot;t_&quot;, &quot;c_&quot;); // 设置过滤表前缀 &#125;) .templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker引擎模板，默认的是Velocity引擎模板 .execute(); &#125;&#125; 7. 多数据源适用于多种场景：纯粹多库、 读写分离、 一主多从、 混合模式等 目前我们就来模拟一个纯粹多库的一个场景，其他场景类似 场景说明： 我们创建两个库，分别为：mybatis_plus（以前的库不动）与mybatis_plus_1（新建），将 mybatis_plus库的product表移动到mybatis_plus_1库，这样每个库一张表，通过一个测试用例 分别获取用户数据与商品数据，如果获取到说明多库模拟成功 7.1 创建数据库及表 创建数据库mybatis_plus_1和表product 1234567891011CREATE DATABASE `mybatis_plus_1` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;use `mybatis_plus_1`;CREATE TABLE product( id BIGINT(20) NOT NULL COMMENT &#x27;主键ID&#x27;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &#x27;商品名称&#x27;, price INT(11) DEFAULT 0 COMMENT &#x27;价格&#x27;, version INT(11) DEFAULT 0 COMMENT &#x27;乐观锁版本号&#x27;, PRIMARY KEY (id)); 添加测试数据 1INSERT INTO product (id, NAME, price) VALUES (1, &#x27;外星人笔记本&#x27;, 100); 删除mybatis_plus库product表 12use mybatis_plus;DROP TABLE IF EXISTS product; 7.2 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.0&lt;/version&gt;&lt;/dependency&gt; 7.3 配置多数据源1234567891011121314151617181920spring: # 配置数据源信息 datasource: dynamic: # 设置默认的数据源或者数据源组,默认值即为master primary: master # 严格匹配数据源,默认false.true未匹配到指定数据源时抛异常,false使用默认数据源 strict: false datasource: master: url: jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8&amp;useSSL=false driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 slave_1: url: jdbc:mysql://localhost:3306/mybatis_plus_1?characterEncoding=utf-8&amp;useSSL=false driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 7.4 创建用户service12public interface UserService extends IService&lt;User&gt; &#123;&#125; 1234@DS(&quot;master&quot;) //指定所操作的数据源@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123;&#125; 7.5 创建商品service12public interface ProductService extends IService&lt;Product&gt; &#123;&#125; 12345@DS(&quot;slave_1&quot;)@Servicepublic class ProductServiceImpl extends ServiceImpl&lt;ProductMapper, Product&gt;implements ProductService &#123;&#125; 7.6 测试12345678910@Autowiredprivate UserService userService; @Autowired private ProductService productService; @Test public void testDynamicDataSource()&#123; System.out.println(userService.getById(1L)); System.out.println(productService.getById(1L));&#125;","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"Gateway服务网关","path":"/2022/06/29/Gateway服务网关/","content":"服务网关1. SpringCloud Gateway介绍Spring cloud gateway是spring官方基于Spring 5.0、Spring Boot2.0和Project Reactor等技术开发的网关，Spring Cloud Gateway旨在为微服务架构提供简单、有效和统一的API路由管理方式，Spring Cloud Gateway作为Spring Cloud生态系统中的网关，目标是替代Netflix Zuul，其不仅提供统一的路由方式，并且还基于Filer链的方式提供了网关基本的功能，例如：安全、监控&#x2F;埋点、限流等 2. 整合gateway网关 pom.xml 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;artifactId&gt;common_util&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务注册 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.properties 12345678910111213141516171819202122232425#服务端口server.port=80#服务名spring.application.name=service-gateway#nacos地址spring.cloud.nacos.discovery.server-addr=localhost:8848#使用服务发现路由spring.cloud.gateway.discovery.locator.enabled=true#设置路由idspring.cloud.gateway.routes[0].id=service-hosp#设置路由的urispring.cloud.gateway.routes[0].uri=lb://service-hosp#设置路由断言,代理servicerId为auth-service的/auth/路径spring.cloud.gateway.routes[0].predicates= Path=/*/hosp/**#设置路由idspring.cloud.gateway.routes[1].id=service-cmn#设置路由的urispring.cloud.gateway.routes[1].uri=lb://service-cmn#设置路由断言,代理servicerId为auth-service的/auth/路径spring.cloud.gateway.routes[1].predicates= Path=/*/cmn/** 添加启动类 1234567@SpringBootApplicationpublic class ServiceGatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceGatewayApplication.class,args); &#125;&#125; 注：启动测试的时候要把nacos启动，再启动测试类，不然会报错","tags":["工作","Java","项目","中间技术"],"categories":["Java技术","医院在线预约系统"]},{"title":"6.数据接口","path":"/2022/06/26/6.数据接口/","content":"一、上传医院接口1. 集成MongoDB 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 12345678#mongodb地址spring.data.mongodb.host=192.168.134.134spring.data.mongodb.port=27017spring.data.mongodb.database=ar_hosp#或spring.data.mongodb.uri=mongodb://192.168.134.134:27017/yygh_hosp 2. 创建repository、service和controller1234@Repositorypublic interface HospitalRepository extends MongoRepository&lt;Hospital,String&gt; &#123;&#125; 12public interface HospitalService &#123;&#125; 123456@Servicepublic class HospitalServiceImpl implements HospitalService &#123; @Autowired private HospitalRepository hospitalRepository;&#125; 12345678@RestController@RequestMapping(&quot;/api/hosp&quot;)public class ApiController &#123; @Autowired private HospitalService hospitalService;&#125; 3. 上传医院 接口数据分析 1234567891011121314151617181920212223&#123; &quot;hoscode&quot;: &quot;1000_01&quot;, &quot;hosname&quot;: &quot;北京协和医院&quot;, &quot;hostype&quot;: &quot;1&quot;, &quot;provinceCode&quot;: &quot;110000&quot;, &quot;cityCode&quot;: &quot;110100&quot;, &quot;districtCode&quot;: &quot;110102&quot;, &quot;address&quot;: &quot;大望路&quot;, &quot;intro&quot;: &quot;北京协和医院是集医疗、教学、科研于一体的大型三级甲等综合医院，是国家卫生计生委...目标而继续努力。&quot;, &quot;route&quot;: &quot;东院区乘车路线：106、...更多乘车路线详见须知。&quot;, &quot;logoData&quot;: &quot;iVBORw0KGgoAAAA...NSUhEUg==&quot;, &quot;bookingRule&quot;: &#123; &quot;cycle&quot;: &quot;1&quot;, &quot;releaseTime&quot;: &quot;08:30&quot;, &quot;stopTime&quot;: &quot;11:30&quot;, &quot;quitDay&quot;: &quot;-1&quot;, &quot;quitTime&quot;: &quot;15:30&quot;, &quot;rule&quot;: [ &quot;西院区预约号取号地点：西院区门诊楼一层大厅挂号窗口取号&quot;, &quot;东院区预约号取号地点：东院区老门诊楼一层大厅挂号窗口或新门诊楼各楼层挂号/收费窗口取号&quot; ] &#125;&#125; https://achang.blog.csdn.net/article/details/115105814","tags":["工作","Java","项目","接口"],"categories":["Java技术","医院在线预约系统"]},{"title":"5.数据字典","path":"/2022/06/22/5.数据字典/","content":"数据字典一、数据字典介绍数据字典就是管理系统中常用的分类数据或者一些固定数据，例如：省市区三级联动数据、民族数据、行业数据、学历数据等，由于该系统大量使用这种数据，所以我们要做一个数据管理方便管理系统数据，一般系统基本都会做数据管理。 二、数据字典开发1.搭建service-cmn模块 config controller mapper service impl 2.数据字典接口列表-后台 123456789101112131415161718192021@RestController@Api(tags = &quot;数据字典的接口&quot;)@CrossOrigin@RequestMapping(&quot;/admin/cmn/dict&quot;)public class DictController &#123; @Autowired private DictService dictService; /** * 根据数据id查询子数据列表 * @param id * @return */ @ApiOperation(value = &quot;根据数据id查询子数据列表&quot;) @GetMapping(&quot;findChildData/&#123;id&#125;&quot;) public Result findChildData(@PathVariable Long id)&#123; List&lt;Dict&gt; dictList = dictService.findChildData(id); return Result.ok(dictList); &#125;&#125; 123456789101112131415161718192021222324252627@Servicepublic class DictServiceImpl extends ServiceImpl&lt;DictMapper, Dict&gt; implements DictService&#123; //根据数据id查询子数据列表 @Override public List&lt;Dict&gt; findChildData(Long id) &#123; QueryWrapper&lt;Dict&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(&quot;parent_id&quot;,id); //ServiceImpl中已经帮忙注入了，所以直接调用就行 List&lt;Dict&gt; dictList = baseMapper.selectList(wrapper); //向list集合每个dict对象中设置hasChildren for (Dict dict : dictList) &#123; Long dictId = dict.getId(); boolean hasChildren = this.hasChildren(dictId); dict.setHasChildren(hasChildren); &#125; return dictList; &#125; //判断id下面是否有子节点 private boolean hasChildren(Long id)&#123; QueryWrapper&lt;Dict&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(&quot;parent_id&quot;,id); Integer count = baseMapper.selectCount(wrapper); return count&gt;0; &#125;&#125; 列表-前端 12345678910111213//数据字典列表getDictList(id) &#123; dict.dictList(id) .then(response =&gt; &#123; this.list = response.data &#125;)&#125;, //层级显示 getChildren(tree, treeNode, resolve) &#123; dict.dictList(tree.id).then(response =&gt; &#123; resolve(response.data) &#125;) &#125; 12345678910111213141516171819202122232425262728293031&lt;el-table:data=&quot;list&quot;style=&quot;width: 100%&quot;row-key=&quot;id&quot;borderlazy:load=&quot;getChildren&quot;:tree-props=&quot;&#123;children: &#x27;children&#x27;, hasChildren: &#x27;hasChildren&#x27;&#125;&quot;&gt; &lt;el-table-column label=&quot;名称&quot; width=&quot;230&quot; align=&quot;left&quot;&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.name &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column label=&quot;编码&quot; width=&quot;220&quot;&gt; &lt;template slot-scope=&quot;&#123;row&#125;&quot;&gt; &#123;&#123; row.dictCode &#125;&#125; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column label=&quot;值&quot; width=&quot;230&quot; align=&quot;left&quot;&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.value &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column label=&quot;创建时间&quot; align=&quot;center&quot;&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.createTime &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt;&lt;/el-table&gt; EasyExcel-写操作 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt; 创建实体类，在对应的属性上设置注解，注解内容就是表头的内容 12345678910@Datapublic class UserData &#123; @ExcelProperty(&quot;用户编号&quot;) private int uid; @ExcelProperty(&quot;用户名称&quot;) private String username;&#125; 实现写操作的代码 12345678910111213141516171819public class TestWrite &#123; public static void main(String[] args) &#123; //构建数据list集合 List&lt;UserData&gt; list = new ArrayList(); for (int i = 0; i &lt; 10; i++) &#123; UserData data = new UserData(); data.setUid(i); data.setUsername(&quot;Sirius&quot;+(i+1); list.add(data); &#125; //设置excel文件路径和名称 String fileName = &quot;E:\\\\StudyFiles\\\\TestExcel\\\\write01.xlsx&quot;; //调用方法实现写操作 EasyExcel.write(fileName,UserData.class).sheet(&quot;用户信息&quot;) .doWrite(list); &#125;&#125; EasyExcel-读操作 创建实体类 123456789101112@Datapublic class UserData &#123; @ColumnWidth(20) //设置列宽 @ExcelProperty(value = &quot;用户编号&quot;,index = 0) private int uid; @ColumnWidth(20) @ExcelProperty(value = &quot;用户名称&quot;,index = 1) private String username;&#125; 写一个监听器 12345678910111213141516171819public class ExcelListener extends AnalysisEventListener&lt;UserData&gt; &#123; //一行一行读取excel的内容，从第二行读取，因为第一行是表头 @Override public void invoke(UserData userData, AnalysisContext analysisContext) &#123; System.out.println(userData); &#125; @Override public void invokeHeadMap(Map&lt;Integer,String&gt; headMap, AnalysisContext analysisContext)&#123; System.out.println(&quot;表头信息：&quot;+headMap); &#125; //读取之后会执行 @Override public void doAfterAllAnalysed(AnalysisContext analysisContext) &#123; &#125;&#125; 实现读操作的代码 12345678public class TestRead &#123; public static void main(String[] args) &#123; //读取文件的路径和名称 String fileName = &quot;E:\\\\StudyFiles\\\\TestExcel\\\\write01.xlsx&quot;; //调用方法实现读取操作 EasyExcel.read(fileName,UserData.class,new ExcelListener()).sheet().doRead(); &#125;&#125; 数据字典-导出 serviceImpl 12345678910111213141516171819202122232425262728//导出数据字典接口@Overridepublic void exportDictData(HttpServletResponse response) &#123; //设置类型 response.setContentType(&quot;application/vnd.ms-excel&quot;); //设置编码 response.setCharacterEncoding(&quot;utf-8&quot;); //这里使用URLEncode.encode可以防止中文乱码，当然和easyexcel没有关系 String fileName = &quot;dict&quot;; response.setHeader(&quot;Content-disposition&quot;,&quot;attachment;filename=&quot;+fileName+&quot;.xlsx&quot;); //查询数据库 List&lt;Dict&gt; dictList = baseMapper.selectList(null); //把Dict转换成DictEeVo List&lt;DictEeVo&gt; dictEeVoList = new ArrayList&lt;&gt;(); for (Dict dict : dictList) &#123; DictEeVo dictEeVo = new DictEeVo(); BeanUtils.copyProperties(dict,dictEeVo); dictEeVoList.add(dictEeVo); &#125; //调用方法进行写的操作 try &#123; EasyExcel.write(response.getOutputStream(), DictEeVo.class).sheet(&quot;dict&quot;) .doWrite(dictEeVoList); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; controller 1234@GetMapping(&quot;exportData&quot;)public void exportDict(HttpServletResponse response)&#123; dictService.exportDictData(response);&#125; 前端 12345//下载数据字典exportData() &#123; //调用导出接口 window.location.href=&quot;http://localhost:8202/admin/cmn/dict/exportData&quot;&#125;, 123&lt;a href=&quot;http://localhost:8202/admin/cmn/dict/exportData&quot; target=&quot;_blank&quot;&gt; &lt;el-button type=&quot;primary&quot;&gt;&lt;i class=&quot;el-icon--right el-icon-download&quot;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;下载&lt;/el-button&gt;&lt;/a&gt; 数据字典导入 注意：listener、fitter都不是Spring容器管理的，无法在这些类中直接使用Spring注解的方式来注入我们需要的对象。 controller 12345@PostMapping(&quot;importData&quot;)public Result importDict(MultipartFile file)&#123; dictService.importDictData(file); return Result.ok();&#125; serviceImpl 123456789//导入数据字典实现@Overridepublic void importDictData(MultipartFile file) &#123; try &#123; EasyExcel.read(file.getInputStream(),DictEeVo.class,new DictListener(baseMapper)).sheet().doRead(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; listener 1234567891011121314151617181920212223public class DictListener extends AnalysisEventListener&lt;DictEeVo&gt; &#123; //这里不能用Autowired注入 private DictMapper dictMapper; //有参构造 public DictListener(DictMapper dictMapper) &#123; this.dictMapper = dictMapper; &#125; //一行一行读取 @Override public void invoke(DictEeVo dictEeVo, AnalysisContext analysisContext) &#123; //调用方法添加数据库 Dict dict = new Dict(); BeanUtils.copyProperties(dictEeVo,dict); dictMapper.insert(dict); &#125; @Override public void doAfterAllAnalysed(AnalysisContext analysisContext) &#123; &#125;&#125; 前端 1234567891011121314151617181920212223&lt;el-dialog title=&quot;上传&quot; :visible.sync=&quot;dialogImportVisible&quot; width=&quot;480px&quot;&gt; &lt;el-form label-position=&quot;right&quot; label-width=&quot;170px&quot;&gt; &lt;el-form-item label=&quot;文件&quot;&gt; &lt;el-upload :multiple=&quot;false&quot; :on-success=&quot;onUploadSuccess&quot; :action=&quot;&#x27;http://localhost:8202/admin/cmn/dict/importData&#x27;&quot; class=&quot;upload-demo&quot;&gt; &lt;el-button size=&quot;small&quot; type=&quot;primary&quot;&gt;点击上传&lt;/el-button&gt; &lt;div slot=&quot;tip&quot; class=&quot;el-upload__tip&quot;&gt;只能上传excel文件，且不超过500kb&lt;/div&gt; &lt;/el-upload&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;div slot=&quot;footer&quot; class=&quot;dialog-footer&quot;&gt; &lt;el-button @click=&quot;dialogImportVisible = false&quot;&gt; 取消 &lt;/el-button&gt; &lt;/div&gt;&lt;/el-dialog&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243export default &#123; data() &#123; return &#123; //设置弹框是否弹出 false为不弹出 dialogImportVisible:false, list:[] //数据字典列表数组 &#125; &#125;, created() &#123; this.getDictList(1) &#125;, methods: &#123; //上传数据字典 importData() &#123; this.dialogImportVisible = true &#125;, //上传成功调用 onUploadSuccess() &#123; //关闭弹框 this.dialogImportVisible = false //刷新页面 this.getDictList(1) &#125;, //下载数据字典 exportData() &#123; //调用导出接口 window.location.href=&quot;http://localhost:8202/admin/cmn/dict/exportData&quot; &#125;, //数据字典列表 getDictList(id) &#123; dict.dictList(id) .then(response =&gt; &#123; this.list = response.data &#125;) &#125;, //层级显示 getChildren(tree, treeNode, resolve) &#123; dict.dictList(tree.id).then(response =&gt; &#123; resolve(response.data) &#125;) &#125; &#125;&#125; 数据字典-添加缓存 缓存：提高查询速度 不经常修改的数据、固定的数据、经常查询的数据适合做缓存 项目集成SpringCache + Redis 在service_util中添加依赖 1234567891011&lt;!-- redis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- spring2.X集成redis所需common-pool2--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; 在service_util中的config包下添加redis的配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Configuration//开启缓存处理@EnableCachingpublic class RedisConfig &#123; /** * 自定义key规则 * @return */ @Bean public KeyGenerator keyGenerator()&#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(target.getClass().getName()); stringBuilder.append(method.getName()); for (Object obj : params) &#123; stringBuilder.append(obj.toString()); &#125; return stringBuilder.toString(); &#125; &#125;; &#125; /** * 设置RedisTemplate规则 * @param redisConnectionFactory * @return */ @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); //序列号key value redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125; /** * 设置CacheManager缓存规则 * @param factory * @return */ @Bean public CacheManager cacheManager(RedisConnectionFactory factory) &#123; RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); // 配置序列化（解决乱码的问题）,过期时间600秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(600)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory) .cacheDefaults(config) .build(); return cacheManager; &#125;&#125; 在application.properties中添加redis配置 12345678910111213141516#redis服务器地址spring.redis.host=192.168.134.134#redis服务器连接端口spring.redis.port=6379#redis数据库索引(默认为0)spring.redis.database=0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间（使用负值表示没有限制）spring.redis.lettuce.pool.max-wait=-1#连接池中最大空闲连接spring.redis.lettcue.pool.max-idle=5#连接池中最小空闲连接spring.redis.lettuce.pool.min-idle=0 3. SpringCache常用缓存标签 缓存@Cacheable 根据方法对其返回结果进行缓存，下次请求时，如果缓存存在，则直接读取缓存数据返回；如果缓存不存在，则执行方法，并把返回的结果存入缓存中。一般用在查询方法上。 查看源码，其属性值如下： value：缓存名，必填，它指定了你的缓存放在哪块命名空间 cacheNames：和value差不多，二选一即可 key：可选属性，可以使用SpEl标签自定义缓存的key 缓存@CachePut 使用该注解标志的方法，每次都会执行，并将结果存入指定的缓存中。其他方法可以直接从响应的缓存中读取缓存数据，而不需要再去查询数据库。一般用在新增方法上。 查看源码，属性值如下： value：缓存名，必填，它指定了你的缓存放在哪块命名空间 cacheNames：和value差不多，二选一即可 key：可选属性，可以使用SpEl标签自定义缓存的key ​\t3. 缓存@CacheEvict ​\t使用该注解标志的方法，会清空指定的缓存。一般用在更新或者删除方法上 ​\t查看源码，属性值如下： ​\tvalue：缓存名，必填，它指定了你的缓存放在哪块命名空间 ​\tcacheNames：和value差不多，二选一即可 ​\tkey：可选属性，可以使用SpEl标签自定义缓存的key ​\tallEntries：是否清空所有缓存，默认为false ​\tbeforeInvocation：是否在方法执行前就清空，默认为false 4. 数据字典的应用在DictServiceImpl中加入注解 12345678910111213141516//根据数据id查询子数据列表@Override@Cacheable(value = &quot;dict&quot;,keyGenerator = &quot;keyGenerator&quot;)public List&lt;Dict&gt; findChildData(Long id) &#123; QueryWrapper&lt;Dict&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(&quot;parent_id&quot;,id); //ServiceImpl中已经帮忙注入了，所以直接调用就行 List&lt;Dict&gt; dictList = baseMapper.selectList(wrapper); //向list集合每个dict对象中设置hasChildren for (Dict dict : dictList) &#123; Long dictId = dict.getId(); boolean hasChildren = this.hasChildren(dictId); dict.setHasChildren(hasChildren); &#125; return dictList;&#125; 启动项目查询后，进入redis就可以看到查询的所有数据已经被存入redis中了。 5. 配置nginx 下载nginx（windows版本，因为后面会用网关代替nginx） 配置nginx.conf 12345678910server &#123; listen 9001; server_name localhost;\tlocation ~ /hosp/ &#123; proxy_pass http://localhost:8201;\t&#125;\tlocation ~ /cmn/ &#123; proxy_pass http://localhost:8202;\t&#125;&#125; 去dev.env.js中修改BASE_API 后续添加service模块自行添加nginx配置，不做说明 后续我们将了Spring Cloud Gateway网关，将替代nginx网关","tags":["工作","Java","项目","前端"],"categories":["Java技术","医院在线预约系统"]},{"title":"4.前端环境搭建","path":"/2022/06/18/4.前端环境搭建/","content":"前端环境搭建一、vue-element-admin 解压文件到项目工作区 根据package.json下载需要的依赖npm install 然后运行npm run dev 二、登录改造..\\src\\store\\modules\\user.js 123456789101112131415161718192021222324Login(&#123; commit &#125;, userInfo) &#123; const data = &#123;&#x27;token&#x27;:&#x27;admin&#x27;&#125; setToken(data.token) commit(&#x27;SET_TOKEN&#x27;, data.token)&#125;,// 获取用户信息GetInfo(&#123; commit, state &#125;) &#123; const data = &#123;&#x27;roles&#x27;:&#x27;admin&#x27;,&#x27;name&#x27;:&#x27;admin&#x27;,&#x27;avatar&#x27;:&#x27;https://wpimg.wallstcn.com/f778738c-e4f8-4870-b634-56703b4acafe.gif&#x27;&#125; if (data.roles &amp;&amp; data.roles.length &gt; 0) &#123; // 验证返回的roles是否是一个非空数组 commit(&#x27;SET_ROLES&#x27;, data.roles) &#125; else &#123; reject(&#x27;getInfo: roles must be a non-null array !&#x27;) &#125; commit(&#x27;SET_NAME&#x27;, data.name) commit(&#x27;SET_AVATAR&#x27;, data.avatar)&#125;,// 登出LogOut(&#123; commit, state &#125;) &#123; commit(&#x27;SET_TOKEN&#x27;, &#x27;&#x27;) commit(&#x27;SET_ROLES&#x27;, []) removeToken()&#125;, 三、框架开发过程 添加路由 设置要跳转的页面路径 在api文件中创建js文件，定义接口路径 在页面中引入js文件，使用axios进行接口调用，把接口返回数据在页面显示 四、医院设置前端开发 添加医院设置路由 12345678910111213141516171819path: &#x27;/hospSet&#x27;, component: Layout, redirect: &#x27;/hospSet/list&#x27;, name: &#x27;医院设置管理&#x27;, meta: &#123; title: &#x27;医院设置管理&#x27;, icon: &#x27;example&#x27; &#125;, children: [ &#123; path: &#x27;list&#x27;, name: &#x27;医院设置列表&#x27;, component: () =&gt; import(&#x27;@/views/hospset/list&#x27;), meta: &#123; title: &#x27;医院设置列表&#x27;, icon: &#x27;table&#x27; &#125; &#125;, &#123; path: &#x27;add&#x27;, name: &#x27;医院设置添加&#x27;, component: () =&gt; import(&#x27;@/views/hospset/add&#x27;), meta: &#123; title: &#x27;医院设置添加&#x27;, icon: &#x27;tree&#x27; &#125; &#125; ] 创建跳转页面，设置跳转路径 123456789101112131415161718192021222324252627282930&lt;template&gt; &lt;div class=&quot;app-container&quot;&gt; 医院设置添加 &lt;el-form label-width=&quot;120px&quot;&gt; &lt;el-form-item label=&quot;医院名称&quot;&gt; &lt;el-input v-model=&quot;hospitalSet.hosname&quot;/&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;医院编号&quot;&gt; &lt;el-input v-model=&quot;hospitalSet.hoscode&quot;/&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;api基础路径&quot;&gt; &lt;el-input v-model=&quot;hospitalSet.apiUrl&quot;/&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;联系人姓名&quot;&gt; &lt;el-input v-model=&quot;hospitalSet.contactsName&quot;/&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;联系人手机&quot;&gt; &lt;el-input v-model=&quot;hospitalSet.contactsPhone&quot;/&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;saveOrUpdate&quot;&gt;保存&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/div&gt;&lt;/template&gt; 在api中创建js文件 123456789export default &#123; //医院设置列表 getHospSetList(current,limit,searchObj) &#123; return request (&#123; url: `/admin/hosp/hospitalSet/findPageHospSet/$&#123;current&#125;/$&#123;limit&#125;`, method: &#x27;post&#x27;, data: searchObj //使用json形式进行传递 &#125;) &#125; //引入接口定义的js文件 import hospset from &#39;@/api/hospset&#39; export default &#123; //定义变量和初始值 data() &#123; return &#123; current:1, //当前页 limit:3, //每页显示记录数 searchObj:&#123;&#125;, //条件封装对象 list:[], //每页数据集合 total:0, //总记录数 multipleSelection: [] // 批量选择中选择的记录列表 &#125; &#125;, created() &#123; //在页面渲染之前执行 //一般调用methods定义的方法，得到数据 this.getList() &#125;, methods: &#123;//定义方法，进行请求接口调用 //医院设置列表 getList(page=1) &#123; //添加当前页参数 this.current = page hospset.getHospSetList(this.current,this.limit,this.searchObj) .then(response =&gt; &#123; //请求成功 response是接口返回数据 //返回集合赋值list this.list = response.data.records //总记录数 this.total = response.data.total &#125;) .catch(error =&gt; &#123;//请求失败 console.log(error) &#125;) &#125; 1234567891011121314151617181920**跨域问题**：三个地方，任何一个不相同都会产生跨域问题1. 访问协议：http https2. 访问地址：192.168.1.1 172.11.1.13. 端口号：9528 8201**解决方案**：在controller中加上`@CrossOrigin`注解**分页操作**：```vue &lt;!-- 分页 --&gt; &lt;el-pagination :current-page=&quot;current&quot; :page-size=&quot;limit&quot; :total=&quot;total&quot; style=&quot;padding: 30px 0; text-align: center;&quot; layout=&quot;total, prev, pager, next, jumper&quot; @current-change=&quot;getList&quot;/&gt; 删除医院 1234567891011121314151617181920//删除医院设置的方法 removeDataById(id) &#123; this.$confirm(&#x27;此操作将永久删除医院是设置信息, 是否继续?&#x27;, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; &#123; //确定执行then方法 //调用接口 hospset.deleteHospSet(id) .then(response =&gt; &#123; //提示 this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;删除成功!&#x27; &#125;) //刷新页面 this.getList(this.current) &#125;) &#125;) &#125; 批量删除 123456789101112131415161718192021222324252627//批量删除 removeRows() &#123; this.$confirm(&#x27;此操作将永久删除医院是设置信息, 是否继续?&#x27;, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; &#123; //确定执行then方法 var idList = [] //遍历数组得到每个id值，设置到idList里面 for(var i=0;i&lt;this.multipleSelection.length;i++) &#123; var obj = this.multipleSelection[i] var id = obj.id idList.push(id) &#125; //调用接口 hospset.batchRemoveHospSet(idList) .then(response =&gt; &#123; //提示 this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;删除成功!&#x27; &#125;) //刷新页面 this.getList(this.current) &#125;) &#125;) &#125;, 判断用户是否点击选择：:disabled=&quot;multipleSelection.length === 0&quot; 选择其他页时，之前页选的的框依然存在：:reserve-selection=&quot;true&quot; 锁定 使用el-switch实现： 123&lt;el-switch v-model=&quot;scope.row.status&quot; :active-value=&quot;1&quot; :inactive-value=&quot;0&quot; active-color=&quot;#13ce66&quot; inactive-color=&quot;#ff4949&quot; @change=&quot;lockHostSet(scope.row.id,scope.row.status)&quot;&gt;&lt;/el-switch&gt; 1234567//锁定和取消锁定 lockHostSet(id,status) &#123; hospset.lockHospSet(id,status) .then(response =&gt; &#123; //刷新 this.getList(this.current) &#125;) &#125;, 添加医院设置 12345678910111213//添加 save() &#123; hospset.saveHospSet(this.hospitalSet) .then(response =&gt; &#123; //提示 this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;添加成功!&#x27; &#125;) //跳转列表页面，使用路由跳转方式实现 this.$router.push(&#123;path:&#x27;/hospSet/list&#x27;&#125;) &#125;) &#125;, 修改 隐藏路由： 1234567&#123; path: &#x27;edit/:id&#x27;, name: &#x27;EduTeacherEdit&#x27;, component: () =&gt;import(&#x27;@/views/hospset/add&#x27;), meta: &#123; title: &#x27;编辑&#x27;, noCache: true &#125;, hidden: true&#125;, 123&lt;router-link :to=&quot;&#x27;/hospSet/edit/&#x27;+scope.row.id&quot;&gt; &lt;el-button type=&quot;primary&quot; size=&quot;mini&quot; icon=&quot;el-icon-edit&quot; title=&quot;编辑&quot;&gt;&lt;/el-button&gt;&lt;/router-link&gt; 123456789//获取路由id值//调用接口得到医院设置信息if(this.$route.params &amp;&amp; this.$route.params.id) &#123; const id = this.$route.params.id this.getHostSet(id) &#125; else &#123; //表单数据清空 this.hospitalSet = &#123;&#125; &#125; 12345678910111213141516171819202122232425262728//根据id查询getHostSet(id) &#123; hospset.getHospSet(id) .then(response =&gt; &#123; this.hospitalSet = response.data &#125;)&#125;,//修改update() &#123; hospset.updateHospSet(this.hospitalSet) .then(response =&gt; &#123; //提示 this.$message(&#123; type: &#x27;success&#x27;, message: &#x27;修改成功!&#x27; &#125;) //跳转列表页面，使用路由跳转方式实现 this.$router.push(&#123;path:&#x27;/hospSet/list&#x27;&#125;) &#125;)&#125;,saveOrUpdate() &#123; //判断添加还是修改 if(!this.hospitalSet.id) &#123; //没有id，做添加 this.save(); &#125;else &#123;//修改 this.update() &#125;&#125; 组件重用问题 问题：vue-router导航切换时，如果两个路由都渲染同一个组件，组建的生命周期方法（created或者mounted）不会被再次调用，组件会被重用，显示上一个路由渲染出来的自建 解决方法：可以简单的在router-view上加一个唯一的key，来保证路由切换时都会重新触发生命周期方法，确保组件被重新初始化。 在src\\views\\layout\\components\\AppMain.vue中 1&lt;router-view :key=&quot;key&quot;&gt;&lt;/router-view&gt; 12345computed: &#123; key() &#123; return this.$route.name !== undefined ? this.$route.name + +new Date() : this.$route + +new Date() &#125;&#125;","tags":["工作","Java","项目","前端"],"categories":["Java技术","医院在线预约系统"]},{"title":"3.前端知识","path":"/2022/06/15/3.前端知识/","content":"一、VUE入门1. Vue入门案例 引入vue文件 编写vue代码 1234567891011121314&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;div id=&quot;app&quot;&gt; &lt;!--插值表达式--&gt; &#123;&#123;message&#125;&#125; &lt;/div&gt; &lt;script&gt; new Vue(&#123; el:&#x27;#app&#x27;, data:&#123; message:&#x27;hello vue&#x27; &#125; &#125;) &lt;/script&gt; 创建代码片段 1234567891011121314151617181920212223242526272829303132333435&#123; &quot;vue htm&quot;:&#123; &quot;scope&quot;: &quot;html&quot;, &quot;prefix&quot;: &quot;vuehtml&quot;, &quot;body&quot;: [ &quot;&lt;!DOCTYPE html&gt;&quot;, &quot;&lt;html lang=\\&quot;en\\&quot;&gt;&quot;, &quot;&quot;, &quot;&lt;head&gt;&quot;, &quot; &lt;meta charset=\\&quot;UTF-8\\&quot;&gt;&quot;, &quot; &lt;meta name=\\&quot;viewport\\&quot; content=\\&quot;width=device-width, initial-scale=1.0\\&quot;&gt;&quot;, &quot; &lt;meta http-equiv=\\&quot;X-UA-Compatible\\&quot; content=\\&quot;ie=edge\\&quot;&gt;&quot;, &quot; &lt;title&gt;Document&lt;/title&gt;&quot;, &quot;&lt;/head&gt;&quot;, &quot;&quot;, &quot;&lt;body&gt;&quot;, &quot; &lt;div id=\\&quot;app\\&quot;&gt;&quot;, &quot;&quot;, &quot; &lt;/div&gt;&quot;, &quot; &lt;script src=\\&quot;vue.min.js\\&quot;&gt;&lt;/script&gt;&quot;, &quot; &lt;script&gt;&quot;, &quot; new Vue(&#123;&quot;, &quot; el: &#x27;#app&#x27;,&quot;, &quot; data: &#123;&quot;, &quot; $1&quot;, &quot; &#125;&quot;, &quot; &#125;)&quot;, &quot; &lt;/script&gt;&quot;, &quot;&lt;/body&gt;&quot;, &quot;&quot;, &quot;&lt;/html&gt;&quot;, ], &quot;description&quot;: &quot;my vue template in html&quot; &#125;&#125; 2. 单向和双向绑定指令单向绑定基础语法：v-bind 指令用在标签属性上面，通过指令获取data中定义变量的值 123456789101112&lt;div id=&quot;app&quot;&gt; &lt;div v-bind:style=&quot;msg&quot;&gt;单向绑定&lt;/div&gt;&lt;/div&gt;&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; msg:&#x27;color:green;&#x27; &#125; &#125;)&lt;/script&gt; 双向绑定基础语法：v-model 12345678910111213141516&lt;div id=&quot;app&quot;&gt; &#123;&#123;keyword&#125;&#125; &lt;br&gt; &lt;input type=&quot;text&quot; :value=&quot;keyword&quot;&gt; &lt;br&gt; &lt;input type=&quot;text&quot; v-model=&quot;keyword&quot;&gt; &lt;/div&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; keyword:&#x27;张三&#x27; &#125; &#125;) &lt;/script&gt; 在双向绑定中值发生变化，会引起所有位置的keyword变化 3. 绑定事件基础语法：v-on：事件名称=&quot;调用方法&quot; 简写：@事件名称 1234567891011121314151617181920&lt;body&gt; &lt;div id=&quot;app&quot;&gt; &lt;button v-on:click=&quot;show()&quot;&gt;事件绑定&lt;/button&gt; &lt;button @click=&quot;show()&quot;&gt;事件绑定简写&lt;/button&gt; &lt;/div&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; &#125;, methods: &#123; show()&#123; console.log(&quot;show....&quot;) &#125; &#125; &#125;) &lt;/script&gt; 4. 条件指令基础语法：v-if v-else 123456789101112131415&lt;div id=&quot;app&quot;&gt; &lt;input type=&quot;checkbox&quot; v-model=&quot;ok&quot; &gt; &lt;br&gt; &lt;div v-if=&quot;ok&quot;&gt;选中了&lt;/div&gt; &lt;div v-else&gt;没有选中&lt;/div&gt; &lt;/div&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; ok: false &#125; &#125;) &lt;/script&gt; 5. 循环指令基础语法：v-for 1234567891011121314151617&lt;div id=&quot;app&quot;&gt; &lt;div v-for=&quot;(user,index) in userList&quot;&gt; &#123;&#123;index&#125;&#125; -- &#123;&#123;user.name&#125;&#125; -- &#123;&#123;user.age&#125;&#125; &lt;/div&gt; &lt;/div&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; userList:[ &#123;&quot;name&quot;:&quot;lucy&quot;,&quot;age&quot;:20&#125;, &#123;&quot;name&quot;:&quot;mary&quot;,&quot;age&quot;:30&#125; ] &#125; &#125;) &lt;/script&gt; 6. 生命周期created：在页面渲染之前执行 mounted：在页面渲染之后执行 1234567891011121314151617181920&lt;div id=&quot;app&quot;&gt; &#123;&#123;msg&#125;&#125; &lt;/div&gt; &lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; msg: &quot;hello&quot; &#125;, created()&#123; debugger console.log(&#x27;在页面渲染之前执行&#x27;) &#125;, mounted()&#123; debugger console.log(&#x27;在页面渲染之后执行&#x27;) &#125; &#125;) &lt;/script&gt; 二、Axois 在html页面中引入axios的js文件，也包含vue的js文件 编写具体代码 123456789101112131415161718192021222324252627282930313233343536 &lt;div id=&quot;app&quot;&gt; &lt;table&gt; &lt;tr v-for=&quot;user in userList&quot;&gt; &lt;td&gt;&#123;&#123;user.name&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;user.age&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;axios.js&quot;&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: &#x27;#app&#x27;, data: &#123; userList:[] &#125;, created()&#123; //调用方法，得到返回的json数据 this.getList() &#125;, methods:&#123; getList()&#123; //使用axios方式请求ajax axios.get(&quot;user.json&quot;) .then(response =&gt; &#123; //请求成功 //console.log(response) this.userList = response.data.data.items console.log(this.userList) &#125;) .catch(error =&gt; &#123; //请求失败 console.log(error) &#125;) &#125; &#125; &#125;)&lt;/script&gt; 三、Node.js是一个基于Chrome V8引擎的JavaScript运行环境：即Node.js内置了Chrome的V8引擎，可以在Node.js环境中直接运行JavaScript程序。 查看是否安装成功，在cmd中输入node -v 12345678910111213//引入http模块const http = require(&#x27;http&#x27;);//创建服务器http.createServer(function(request, response)&#123; //发送http头部 //http状态值：200 ：OK //内容类型：text/plain response.writeHead(200,&#123;&#x27;Content-Type&#x27;:&#x27;text/html&#x27;&#125;) //发送响应数据&quot;hello world&quot; response.end(&#x27;&lt;h1&gt;Hello Node.js Server&lt;/h1&gt;&#x27;);&#125;).listen(8888);//终端打印如下信息console.log(&#x27;Server running at http://127.0.0.1:8888/&#x27;); 四、NPM包管理器常用命令： npm init：初始化，生成package.json文件 npm init -y：初始化都使用默认的值 npm config set registry https://registry.npm.taobao.org：修改淘宝镜像 npm config list：查看npm配置信息 npm install 依赖名称，或者指定下载版本npm install 依赖名称@x.x.x 根据配置文件下载依赖：直接使用npm install 五、webpack可以将多种静态资源文件转换成一个静态资源文件，减少了页面请求 安装webpack，npm install -g webpack webpack-cli 创建js文件 1234//01.jsexports.info=function(str)&#123; document.write(str)&#125; 1234//02.jsexports.add=function(a,b)&#123; return a+b;&#125; 12345//main.jsconst a = require(&#x27;./01.js&#x27;)const b = require(&#x27;./02.js&#x27;)a.info(&#x27;hello a&#x27;+b.add(1,2)) 创建配置文件webpack.config.js 12345678const path = require(&quot;path&quot;) //node.js内置模块module.exports=&#123; entry: &#x27;./main.js&#x27;, //配置文件入口 output:&#123; path: path.resolve(__dirname,&#x27;./dist&#x27;), //输出路径 filename: &#x27;bundle.js&#x27; //输出文件 &#125;&#125; 使用命令打包webpack --mode=development","tags":["工作","Java","项目","前端"],"categories":["Java技术","医院在线预约系统"]},{"title":"2.医院设置接口","path":"/2022/06/13/2.医院设置接口/","content":"一、医院设置需求1、需求医院设置主要是用来保存开通医院的一些基本信息，每个医院一条信息，保存了医院编号（平台分配，全局唯一）和接口调用相关的签名key等信息，是整个流程的第一步，只有开通了医院设置信息，才可以上传医院相关信息。 我们所开发的功能就是基于单表的一个CRUD、锁定&#x2F;解锁和发送签名信息这些基本功能。 2、表结构创建hospital_set表 123456789101112131415CREATE TABLE `hospital_set` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;编号&#x27;, `hosname` varchar(100) DEFAULT NULL COMMENT &#x27;医院名称&#x27;, `hoscode` varchar(30) DEFAULT NULL COMMENT &#x27;医院编号&#x27;, `api_url` varchar(100) DEFAULT NULL COMMENT &#x27;api基础路径&#x27;, `sign_key` varchar(50) DEFAULT NULL COMMENT &#x27;签名秘钥&#x27;, `contacts_name` varchar(20) DEFAULT NULL COMMENT &#x27;联系人&#x27;, `contacts_phone` varchar(11) DEFAULT NULL COMMENT &#x27;联系人手机&#x27;, `status` tinyint(3) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;状态&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;, `is_deleted` tinyint(3) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;逻辑删除(1:已删除，0:未删除)&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `uk_hoscode` (`hoscode`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COMMENT=&#x27;医院设置表&#x27;; 二、医院模块开发1、搭建医院模块service_hospital修改pom.xml 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;artifactId&gt;service_hospital&lt;/artifactId&gt; &lt;name&gt;service-hosp&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;artifactId&gt;model&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;service-hosp&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 添加配置文件application.properties 123456789101112131415161718#服务端口server.port=8201#服务名spring.application.name=service-hosp#环境设置spring.profiles.active=dev#mysql数据库连接spring.datasource.url=jdbc:mysql://localhost:3306/ar_hospital?useSSL=falsespring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver#返回json的全局时间格式spring.jackson.time-zone=GMT+8spring.jackson.date-format=yyyy-MM-dd HH:mm:ss 添加启动类 123456789import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ServiceHospApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceHospApplication.class,args); &#125;&#125; 2、添加医院设置CRUD在model中添加实体类 添加Mapper 123456import com.CPG.ar.entity.hosp.HospitalSet;import com.baomidou.mybatisplus.core.mapper.BaseMapper;public interface HospitalSetMapper extends BaseMapper&lt;HospitalSet&gt; &#123; &#125; xml 12345&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.CPG.ar.hosp.mapper.HospitalSetMapper&quot;&gt;&lt;/mapper&gt; 添加service接口及实现类 接口 123456import com.CPG.ar.entity.hosp.HospitalSet;import com.baomidou.mybatisplus.extension.service.IService;public interface HospitalSetService extends IService&lt;HospitalSet&gt; &#123;&#125; 实现类 12345678910import com.CPG.ar.entity.hosp.HospitalSet;import com.CPG.ar.hosp.mapper.HospitalSetMapper;import com.CPG.ar.hosp.service.HospitalSetService;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import org.springframework.stereotype.Service;@Servicepublic class HospitalSetServiceImpl extends ServiceImpl&lt;HospitalSetMapper, HospitalSet&gt; implements HospitalSetService &#123; &#125; 添加controller 123456789101112131415161718192021222324252627282930import com.CPG.ar.entity.hosp.HospitalSet;import com.CPG.ar.hosp.service.HospitalSetService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;@RestController@RequestMapping(&quot;/admin/hosp/hospitalSet&quot;)public class HospitalSetController &#123; //注入service @Autowired private HospitalSetService hospitalSetService; //1 查询医院设置表里的所有信息 @GetMapping(&quot;findAll&quot;) public List&lt;HospitalSet&gt; findAllHospitalSet()&#123; //调用service中的方法 List&lt;HospitalSet&gt; list = hospitalSetService.list(); return list; &#125; //2 逻辑删除医院设置 @DeleteMapping(&quot;&#123;id&#125;&quot;) public boolean removeHospital(@PathVariable Long id)&#123; boolean flag = hospitalSetService.removeById(id); return flag; &#125;&#125; 3、swagger2集成项目整合swagger2 在common模块pom.xml中引入依赖 123456789&lt;!--swagger--&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;&lt;/dependency&gt; 说明：我们在父工程中的pom.xml中添加了版本控制，这里不需要添加版本，已引入就忽略 问题：报错Failed to start bean &#39;documentationPluginsBootstrapper&#39;; nested exception is java.lang.NullPointerException 原因： 这是因为Springfox使用的路径匹配是基于AntPathMatcher的，而Spring Boot 2.6.X使用的是PathPatternMatcher。解决：在application.properties里配置：spring.mvc.pathmatch.matching-strategy&#x3D;ANT_PATH_MATCHER。 添加swagger2配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Swagger2配置信息 */@Configuration@EnableSwagger2public class Swagger2Config &#123; @Bean public Docket webApiConfig()&#123; return new Docket(DocumentationType.SWAGGER_2) .groupName(&quot;webApi&quot;) .apiInfo(webApiInfo()) .select() //过滤掉admin路径下的所有页面 .paths(Predicates.and(PathSelectors.regex(&quot;/api/.*&quot;))) //过滤掉所有error或error.*页面 //.paths(Predicates.not(PathSelectors.regex(&quot;/error.*&quot;))) .build(); &#125; @Bean public Docket adminApiConfig()&#123; return new Docket(DocumentationType.SWAGGER_2) .groupName(&quot;adminApi&quot;) .apiInfo(adminApiInfo()) .select() .paths(Predicates.and(PathSelectors.regex(&quot;/admin/.*&quot;))) .build(); &#125; private ApiInfo webApiInfo()&#123; return new ApiInfoBuilder() .title(&quot;网站-API文档&quot;) .description(&quot;本文档描述了网站微服务接口定义&quot;) .version(&quot;1.0&quot;) .contact(new Contact(&quot;CPG&quot;, &quot;https://github.com/Cccccpg&quot;, &quot;1368921075@qq.com&quot;)) .build(); &#125; private ApiInfo adminApiInfo()&#123; return new ApiInfoBuilder() .title(&quot;后台管理系统-API文档&quot;) .description(&quot;本文档描述了后台管理系统微服务接口定义&quot;) .version(&quot;1.0&quot;) .contact(new Contact(&quot;CPG&quot;, &quot;https://github.com/Cccccpg&quot;, &quot;1368921075@qq.com&quot;)) .build(); &#125;&#125; 在主启动类中加入扫描 1234567@SpringBootApplication@ComponentScan(basePackages = &quot;com.CPG&quot;)public class ServiceHospApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceHospApplication.class,args); &#125;&#125; 使用统一返回类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 全局统一返回结果类 */@Data@ApiModel(value = &quot;全局统一返回结果&quot;)public class Result&lt;T&gt; &#123; @ApiModelProperty(value = &quot;返回码&quot;) private Integer code; @ApiModelProperty(value = &quot;返回消息&quot;) private String message; @ApiModelProperty(value = &quot;返回数据&quot;) private T data; public Result()&#123;&#125; public static &lt;T&gt; Result&lt;T&gt; build(T data) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); if (data != null) result.setData(data); return result; &#125; public static &lt;T&gt; Result&lt;T&gt; build(T body, ResultCodeEnum resultCodeEnum) &#123; Result&lt;T&gt; result = build(body); result.setCode(resultCodeEnum.getCode()); result.setMessage(resultCodeEnum.getMessage()); return result; &#125; public static&lt;T&gt; Result&lt;T&gt; ok()&#123; return Result.ok(null); &#125; /** * 操作成功 * @param data * @param &lt;T&gt; * @return */ public static&lt;T&gt; Result&lt;T&gt; ok(T data)&#123; Result&lt;T&gt; result = build(data); return build(data, ResultCodeEnum.SUCCESS); &#125; public static&lt;T&gt; Result&lt;T&gt; fail()&#123; return Result.fail(null); &#125; /** * 操作失败 * @param data * @param &lt;T&gt; * @return */ public static&lt;T&gt; Result&lt;T&gt; fail(T data)&#123; Result&lt;T&gt; result = build(data); return build(data, ResultCodeEnum.FAIL); &#125; public Result&lt;T&gt; message(String msg)&#123; this.setMessage(msg); return this; &#125; public Result&lt;T&gt; code(Integer code)&#123; this.setCode(code); return this; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 统一返回结果状态信息类 */@Getterpublic enum ResultCodeEnum &#123; SUCCESS(200,&quot;成功&quot;), FAIL(201, &quot;失败&quot;), PARAM_ERROR( 202, &quot;参数不正确&quot;), SERVICE_ERROR(203, &quot;服务异常&quot;), DATA_ERROR(204, &quot;数据异常&quot;), DATA_UPDATE_ERROR(205, &quot;数据版本异常&quot;), LOGIN_AUTH(208, &quot;未登陆&quot;), PERMISSION(209, &quot;没有权限&quot;), CODE_ERROR(210, &quot;验证码错误&quot;), // LOGIN_MOBLE_ERROR(211, &quot;账号不正确&quot;), LOGIN_DISABLED_ERROR(212, &quot;改用户已被禁用&quot;), REGISTER_MOBLE_ERROR(213, &quot;手机号已被使用&quot;), LOGIN_AURH(214, &quot;需要登录&quot;), LOGIN_ACL(215, &quot;没有权限&quot;), URL_ENCODE_ERROR( 216, &quot;URL编码失败&quot;), ILLEGAL_CALLBACK_REQUEST_ERROR( 217, &quot;非法回调请求&quot;), FETCH_ACCESSTOKEN_FAILD( 218, &quot;获取accessToken失败&quot;), FETCH_USERINFO_ERROR( 219, &quot;获取用户信息失败&quot;), //LOGIN_ERROR( 23005, &quot;登录失败&quot;), PAY_RUN(220, &quot;支付中&quot;), CANCEL_ORDER_FAIL(225, &quot;取消订单失败&quot;), CANCEL_ORDER_NO(225, &quot;不能取消预约&quot;), HOSCODE_EXIST(230, &quot;医院编号已经存在&quot;), NUMBER_NO(240, &quot;可预约号不足&quot;), TIME_NO(250, &quot;当前时间不可以预约&quot;), SIGN_ERROR(300, &quot;签名错误&quot;), HOSPITAL_OPEN(310, &quot;医院未开通，暂时不能访问&quot;), HOSPITAL_LOCK(320, &quot;医院被锁定，暂时不能访问&quot;), ; private Integer code; private String message; private ResultCodeEnum(Integer code, String message) &#123; this.code = code; this.message = message; &#125;&#125; 改造controller 123456789101112131415161718192021222324252627282930@Api(tags = &quot;医院设置管理&quot;)@RestController@RequestMapping(&quot;/admin/hosp/hospitalSet&quot;)public class HospitalSetController &#123; //注入service @Autowired private HospitalSetService hospitalSetService; //1 查询医院设置表里的所有信息 @ApiOperation(value = &quot;获取所有医院设置&quot;) @GetMapping(&quot;findAll&quot;) public Result findAllHospitalSet()&#123; //调用service中的方法 List&lt;HospitalSet&gt; list = hospitalSetService.list(); return Result.ok(list); &#125; //2 逻辑删除医院设置 @ApiOperation(value = &quot;逻辑删除医院设置信息&quot;) @DeleteMapping(&quot;&#123;id&#125;&quot;) public Result removeHospital(@PathVariable Long id)&#123; boolean flag = hospitalSetService.removeById(id); if (flag)&#123; return Result.ok(); &#125;else&#123; return Result.fail(); &#125; &#125;&#125; 4、分页条件查询 创建vo类，封装条件值 编写controller，获取条件对象，分页数据 123456789101112131415161718192021222324//3 条件查询带分页@PostMapping(&quot;findPageHospSet/&#123;current&#125;/&#123;limit&#125;&quot;)public Result findPageHospSet(@PathVariable long current, @PathVariable long limit, @RequestBody(required = false) HospitalQueryVo hospitalQueryVo)&#123; //创建page对象，传递当前页，每页记录数 Page&lt;HospitalSet&gt; page = new Page&lt;&gt;(current, limit); //构造条件 QueryWrapper&lt;HospitalSet&gt; wrapper = new QueryWrapper&lt;&gt;(); //医院名称 String hosname = hospitalQueryVo.getHosname(); //医院编号 String hoscode = hospitalQueryVo.getHoscode(); if (StringUtils.hasLength(hosname))&#123; wrapper.like(&quot;hosname&quot;,hospitalQueryVo.getHosname()); &#125; if (StringUtils.hasLength(hoscode))&#123; wrapper.eq(&quot;hoscode&quot;,hospitalQueryVo.getHoscode()); &#125; //调用方法实现分页查询 Page&lt;HospitalSet&gt; pageHostpitalSet = hospitalSetService.page(page, wrapper); //返回结果 return Result.ok(pageHostpitalSet);&#125; 注意：StringUtils中的isEmpty( )方法已经被弃用了，建议使用hasLength( )。 @RequestBody(required = false)：用json形式传递数据，其中required &#x3D; false表示，这个值可以为空 5、添加医院设置123456789101112//4 添加医院设置@PostMapping(&quot;saveHospitalSet&quot;)public Result saveHospitalSet(@RequestBody HospitalSet hospitalSet)&#123; //设置状态 1：可以使用 0：不能使用 hospitalSet.setStatus(1); //签名秘钥 Random random = new Random(); hospitalSet.setSignKey(MD5.encrypt(System.currentTimeMillis()+&quot;&quot;+random.nextInt(1000))); //调用service boolean save = hospitalSetService.save(hospitalSet); return save?Result.ok():Result.fail();&#125; 6、根据ID获取、修改、批量删除 根据id获取医院设置 12345@GetMapping(&quot;getHospitalSet/&#123;id&#125;&quot;)public Result getHospitalSet(@PathVariable long id)&#123; HospitalSet hospitalSet = hospitalSetService.getById(id); return Result.ok(hospitalSet);&#125; 修改医院设置 123456//6 修改医院设置@PostMapping(&quot;updateHospitalSet&quot;)public Result updateHospitalSet(@RequestBody HospitalSet hospitalSet)&#123; boolean flag = hospitalSetService.updateById(hospitalSet); return flag?Result.ok():Result.fail();&#125; 批量删除医院设置 123456//7 批量删除医院设置@DeleteMapping(&quot;batchRemove&quot;)public Result batchRemoveHospitalSet(@RequestBody List&lt;Long&gt; idList)&#123; hospitalSetService.removeByIds(idList); return Result.ok();&#125; 7、锁定解锁、发送秘钥1234567891011121314151617181920212223//8 医院设置锁定和解锁@PutMapping(&quot;lockHospitalSet/&#123;id&#125;/&#123;status&#125;&quot;)public Result lockHospitalSet(@PathVariable long id, @PathVariable Integer status)&#123; //根据id查询出医院设置的信息 HospitalSet hospitalSet = hospitalSetService.getById(id); //设置医院状态 hospitalSet.setStatus(status); //调用方法 hospitalSetService.updateById(hospitalSet); return Result.ok();&#125;//9 发送签名秘钥@PutMapping(&quot;sendKey/&#123;id&#125;&quot;)public Result sendKeyHospitalSet(@PathVariable long id)&#123; HospitalSet hospitalSet = hospitalSetService.getById(id); String signKey = hospitalSet.getSignKey(); String hoscode = hospitalSet.getHoscode(); String hosname = hospitalSet.getHosname(); //TODO 发送短信 return Result.ok();&#125; 8、全局异常处理1234567891011121314151617@RestControllerAdvicepublic class GlobalExceptionHandler &#123; //全局异常处理 @ExceptionHandler(Exception.class) public Result error(Exception e)&#123; e.printStackTrace(); return Result.fail(); &#125; //自定义异常处理 @ExceptionHandler(AppointmentRegisterException.class) public Result error(AppointmentRegisterException e)&#123; e.printStackTrace(); return Result.fail(); &#125;&#125; 异常： 1234567891011//5 根据id获取医院设置@GetMapping(&quot;getHospitalSet/&#123;id&#125;&quot;)public Result getHospitalSet(@PathVariable long id)&#123; try&#123; int i = 1/0; &#125;catch (Exception e)&#123; throw new AppointmentRegisterException(&quot;失败&quot;,201); &#125; HospitalSet hospitalSet = hospitalSetService.getById(id); return Result.ok(hospitalSet);&#125; 9、日志日志记录器（Logger）的行为是分等级的。如下表所示： 分为：OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL 默认情况下，spring boot从控制台打印出来的日志级别只有INFO及以上级别，可以配置日志级别 application.properties 12# 设置日志级别logging.level.root=WARN 这种方式只能将日志打印在控制台上 Logback日志pring boot内部使用Logback作为日志实现的框架。 Logback和log4j非常相似，如果你对log4j很熟悉，那对logback很快就会得心应手。 配置日志resources/logback-spring.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;10 seconds&quot;&gt; &lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt; &lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt; &lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt; &lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“$&#123;&#125;”来使用变量。 --&gt; &lt;property name=&quot;log.path&quot; value=&quot;D:/Study/edu&quot; /&gt; &lt;!-- 彩色日志 --&gt; &lt;!-- 配置格式变量：CONSOLE_LOG_PATTERN 彩色日志格式 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;!-- boldMagenta:粗红--&gt; &lt;!-- cyan:青色 --&gt; &lt;!-- white:白色 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;%yellow(%date&#123;yyyy-MM-dd HH:mm:ss&#125;) |%highlight(%-5level) |%blue(%thread) |%blue(%file:%line) |%green(%logger) |%cyan(%msg%n)&quot;/&gt; &lt;!--输出到控制台--&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;!-- 例如：如果此处配置了INFO级别，则后面其他位置即使配置了DEBUG级别的日志，也不会被输出 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到文件--&gt; &lt;!-- 时间滚动输出 level为 INFO 日志 --&gt; &lt;appender name=&quot;INFO_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/info/log-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录info级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 WARN 日志 --&gt; &lt;appender name=&quot;WARN_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/warn/log-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录warn级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 ERROR 日志 --&gt; &lt;appender name=&quot;ERROR_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/error/log-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、以及指定&lt;appender&gt;。 &lt;logger&gt;仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 如果未设置此属性，那么当前logger将会继承上级的级别。 --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把&lt;root level=&quot;INFO&quot;&gt;改成&lt;root level=&quot;DEBUG&quot;&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给mapper下目录配置DEBUG模式，代码如下，这样配置sql语句会打印，其他还是正常DEBUG级别： --&gt; &lt;!--开发环境:打印控制台--&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;!--可以输出项目中的debug日志，包括mybatis的sql日志--&gt; &lt;logger name=&quot;com.guli&quot; level=&quot;INFO&quot; /&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，默认是DEBUG 可以包含零个或多个appender元素。 --&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt; &lt;appender-ref ref=&quot;INFO_FILE&quot; /&gt; &lt;appender-ref ref=&quot;WARN_FILE&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;!--生产环境:输出到文件--&gt; &lt;springProfile name=&quot;pro&quot;&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt; &lt;appender-ref ref=&quot;DEBUG_FILE&quot; /&gt; &lt;appender-ref ref=&quot;INFO_FILE&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;appender-ref ref=&quot;WARN_FILE&quot; /&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt;","tags":["工作","Java","项目"],"categories":["Java技术","医院在线预约系统"]},{"title":"1.搭建后台环境","path":"/2022/06/13/1.搭建后台环境/","content":"1.构建父工程（AppointmentRegister_parent）1. 配置父工程的pom123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;modules&gt; &lt;module&gt;common&lt;/module&gt; &lt;module&gt;common_util&lt;/module&gt; &lt;module&gt;service_util&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;artifactId&gt;appointmentregister_parent&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;appointmentregister_parent&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;cloud.version&gt;Hoxton.RELEASE&lt;/cloud.version&gt; &lt;alibaba.version&gt;2.2.0.RELEASE&lt;/alibaba.version&gt; &lt;mybatis-plus.version&gt;3.3.1&lt;/mybatis-plus.version&gt; &lt;mysql.version&gt;5.1.46&lt;/mysql.version&gt; &lt;swagger.version&gt;2.7.0&lt;/swagger.version&gt; &lt;jwt.version&gt;0.7.0&lt;/jwt.version&gt; &lt;fastjson.version&gt;1.2.29&lt;/fastjson.version&gt; &lt;httpclient.version&gt;4.5.1&lt;/httpclient.version&gt; &lt;easyexcel.version&gt;2.2.0-beta2&lt;/easyexcel.version&gt; &lt;aliyun.version&gt;4.1.1&lt;/aliyun.version&gt; &lt;oss.version&gt;3.9.1&lt;/oss.version&gt; &lt;jodatime.version&gt;2.10.1&lt;/jodatime.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mybatis-plus 持久层--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger ui--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;$&#123;jwt.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;$&#123;httpclient.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;$&#123;fastjson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;$&#123;easyexcel.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;$&#123;aliyun.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;version&gt;$&#123;oss.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--日期时间工具--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;$&#123;jodatime.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2. 搭建common父模块common：公共模块父节点 common-util：工具类模块，所有模块都可以依赖于它 service-util：service服务的工具包，包含service服务的公共配置类，所有 service模块依赖于它 3.1 common的pom1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;appointmentregister_parent&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;common_util&lt;/module&gt; &lt;module&gt;service_util&lt;/module&gt; &lt;/modules&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;!--lombok用来简化实体类：需要安装lombok插件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3.2 common_util的pom123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;common_util&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日期工具栏依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3.3 service_util的pom1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;service_util&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;artifactId&gt;common_util&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring2.X集成redis所需common-pool2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 3. 搭建model模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;appointmentregister_parent&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;model&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;scope&gt;provided &lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 4.搭建service模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;appointmentregister_parent&lt;/artifactId&gt; &lt;groupId&gt;com.CPG&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--开发者工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- 服务调用feign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 服务注册 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 流量控制 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt;","tags":["工作","Java","项目"],"categories":["Java技术","医院在线预约系统"]},{"title":"Redis","path":"/2022/04/22/Redis/","content":"Redis1. NoSQL介绍NoSQL泛指非关系型数据库。它不依赖一无逻辑方式存储，而是以简单的key-value模式存储。大大增加了数据库的扩展能力。 特点： 不遵循SQL标准。 不支持ACID（原子性、一致性、隔离性、持久性）。 远超于SQL的性能。 适用于： 对数据高并发读写。 海量数据的读写。 对数据高可扩展性。 不适用于： 需要事务支持。 基于SQL的结构化存储，处理复杂的关系。 用不着SQL的和用了SQL也不行的情况，请考虑用NoSQL。 MongoDB： 高性能、开源、模式自由(schema free)的文档型数据库 数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘 虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能 支持二进制数据及大型对象 可以根据数据的特点替代RDBMS ，成为独立的数据库。或者配合RDBMS，存储特定的数据。 2. Redis安装用docker进行安装配置 docker pull redis:6.2.6 启动redis： docker start redis docker exec -it redis redis-cli 关闭redis：shutdown 切换数据库：select 12 所有的数据库密码都相同 3. 常用五大数据类型3.1 Redis键（key）key值的操作： keys *查看当前库中所有key set key value 设置key值与value exists key 判断key是否存在，存在返回1，不存在返回0 type key 查看key是什么类型 del key 删除指定的key数据 unlink key 根据value选择非阻塞删除，仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作 expire key 10 10秒钟：为给定的key设置过期时间 ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期 库的选择： select 命令切换数据库 dbsize 查看当前数据库的key数量 flushdb 清空当前库 flushall 通杀全部库 3.2 String字符串 一个key对应一个value 二进制安全的，即可包含任何数据 value最多可以是512m 参数设置： set key value 设置key值，当设置的值存在时，新设置的值会把原来的值覆盖掉 get key 查询key值 append key value 将给定的value追加到原值末尾 strlen key 获取值的长度 setnx key value 只有在key不存在的时候，设置key值，若设置的值存在，则不做任何事 incr key 将key值存储的数字增1，只对数字值操作，如果为空，新增值为1 decr key 将key值存储的数字减1，只对数字值操作，如果为空，新增值为1 incrby/decrby key &lt;步长&gt; 将key值存储的数字增减如步长 原子操作：是指不会被线程调度机制打断的操作 这种操作一旦开始，就会一直运行到结束，中间不会有任何context switch（切换到另一个线程）。 Redis单命令的原子性主要得益于Redis的单线程 问题：Java中的i++是否是原子操作？ 答：不是 问题：i&#x3D;0，两个线程分别对i进行++100次，i值最后等于多少？ 答：2~200 补充额外的字符串参数： mset key value key value..同时设置一个或者多个key-value mget key key...同时获取一个或多个value msetnx key value key value..同时设置一个或者多个key-value，当且仅当所有给定key都不存在 getrange key &lt;起始位置&gt; &lt;结束位置&gt; 获取key的起始位置和结束位置的值，类似于java中的substring setrange key &lt;起始位置&gt; value 将value的值覆盖起始位置开始 setex key &lt;&gt; value 设置键值的同时,设置过期时间 getset key value 用新值换旧值 3.3 List列表Redis列表是简单的字符串列表，按照插入顺序排序。 其底层其实是一个双向列表，对两端的操作性能很高，通过索引下标的操作中间的节点西能会较差。 lpush/rpush key value value...从左或者右插入一个或者多个值(头插与尾插) lpop/rpop key 从左或者右吐出一个或者多个值(值在键在，值没键没) rpoplpush key1 key2 从key1列表右边吐出一个值,插入到key2的左边 lrange key start stop 按照索引下标获取元素(从左到右) lrange key 0 -1 获取所有值 lindex key index 按照索引下标获得元素 llen key 获取列表长度 linsert key before/after value newvalue 在value的后面&#x2F;前面插入一个新值 lrem key n value 从左边删除n个value值 lset key index value 在列表key中的下标index中修改值value List的数据结构为快速链表quickList 在列表元素较少的情况下会使用一块连续的内存存储，这个结构式ziplist，也即压缩列表。 但数据量比较多时才会改成quicklist。 3.4 Set集合Set是可以自动排重的，并且是无序的 Redis的Set是String类型的无需集合。它的底层其实是一个value为null的hash表，所以添加、删除、查找的时间复杂度都是O(1)。 sadd key value value... 将一个或者多个member元素加入集合key中,已经存在的member元素被忽略 smembers key 取出该集合的所有值 sismember key value 判断该集合key是否存在该值 scard key 返回该集合的元素个数 srem key value value 删除集合中的某个元素 spop key 随机从集合中取出一个元素，会从集合中删除该值 srandmember key n 随即从该集合中取出n个值，不会从集合中删除 smove &lt;一个集合a&gt;&lt;一个集合b&gt;value 将一个集合a的某个value移动到另一个集合b sinter key1 key2 返回两个集合的交集元素 sunion key1 key2 返回两个集合的并集元素 sdiff key1 key2 返回两个集合的差集元素（key1有的，key2没有） Set数据结构是dict字典，字典是用哈希表实现的。 Java中的HashSet的内部实现使用的就是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它内部也是用hash结构，所有的value都指向同一个内部值。 3.5 Hash哈希Redis中的Hash是一个键值对集合。 它是一个String类型的field和value的映射表，hash特别适合用于存储对象。 类似Java中的Map&lt;String，Object&gt; hset key field value 给key集合中的filed键赋值value hget key1 field 集合field取出value hmset key1 field1 value1 field2 value2 批量设置hash的值 hexists key1 field 查看哈希表key中，给定域field是否存在 hkeys key 列出该hash集合的所有field hvals key 列出该hash集合的所有value hincrby key field increment 为哈希表key中的域field的值加上增量1 -1 hsetnx key field value 将哈希表key中的域field的值设置为value，当且仅当域field不存在 Hash类型对应的数据结构有两种：ziplist、hashtable。当field-value的长度较短且个数较少时，使用ziplist，否则使用hashtable。 3.6 Zset有序集合Redis有序集合Zset与普通集合set非常相似，是一个没有重复元素的字符串集合。 不同之处是有序集合的每个成员都关联了一个评分（score），这个评分被用来按照从最低到最高的方式来排序。集合中的成员是唯一的，但是评分是可以重复的。 zadd key score1 value1 score2 value2 将一个或多个member元素及其score值加入到有序key中 zrange key start stop (withscores) 返回有序集key，下标在start与stop之间的元素，带withscores，可以让分数一起和值返回到结果集。 zrangebyscore key min max(withscores) 返回有序集key，所有score值介于min和max之间（包括等于min或max）的成员。有序集成员按score的值递增次序排列 zrevrangebyscore key max min （withscores）同上，改为从大到小排列 zincrby key increment value 为元素的score加上增量 zrem key value 删除该集合下，指定值的元素 zcount key min max 统计该集合，分数区间内的元素个数 zrank key value 返回该值在集合中的排名，从0开始 zset底层使用了两个数据结构 hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score。 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。 4. 配置文件详解默认情况bind 127.0.0.1只支持本地连接，可以注释掉。 protected-mode no可以进行远程访问。 timeout 0表示永不超时，以秒为单位。 tcp-keepalive 300每隔300s检测一次是否还在操作，如果300秒都没操作，就释放连接。 daemonize yes设置后台启动 pidfile保存进程号的路径 设置密码 在redis.conf文件中加入requirepass foobared 使用命令行config get requirepass,config set requirepass &quot;123456&quot; 设置之后每次一输入redis-cli进入的时候都要输入 密码才能访问。 5. Redis发布和订阅Redis发布订阅是一种消息通信模式，redis客户端可以订阅任意数量的频道。 6. 新数据类型6.1 Bitmaps 合理使用操作位可以有效提高内存使用率和开发使用率。 本身是一个字符串，不是数据类型，数组的每个单元只能放01，数组下标在Bitmaps叫做偏移量。 节省空间，一般存储活跃用户比较多。 setbit key offset value 设置值 getbit key offset取出值 bitcount key统计字符串中比特值为1的数量 bitop and(or/not/xor) destkey key符合操作，交并非异或，结果保存在destkey 6.2 HyperLogLog 统计网页中页面访问量 只会根据输入元素来计算基数，而不会存储输入元素本身，不能像集合那样，返回输入的各个元素 基数估计是在误差可接受的范围内，快速计算 pfadd key element 添加指定元素到hyperloglog中，成功则返回1，不成功返回0 pfcount key 计算key的近似基数 pfmerge destkey sourcekey sourcekey 一个或多个key合并后的结果存在destkey中 6.3 Geographic提供经纬度设置，查询范围，距离查询等 geoadd key longitude latitude member 添加地理位置 geopos key member 获取指定地区的坐标值 geodist key member1 member2 (m km ft英尺 mi英里) 获取两个位置之间的直线距离 georadius key longitude latitude radius (m km ft mi) 以给定的经纬度为中心，找出另一半径的内元素 7. Jedis操作通过java操作redis 创建maven工程，引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.7.1&lt;/version&gt;&lt;/dependency&gt; 创建jedis类 1234567891011public class JedisDemo1 &#123; public static void main(String[] args) &#123; //创建jedis对象 Jedis jedis = new Jedis(&quot;192.168.134.134&quot;,6379); //测试 String ping = jedis.ping(); System.out.println(ping); &#125;&#125; 可能出现的问题解决方法： 关闭linux的防火墙 在redis.conf配置文件中注释掉bind 设置保护模式为no 7.1 类型测试测试key 1234567891011121314@Testpublic void TestKey()&#123; //创建jedis对象 Jedis jedis = new Jedis(&quot;192.168.134.134&quot;,6379); //添加 jedis.set(&quot;name&quot;,&quot;lucy&quot;); //获取 String name = jedis.get(&quot;name&quot;); System.out.println(name); Set&lt;String&gt; keys = jedis.keys(&quot;*&quot;); for (String key : keys) &#123; System.out.println(key); &#125;&#125; 测试String 12345678@Testpublic void TestString()&#123; Jedis jedis = new Jedis(&quot;192.168.134.134&quot;,6379); //设置多个key-value jedis.mset(&quot;k1&quot;,&quot;v1&quot;,&quot;k2&quot;,&quot;v2&quot;); List&lt;String&gt; mget = jedis.mget(&quot;k1&quot;, &quot;k2&quot;); System.out.println(mget);&#125; 测试List 123456@Testpublic void TestList()&#123; jedis.lpush(&quot;key1&quot;,&quot;lucy&quot;,&quot;marry&quot;,&quot;jack&quot;); List&lt;String&gt; key1 = jedis.lrange(&quot;key1&quot;, 0, -1); System.out.println(key1);&#125; 测试Set 123456@Testpublic void TestSet()&#123; jedis.sadd(&quot;username&quot;,&quot;lucy&quot;,&quot;jack&quot;); Set&lt;String&gt; name = jedis.smembers(&quot;username&quot;); System.out.println(name);&#125; 测试Hash 123456@Testpublic void TestHash()&#123; jedis.hset(&quot;users&quot;,&quot;age&quot;,&quot;20&quot;); String hget = jedis.hget(&quot;users&quot;, &quot;age&quot;); System.out.println(hget);&#125; 测试Zset 12345@Testpublic void TestZset()&#123; jedis.zadd(&quot;China&quot;,100d,&quot;Shanghai&quot;); System.out.println(jedis.zrange(&quot;China&quot;,0,-1));&#125; 7.2 jedis实例-手机验证码需求： 输入手机号，点击发送后随机生成6位数字码，2分钟内有效 输入验证码，点击验证，返回成功或失败 每个手机号每天只能输入三次 思路： 生成随机六位数字验证码：用Random 验证码在2分钟内有效：把验证码放到redis中，设置过期时间120秒 判断验证码是否一致：把redis中的验证码和输入的验证码比较，是否一致 每个号码每天只能输入三次：incr每次发送后+1，当大于2的时候，提交不能发送 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class PhoneCode &#123; static Jedis jedis = new Jedis(&quot;192.168.134.134&quot;,6379); public static void main(String[] args) &#123; //模拟验证码发送 //verifyCode(&quot;12345678910&quot;); //getRedisCode(&quot;12345678910&quot;,&quot;085158&quot;); verifyCode(&quot;12345678910&quot;); &#125; //1.生成6位数字验证码 public static String getCode()&#123; Random random = new Random(); StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; 6; i++) &#123; int rand = random.nextInt(10); sb.append(String.valueOf(rand)); &#125; return sb.toString(); &#125; //2.每个手机每天只能发送三次，验证码放到redis中去，设置过期时间 public static void verifyCode(String phone)&#123; //拼接key //手机发送次数 String countKey = &quot;VerifyCode&quot; + phone + &quot;:count&quot;; //验证码key String codeKey = &quot;VerifyCode&quot; + phone + &quot;:code&quot;; //每个手机每天只能发三次 String count = jedis.get(countKey); if(count == null)&#123; //没有发送次数，第一次发送 jedis.setex(countKey,24*60*60,&quot;1&quot;); &#125;else if(Integer.parseInt(count)&lt;=2)&#123; //发送次数+1 jedis.incr(countKey); &#125;else&#123; //发送次数大于3 System.out.println(&quot;今天发送次数已经大于三次，不能再发送了&quot;); jedis.close(); return; &#125; //发送验证码放到redis中 String vcode = getCode(); jedis.setex(codeKey,120,vcode); jedis.close(); &#125; //3.验证码的校验 public static void getRedisCode(String phone,String code)&#123; //从Redis中获取验证码 //验证码key String codeKey = &quot;VerifyCode&quot; + phone + &quot;:code&quot;; String redisCode = jedis.get(codeKey); //判断 if (code.equals(redisCode))&#123; System.out.println(&quot;成功&quot;); &#125;else&#123; System.out.println(&quot;失败&quot;); &#125; &#125;&#125; 8. SpringBoot整合Redis 引入依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; application.properties中配置redis 12345678910111213141516#redis服务器地址spring.redis.host=192.168.134.134#redis服务器连接端口spring.redis.port=6379#redis数据库索引(默认为0)spring.redis.database=0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间（使用负值表示没有限制）spring.redis.lettuce.pool.max-wait=-1#连接池中最大空闲连接spring.redis.lettcue.pool.max-idle=5#连接池中最小空闲连接spring.redis.lettuce.pool.min-idle=0 创建redis配置类 12345678910111213141516171819202122232425262728293031323334353637383940414243@EnableCaching@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setConnectionFactory(factory); //key序列化方式 template.setKeySerializer(redisSerializer); //value序列化 template.setValueSerializer(jackson2JsonRedisSerializer); //value hashmap序列化 template.setHashValueSerializer(jackson2JsonRedisSerializer); return template; &#125; @Bean public CacheManager cacheManager(RedisConnectionFactory factory) &#123; RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); // 配置序列化（解决乱码的问题）,过期时间600秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(600)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory) .cacheDefaults(config) .build(); return cacheManager; &#125;&#125; 编写controller 12345678910111213141516@RestController@RequestMapping(&quot;/redisTest&quot;)public class RedisTestController &#123; @Autowired private RedisTemplate redisTemplate; @GetMapping public String testRedis()&#123; //设置值到redis中 redisTemplate.opsForValue().set(&quot;name&quot;,&quot;lucy&quot;); //获取值 String name = (String)redisTemplate.opsForValue().get(&quot;name&quot;); return name; &#125;&#125; 9. Redis事务 单独的隔离操作 事务中的所有命令都会序列化、按顺序执行 事务在执行过程中，不会被其他客户端送来的命令请求打断 从输入Multi命令开始，输入的命令都会一次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。 组队过程中可以通过discard来放弃组队。 事务的错误处理： 组队中某个命令出现了错误报告，执行时整个的所有队列都会被取消。 执行阶段某个命令出现了错误，则只有报错的命令不会被执行，其他命令都会执行，不会回滚。 9.1 悲观锁和乐观锁 悲观锁：不能同时进行多人，执行的时候先上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁 乐观锁：通过版本号一致与否，即给数据加上版本，同步更新数据以及加上版本号。不会上锁，判断版本号，可以多人操作，类似生活中的抢票。每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的 在执行multi之前，执行命令watch key1 [key2]，如果实物执行之前这个（或这些）key被其他命令所改动，那么事务被打断。 在事务1中： 12345678910127.0.0.1:6379&gt; set balance 100OK127.0.0.1:6379&gt; watch balanceOK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; incrby balance 10QUEUED127.0.0.1:6379(TX)&gt; exec1) (integer) 110 在事务2中： 12345678127.0.0.1:6379&gt; watch balanceOK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; incrby balance 20QUEUED127.0.0.1:6379(TX)&gt; exec(nil) 会发现在事务2中exec命令执行后，显示失败，并没有执行加20的操作，这就是乐观锁 9.2 Redis事务三大特性： 单独的隔离操作，事务中的所有命令都会序列化，按照顺序来执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念，队列中的命令没有提交之前都不会实际被执行。 不保证原子性，事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。 10. Redis持久化具体Redis 提供了2个不同形式的持久化方式 RDB（Redis DataBase） AOF（Append Of File） 10.1 RDB在指定的时间间隔内将内存中的数据集快照写入磁盘 具体的备份流程如下：Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 RDB的缺点是最后一次持久化后的数据可能丢失。 数据如果有变化的，会在&#x2F;usr&#x2F;local&#x2F;bin目录下生成一个dum.rdb的文件 关于fork进程 Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“写时复制技术” 一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。 关于redis.conf配置文件的部分解释： save 3600save 300 10save 60 10000大概意思如下：save 秒钟 写操作次数，60秒传10000次的写操作。不设置save指令，或者给save传入空字符串 关于save和bgsave的比较： save ：save时只管保存，其它不管，全部阻塞。手动保存。不建议。bgsave：Redis会在后台异步进行快照操作， 快照同时还可以响应客户端请求。可以通过lastsave 命令获取最后一次成功执行快照的时间 stop-writes-on-bgsave-error yes 关闭写入磁盘操作。比如当Redis无法写入磁盘的话，直接关掉Redis的写操作 rdbcompression yes 对于存储到磁盘中的快照，可以设置是否进行压缩存储，如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes. rdbchecksum yes 增加数据校验，增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能 dbfilename dump.rdb 在redis.conf中配置文件名称，默认为dump.rdb dir .&#x2F; 默认为Redis启动时命令行所在的目录下 具体rdb的备份 因为是临时文件，如果redis关闭之后，rdb的东西就会不见所以通过mv 更改其名字之后mv dump.rdb d.rdb在启动之前 又更改回来名字即可，mv d.rdb dump.rdb（启动Redis, 备份数据会直接加载） 总结 优点： 适合大规模的数据恢复 对数据完整性和一致性要求不高更适合使用 节省磁盘空间 恢复速度快 缺点： Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。 10.2 AOF以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(读操作不记录)， 只许追加文件但不可以改写文件 redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 关于redis.conf配置文件的部分解释AOF的备份机制和性能虽然和RDB不同, 但是备份和恢复的操作同RDB一样，都是拷贝备份文件，需要恢复时再拷贝到Redis工作目录下，启动系统即加载 默认是不开启AOF，开启RDB可以在redis.conf中配置文件名称，默认为 appendonly.aofAOF文件的保存路径，同RDB的路径一致 appendonly no改为yes 插入其数据的时候，在日志里面会看到数据的添加如果直接在日志添加一些无法识别的数据，启动redis会启动不了可以通通过/usr/local/bin/redis-check-aof--fix appendonly.aof进行恢复在当前目录下有redis-check-aof这个文件 关于Rewrite压缩 AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof 重写机制： AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再renameredis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作 no-appendfsync-on-rewrite：缓存，yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）磁盘，no，还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低） 什么时候重写 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发 重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写。 auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发） auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。 重写流程 （1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。（2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。（3）子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。（4）1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。（5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写 总结优点： 备份机制更稳健，丢失数据概率更低 可读的日志文本，通过操作AOF稳健，可以处理误操作 缺点： 比起RDB占用更多的磁盘空间。 恢复备份速度要慢。 每次读写都同步的话，有一定的性能压力。 存在个别Bug，造成恢复不能 10.3 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾. Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式. 同时开启两种持久化方式 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据, 因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整. RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 答：建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。","tags":["中间技术","学习","技术"],"categories":["中间技术","Redis"]},{"title":"Git命令","path":"/2022/04/12/Git命令/","content":"Git常用命令 命令名称 作用 git config –global user.name 用户名 设置用户签名 git config –global user.email 邮箱 设置用户签名 git init 初始化本地库 git status 查看本地库状态 git add 文件名 添加到暂存区 git commit m “ 日志信息 “ 文件名 提交到本地库 git reflog 查看历史记录 git reset hard 版本号 版本穿梭 1.1 设置用户签名 git config --global user.name 用户名 git config --global user.email 邮箱 并且在自己 C:\\Users\\Acer 下有个 .gitconfig 文件，打开里面就是我们设置的用户签名 1.2 初始化本地库基本语法：git init 1.3 查看本地库状态基本语法：git status 新增文件： 语法：vim hello.txt ,然后按 i 键进入 INSERT，要想复制粘贴 ，需要先按 esc 键，之后 yy 复制，p 粘贴 文件内容输入完毕，需要先按:,输入wq，然后才算完成新增文件，再次查看 1.4 添加暂存区基本语法：git add 文件名 可以用 git rm --cached hello.txt删除暂存区的文件，注意这里删除的只是暂存区的文件，工作区的没有被删掉 1.5 提交本地库基本语法：git commit -m &quot;日志信息&quot; 文件名 1.6 修改文件语法：vim 文件名 修改后记得commit到本地库，记录下来版本 1.7 历史版本基本语法： git reflog 查看版本信息 git log 查看版本详细信息 版本穿梭： 语法：git reset --hard 版本号 1.8 切换版本原理Git 切换版本，底层其实是移动的HEAD 指针 HEAD 指针指向 master 分支，master分支指向 first 版本， 之后有了 second 版本，master 指针指向 second 版本 之后有了third 版本，master 指针指向 third 版本 如果我们想穿越回去，只需要让 master 指针指向 first 版本或者 second 版本","tags":["学习","技术","Git","命令"],"categories":["中间技术","Git"]},{"title":"Git分支","path":"/2022/04/12/Git分支/","content":"Git分支好处： 同时并行推进多个功能开发，提高开发效率。 各个分支在开发过程中，如果某一个分支开发失败，不会对其他分支有任何影响。失败的分支删除重新开始即可。 分支操作： 命令名称 作用 git branch 分支名称 创建分支 git branch -v 查看分支 git checkout 分支名 切换分支 git merge 分支名 把指定的分支合并到当前分支上 合并产生冲突： 冲突产生的原因： 合并分支时，两个分支在同一个文件的同一个位置有两套完全不同的修改。 有两套完全不同的修改。 Git无法替我们决定使用哪一个。必须 人为决定新代码内容。 解决冲突： 编辑有冲突的文件，删除特殊符号，决定要使用的内容 特殊符号：&lt;&lt;&lt;&lt;&lt;&lt; HEAD 当前分支的代码 ======= 合并过来的代码 &gt;&gt;&gt;&gt;&gt;&gt;&gt;hot-fix 删除完成之后保存，再次添加到暂存区，并再次提交到本地库(注意：此时使用 git commit 命令时候不能带文件名)","tags":["学习","技术","Git"],"categories":["中间技术","Git"]},{"title":"SpringBoot开发技巧","path":"/2021/10/29/SpringBoot开发小技巧/","content":"SpringBoot开发小技巧1. LombokLombok用标签方式代替构造器、getter&#x2F;setter、toString()等鸡肋代码。 spring boot已经管理Lombok。引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; IDEA中File-&gt;Settings-&gt;Plugins，搜索安装Lombok插件。 1234567891011121314151617@NoArgsConstructor //无参构造//@AllArgsConstructor //有参构造@Data //set get方法@ToString@EqualsAndHashCodepublic class User &#123; private String name; private Integer age; private Pet pet; public User(String name,Integer age)&#123; this.name = name; this.age = age; &#125;&#125; 简化日志开发 123456789@Slf4j@RestControllerpublic class HelloController &#123; @RequestMapping(&quot;/hello&quot;) public String handle01(@RequestParam(&quot;name&quot;) String name)&#123; log.info(&quot;请求进来了....&quot;); return &quot;Hello, Spring Boot 2!&quot;+&quot;你好：&quot;+name; &#125;&#125; 2. dev-tools添加依赖： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在IDEA中，项目或者页面修改以后：Ctrl+F9。 3. Spring InitailizrSpring Initailizr是创建Spring Boot工程向导。 在IDEA中，菜单栏New -&gt; Project -&gt; Spring Initailizr。","tags":["工作","技术","SpringBoot"],"categories":["Java技术","SpringBoot"]},{"title":"SpringBoot的Web开发","path":"/2021/10/28/SpringBoot的Web开发/","content":"1、拦截器-登录检查与资源放行 编写一个拦截器实现HandlerInterceptor接口 拦截器注册到容器中（实现WebMvcConfigurer的addInterceptors()） 指定拦截规则（注意，如果是拦截所有，静态资源也会被拦截） 编写一个实现HandlerInterceptor接口的拦截器： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4jpublic class LoginInterceptor implements HandlerInterceptor &#123; /** * 目标方法执行之前 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String requestURI = request.getRequestURI(); log.info(&quot;preHandle拦截的请求路径是&#123;&#125;&quot;,requestURI); //登录检查逻辑 HttpSession session = request.getSession(); Object loginUser = session.getAttribute(&quot;loginUser&quot;); if(loginUser != null)&#123; //放行 return true; &#125; //拦截住。未登录。跳转到登录页 request.setAttribute(&quot;msg&quot;,&quot;请先登录&quot;);// re.sendRedirect(&quot;/&quot;); request.getRequestDispatcher(&quot;/&quot;).forward(request,response); return false; &#125; /** * 目标方法执行完成以后 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; log.info(&quot;postHandle执行&#123;&#125;&quot;,modelAndView); &#125; /** * 页面渲染以后 */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; log.info(&quot;afterCompletion执行异常&#123;&#125;&quot;,ex); &#125;&#125; 拦截器注册到容器中 &amp;&amp; 指定拦截规则： 123456789@Configurationpublic class AdminWebConfig implements WebMvcConfigurer&#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor())//拦截器注册到容器中 .addPathPatterns(&quot;/**&quot;) //所有请求都被拦截包括静态资源 .excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/css/**&quot;,&quot;/fonts/**&quot;,&quot;/images/**&quot;, &quot;/js/**&quot;,&quot;/aa/**&quot;); //放行的请求&#125; 拦截器原理 根据当前请求，找到HandlerExecutionChain【可以处理请求的handler以及handler的所有拦截器】 先来顺序执行所有拦截器的preHandle方法 如果当前拦截器preHandler返回为true，则执行下一个拦截器的preHandle 如果当前拦截器preHandler返回为false，则直接倒序执行所有已经执行了的拦截器的afterCompletion 如果任何一个拦截器执行false，直接跳出不执行目标方法 所有拦截器都返回true，执行目标方法 倒序执行所有拦截器的postHandle方法 前面的步骤有任何异常都会直接触发afterCompletion 页面成功渲染完成以后，也会倒序触发afterCompletion image-20220324111931368 2、文件上传-单文件与多文件上传的使用前端代码：&#x2F;static&#x2F;form&#x2F;form_layouts.html 12345678910111213141516171819202122232425262728&lt;form role=&quot;form&quot; th:action=&quot;@&#123;/upload&#125;&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputEmail1&quot;&gt;邮箱&lt;/label&gt; &lt;input type=&quot;email&quot; name=&quot;email&quot; class=&quot;form-control&quot; id=&quot;exampleInputEmail1&quot; placeholder=&quot;Enter email&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputPassword1&quot;&gt;名字&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;username&quot; class=&quot;form-control&quot; id=&quot;exampleInputPassword1&quot; placeholder=&quot;Password&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputFile&quot;&gt;头像&lt;/label&gt; &lt;input type=&quot;file&quot; name=&quot;headerImg&quot; id=&quot;exampleInputFile&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;exampleInputFile&quot;&gt;生活照&lt;/label&gt; &lt;input type=&quot;file&quot; name=&quot;photos&quot; multiple&gt; &lt;/div&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot;&gt; Check me out &lt;/label&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;提交&lt;/button&gt;&lt;/form&gt; 控制层代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 文件上传测试 */@Slf4j@Controllerpublic class FormTestController &#123; @GetMapping(&quot;/form_layouts&quot;) public String form_layouts()&#123; return &quot;form/form_layouts&quot;; &#125; /** * MultipartFile自动封装上传来的文件 * @param email * @param username * @param headerImg * @param photos * @return */ @RequestMapping(&quot;/upload&quot;) public String upload(@RequestParam(&quot;email&quot;) String email, @RequestParam(&quot;username&quot;) String username, @RequestPart(&quot;headerImg&quot;) MultipartFile headerImg, @RequestPart MultipartFile[] photos) throws IOException &#123; log.info(&quot;上传信息：email=&#123;&#125;，username=&#123;&#125;，headerImg=&#123;&#125;，photos=&#123;&#125;&quot;, email,username,headerImg.getSize(),photos.length); if(!headerImg.isEmpty())&#123; //保存到文件服务器，OSS服务器 String originalFilename = headerImg.getOriginalFilename(); headerImg.transferTo(new File(&quot;E:\\\\StudyFiles\\\\SpringBoot\\\\FileTest\\\\headerImg\\\\&quot;+originalFilename)); &#125; if(photos.length &gt; 0)&#123; for (MultipartFile photo : photos) &#123; if(!photo.isEmpty())&#123; String originalFilename = photo.getOriginalFilename(); photo.transferTo(new File(&quot;E:\\\\StudyFiles\\\\SpringBoot\\\\FileTest\\\\photos\\\\&quot;+originalFilename)); &#125; &#125; &#125; return &quot;main&quot;; &#125;&#125; 文件大小相关配置项： 12spring.servlet.multipart.max-file-size=10MBspring.servlet.multipart.max-request-size=100MB 3、错误处理-SpringBoot默认错误处理机制默认规则： 默认情况下，Spring Boot提供/error处理所有错误的映射 机器客户端，它将生成JSON响应，其中包含错误，HTTP状态和异常消息的详细信息。对于浏览器客户端，响应一个“ whitelabel”错误视图，以HTML格式呈现相同的数据 要对其进行自定义，添加View解析为error 要完全替换默认行为，可以实现 ErrorController并注册该类型的Bean定义，或添加ErrorAttributes类型的组件以使用现有机制但替换其内容。 &#x2F;templates&#x2F;error&#x2F;下的4xx，5xx页面会被自动解析 4、Web原生组件注入-原生注解与Spring方式注入使用原生的注解12345678@WebServlet(urlPatterns = &quot;/my&quot;)\t//直接响应，没有Spring的拦截器public class MyServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.getWriter().write(&quot;66666&quot;); &#125;&#125; 12345678910111213141516171819@Slf4j@WebFilter(urlPatterns=&#123;&quot;/css/*&quot;,&quot;/images/*&quot;&#125;) //mypublic class MyFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; log.info(&quot;MyFilter初始化完成&quot;); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; log.info(&quot;MyFilter工作&quot;); chain.doFilter(request,response); &#125; @Override public void destroy() &#123; log.info(&quot;MyFilter销毁&quot;); &#125;&#125; 123456789101112131415@Slf4j@WebListenerpublic class MyServletContextListener implements ServletContextListener &#123; @Override public void contextInitialized(ServletContextEvent sce) &#123; log.info(&quot;MySwervletContextListener监听到项目初始化完成&quot;); &#125; @Override public void contextDestroyed(ServletContextEvent sce) &#123; log.info(&quot;MySwervletContextListener监听到项目销毁&quot;); &#125;&#125; 最后还要在主启动类添加注解@ServletComponentScan 12345678@ServletComponentScan(basePackages = &quot;com.lun&quot;)//@SpringBootApplication(exclude = RedisAutoConfiguration.class)public class Boot05WebAdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Boot05WebAdminApplication.class, args); &#125;&#125; Spring方式注入ServletRegistrationBean,FilterRegistrationBean,andServletListenerRegistrationBean 123456789101112131415161718192021222324252627@Configuration(proxyBeanMethods = true)public class MyRegistConfig &#123; @Bean public ServletRegistrationBean myServlet()&#123; MyServlet myServlet = new MyServlet(); return new ServletRegistrationBean(myServlet,&quot;/my&quot;,&quot;/my02&quot;); &#125; @Bean public FilterRegistrationBean myFilter()&#123; MyFilter myFilter = new MyFilter();// return new FilterRegistrationBean(myFilter,myServlet()); FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(myFilter); filterRegistrationBean.setUrlPatterns(Arrays.asList(&quot;/my&quot;,&quot;/css/*&quot;)); return filterRegistrationBean; &#125; @Bean public ServletListenerRegistrationBean myListener()&#123; MySwervletContextListener mySwervletContextListener = new MySwervletContextListener(); return new ServletListenerRegistrationBean(mySwervletContextListener); &#125;&#125; 5、定制化原理-SpringBoot定制化组件的几种方式（小结）定制化的常见方式 修改配置文件 xxxxxCustomizer 编写自定义的配置类 xxxConfiguration + @Bean替换、增加容器中默认组件，视图解析器 Web应用 编写一个配置类实现 WebMvcConfigurer 即可定制化web功能 + @Bean给容器中再扩展一些组件 123@Configurationpublic class AdminWebConfig implements WebMvcConfigurer&#123;&#125; @EnableWebMvc + WebMvcConfigurer — @Bean 可以全面接管SpringMVC，所有规则全部自己重新配置； 实现定制和扩展功能（高级功能，初学者退避三舍）。 原理： ​\t1. WebMvcAutoConfiguration默认的SpringMVC的自动配置功能类，如静态资源、欢迎页等。 一旦使用 @EnableWebMvc ，会@Import(DelegatingWebMvcConfiguration.class) DelegatingWebMvcConfiguration的作用，只保证SpringMVC最基本的使用 把所有系统中的WebMvcConfigurer拿过来，所有功能的定制都是这些WebMvcConfigurer合起来一起生效。 自动配置了一些非常底层的组件，如RequestMappingHandlerMapping，这些组件依赖的组件都是从容器中获取如。 public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport。 WebMvcAutoConfiguration里面的配置要能生效必须 @ConditionalOnMissingBean(WebMvcConfigurationSupport.class)。 @EnableWebMvc 导致了WebMvcAutoConfiguration 没有生效。 原理分析套路： 场景starter - xxxxAutoConfiguration - 导入xxx组件 - 绑定xxxProperties - 绑定配置文件项。","tags":["工作","技术","SpringBoot"],"categories":["Java技术","SpringBoot"]},{"title":"SpringBoot单元测试","path":"/2021/10/27/SpringBoot单元测试/","content":"1、单元测试-JUnit5简介Spring Boot 2.2.0 版本开始引入 JUnit 5 作为单元测试默认库 作为最新版本的JUnit框架，JUnit5与之前版本的JUnit框架有很大的不同。由三个不同子项目的几个不同模块组成。 JUnit 5 &#x3D; JUnit Platform + JUnit Jupiter + JUnit Vintage JUnit Platform: Junit Platform是在JVM上启动测试框架的基础，不仅支持Junit自制的测试引擎，其他测试引擎也都可以接入。 JUnit Jupiter: JUnit Jupiter提供了JUnit5的新的编程模型，是JUnit5新特性的核心。内部包含了一个测试引擎，用于在Junit Platform上运行。 JUnit Vintage: 由于JUint已经发展多年，为了照顾老的项目，JUnit Vintage提供了兼容JUnit4.x，JUnit3.x的测试引擎。 注意： SpringBoot 2.4 以上版本移除了默认对 Vintage 的依赖。如果需要兼容JUnit4需要自行引入（不能使用JUnit4的功能 @Test） JUnit 5’s Vintage已经从spring-boot-starter-test从移除。如果需要继续兼容Junit4需要自行引入Vintage依赖： 2、单元测试-常用测试注解 @Test：表示方法是测试方法。但是与JUnit4的@Test不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试 @ParameterizedTest：表示方法是参数化测试。 @RepeatedTest：表示方法可重复执行。 @DisplayName：为测试类或者测试方法设置展示名称。 @BeforeEach：表示在每个单元测试之前执行。 @AfterEach：表示在每个单元测试之后执行。 @BeforeAll：表示在所有单元测试之前执行。 @AfterAll：表示在所有单元测试之后执行。 @Tag：表示单元测试类别，类似于JUnit4中的@Categories。 @Disabled：表示测试类或测试方法不执行，类似于JUnit4中的@Ignore。 @Timeout：表示测试方法运行如果超过了指定时间将会返回错误。 @ExtendWith：为测试类或测试方法提供扩展类引用。 123456789101112131415161718192021222324252627282930313233343536373839package com.sirius.admin;import org.junit.jupiter.api.*;@DisplayName(&quot;Junit5功能测试&quot;)public class Junit5Test &#123; @DisplayName(&quot;测试DisplayName注解&quot;) @Test void testDisplayName()&#123; System.out.println(1); &#125; @DisplayName(&quot;测试方法2&quot;) @Test void test2()&#123; System.out.println(2); &#125; @BeforeEach void testBeforeEach()&#123; System.out.println(&quot;测试就要开始了&quot;); &#125; @AfterEach void testAfterEach()&#123; System.out.println(&quot;测试结束了&quot;); &#125; @BeforeAll static void testBeforeAll()&#123; System.out.println(&quot;所有测试就要开始了&quot;); &#125; @AfterAll static void testAfterAll()&#123; System.out.println(&quot;所有测试结束了&quot;); &#125;&#125; 3、单元测试-断言机制断言Assertion是测试方法中的核心部分，用来对测试需要满足的条件进行验证。这些断言方法都是org.junit.jupiter.api.Assertions的静态方法。检查业务逻辑返回的数据是否合理。所有的测试运行结束以后，会有一个详细的测试报告。 JUnit 5 内置的断言可以分成如下几个类别： 简单断言用来对单个值进行简单的验证。如： 方法 说明 assertEquals 判断两个对象或两个原始类型是否相等 assertNotEquals 判断两个对象或两个原始类型是否不相等 assertSame 判断两个对象引用是否指向同一个对象 assertNotSame 判断两个对象引用是否指向不同的对象 assertTrue 判断给定的布尔值是否为 true assertFalse 判断给定的布尔值是否为 false assertNull 判断给定的对象引用是否为 null assertNotNull 判断给定的对象引用是否不为 null 123456789101112/** * 前面的断言失败，后面的代码都不会执行 */ @DisplayName(&quot;测试简单断言&quot;) @Test void testSimpleAssertions()&#123; int res = cal(2, 3); assertEquals(5,res,&quot;业务逻辑计算失败&quot;); Object obj1 = new Object(); Object obj2 = new Object(); assertSame(obj1,obj2,&quot;两个对象不一样&quot;); &#125; 数组断言通过 assertArrayEquals 方法来判断两个对象或原始类型的数组是否相等。 12345@Test@DisplayName(&quot;array assertion&quot;)public void array() &#123;\tassertArrayEquals(new int[]&#123;1, 2&#125;, new int[] &#123;1, 2&#125;);&#125; 组合断言assertAll()方法接受多个 org.junit.jupiter.api.Executable 函数式接口的实例作为要验证的断言，可以通过 lambda 表达式很容易的提供这些断言。 12345678@Test@DisplayName(&quot;assert all&quot;)public void all() &#123; assertAll(&quot;Math&quot;, () -&gt; assertEquals(2, 1 + 1), () -&gt; assertTrue(1 &gt; 0) );&#125; 异常断言在JUnit4时期，想要测试方法的异常情况时，需要用@Rule注解的ExpectedException变量还是比较麻烦的。而JUnit5提供了一种新的断言方式Assertions.assertThrows()，配合函数式编程就可以进行使用。 1234567@Test@DisplayName(&quot;异常测试&quot;)public void exceptionTest() &#123; ArithmeticException exception = Assertions.assertThrows( //扔出断言异常 ArithmeticException.class, () -&gt; System.out.println(1 % 0));&#125; 超时断言JUnit5还提供了Assertions.assertTimeout()为测试方法设置了超时时间。 123456@Test@DisplayName(&quot;超时测试&quot;)public void timeoutTest() &#123; //如果测试方法时间超过1s将会异常 Assertions.assertTimeout(Duration.ofMillis(1000), () -&gt; Thread.sleep(500));&#125; 快速失败通过 fail 方法直接使得测试失败。 12345@Test@DisplayName(&quot;fail&quot;)public void shouldFail() &#123;\tfail(&quot;This should fail&quot;);&#125; 4、单元测试-前置条件JUnit 5 中的前置条件（assumptions【假设】）类似于断言，不同之处在于不满足的断言assertions会使得测试方法失败，而不满足的前置条件只会使得测试方法的执行终止。 前置条件可以看成是测试方法执行的前提，当该前提不满足时，就没有继续执行的必要。 1234567891011121314151617181920@DisplayName(&quot;前置条件&quot;)public class AssumptionsTest &#123; private final String environment = &quot;DEV&quot;; @Test @DisplayName(&quot;simple&quot;) public void simpleAssume() &#123; assumeTrue(Objects.equals(this.environment, &quot;DEV&quot;)); assumeFalse(() -&gt; Objects.equals(this.environment, &quot;PROD&quot;)); &#125; @Test @DisplayName(&quot;assume then do&quot;) public void assumeThenDo() &#123; assumingThat( Objects.equals(this.environment, &quot;DEV&quot;), () -&gt; System.out.println(&quot;In DEV&quot;) ); &#125;&#125; assumeTrue 和 assumFalse 确保给定的条件为 true 或 false，不满足条件会使得测试执行终止。 assumingThat 的参数是表示条件的布尔值和对应的 Executable 接口的实现对象。只有条件满足时，Executable 对象才会被执行；当条件不满足时，测试执行并不会终止。 5、单元测试-嵌套测试JUnit 5 可以通过 Java 中的内部类和@Nested 注解实现嵌套测试，从而可以更好的把相关的测试方法组织在一起。在内部类中可以使用@BeforeEach 和@AfterEach注解，而且嵌套的层次没有限制。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@DisplayName(&quot;A stack&quot;)class TestingAStackDemo &#123; Stack&lt;Object&gt; stack; @Test @DisplayName(&quot;is instantiated with new Stack()&quot;) void isInstantiatedWithNew() &#123; new Stack&lt;&gt;(); &#125; @Nested @DisplayName(&quot;when new&quot;) class WhenNew &#123; @BeforeEach void createNewStack() &#123; stack = new Stack&lt;&gt;(); &#125; @Test @DisplayName(&quot;is empty&quot;) void isEmpty() &#123; assertTrue(stack.isEmpty()); &#125; @Test @DisplayName(&quot;throws EmptyStackException when popped&quot;) void throwsExceptionWhenPopped() &#123; assertThrows(EmptyStackException.class, stack::pop); &#125; @Test @DisplayName(&quot;throws EmptyStackException when peeked&quot;) void throwsExceptionWhenPeeked() &#123; assertThrows(EmptyStackException.class, stack::peek); &#125; @Nested @DisplayName(&quot;after pushing an element&quot;) class AfterPushing &#123; String anElement = &quot;an element&quot;; @BeforeEach void pushAnElement() &#123; stack.push(anElement); &#125; @Test @DisplayName(&quot;it is no longer empty&quot;) void isNotEmpty() &#123; assertFalse(stack.isEmpty()); &#125; @Test @DisplayName(&quot;returns the element when popped and is empty&quot;) void returnElementWhenPopped() &#123; assertEquals(anElement, stack.pop()); assertTrue(stack.isEmpty()); &#125; @Test @DisplayName(&quot;returns the element when peeked but remains not empty&quot;) void returnElementWhenPeeked() &#123; assertEquals(anElement, stack.peek()); assertFalse(stack.isEmpty()); &#125; &#125; &#125;&#125; 6、单元测试-参数化测试参数化测试是JUnit5很重要的一个新特性，它使得用不同的参数多次运行测试成为了可能，也为我们的单元测试带来许多便利。 利用@ValueSource等注解，指定入参，我们将可以使用不同的参数进行多次单元测试，而不需要每新增一个参数就新增一个单元测试，省去了很多冗余代码。 利用**@ValueSource**等注解，指定入参，我们将可以使用不同的参数进行多次单元测试，而不需要每新增一个参数就新增一个单元测试，省去了很多冗余代码。 @ValueSource: 为参数化测试指定入参来源，支持八大基础类以及String类型,Class类型 @NullSource: 表示为参数化测试提供一个null的入参 @EnumSource: 表示为参数化测试提供一个枚举入参 @CsvFileSource：表示读取指定CSV文件内容作为参数化测试入参 @MethodSource：表示读取指定方法的返回值作为参数化测试入参(注意方法返回需要是一个流) 当然如果参数化测试仅仅只能做到指定普通的入参还达不到让我觉得惊艳的地步。让我真正感到他的强大之处的地方在于他可以支持外部的各类入参。如:CSV,YML,JSON 文件甚至方法的返回值也可以作为入参。只需要去实现ArgumentsProvider接口，任何外部文件都可以作为它的入参。 1234567891011121314151617181920@ParameterizedTest@ValueSource(strings = &#123;&quot;one&quot;, &quot;two&quot;, &quot;three&quot;&#125;)@DisplayName(&quot;参数化测试1&quot;)public void parameterizedTest1(String string) &#123; System.out.println(string); Assertions.assertTrue(StringUtils.isNotBlank(string));&#125;@ParameterizedTest@MethodSource(&quot;method&quot;) //指定方法名@DisplayName(&quot;方法来源参数&quot;)public void testWithExplicitLocalMethodSource(String name) &#123; System.out.println(name); Assertions.assertNotNull(name);&#125;static Stream&lt;String&gt; method() &#123; return Stream.of(&quot;apple&quot;, &quot;banana&quot;);&#125;","tags":["工作","技术","SpringBoot","测试"],"categories":["Java技术","SpringBoot"]},{"title":"SpringBoot数据访问","path":"/2021/10/26/SpringBoot数据访问/","content":"1、数据访问-数据库场景的自动配置分析与整合测试导入JDBC场景1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 为什么导入JDBC场景，官方不导入驱动？ 因为官方不知道我们接下来要操作什么数据库。 数据库版本要和驱动版本对应！ 123456789101112131415161718&lt;!--默认版本：--&gt;&lt;mysql.version&gt;8.0.22&lt;/mysql.version&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;!--&lt;version&gt;5.1.49&lt;/version&gt;--&gt;&lt;/dependency&gt;&lt;!--想要修改版本1、直接依赖引入具体版本（maven的就近依赖原则）2、重新声明版本（maven的属性的就近优先原则）--&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;mysql.version&gt;5.1.49&lt;/mysql.version&gt;&lt;/properties&gt; 相关数据源配置类 DataSourceAutoConfiguration ： 数据源的自动配置。 修改数据源相关的配置：spring.datasource。 数据库连接池的配置，是自己容器中没有DataSource才自动配置的。 底层配置好的连接池是：HikariDataSource。 DataSourceTransactionManagerAutoConfiguration： 事务管理器的自动配置。 JdbcTemplateAutoConfiguration： JdbcTemplate的自动配置，可以来对数据库进行CRUD。 可以修改前缀为spring.jdbc的配置项来修改JdbcTemplate。 @Bean @Primary JdbcTemplate：Spring容器中有这个JdbcTemplate组件，使用@Autowired。 JndiDataSourceAutoConfiguration： JNDI的自动配置。 XADataSourceAutoConfiguration： 分布式事务相关的。 修改配置项1234567spring: datasource: url: jdbc:mysql://localhost:3306/hotel?useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver# type: com.zaxxer.hikari.HikariDataSource 单元测试数据源123456789101112131415@Slf4j@SpringBootTestclass BootWebAdminApplicationTests &#123; @Autowired JdbcTemplate jdbcTemplate; @Test void contextLoads() &#123; Long aLong = jdbcTemplate.queryForObject(&quot;select count(*) from webmanager&quot;, Long.class); log.info(&quot;记录总数：&#123;&#125;&quot;,aLong); &#125;&#125; 2、数据访问-自定义方式整合druid数据源Druid是什么？它是数据库连接池，它能够提供强大的监控和扩展功能。 Spring Boot整合第三方技术的两种方式： 自定义 找starter场景 自定义方式添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.17&lt;/version&gt;&lt;/dependency&gt; 配置Druid数据源： 123456789101112131415@Configurationpublic class MyConfig &#123; @Bean @ConfigurationProperties(&quot;spring.datasource&quot;)//复用配置文件的数据源配置 public DataSource dataSource() throws SQLException &#123; DruidDataSource druidDataSource = new DruidDataSource();// druidDataSource.setUrl();// druidDataSource.setUsername();// druidDataSource.setPassword(); return druidDataSource; &#125;&#125; 配置Druid的监控页功能： Druid内置提供了一个StatViewServlet用于展示Druid的统计信息。官方文档 - 配置_StatViewServlet配置。这个StatViewServlet的用途包括： 提供监控信息展示的html页面 提供监控信息的JSON API Druid内置提供一个StatFilter，用于统计监控信息。官方文档 - 配置_StatFilter WebStatFilter用于采集web-jdbc关联监控的数据，如SQL监控、URI监控。官方文档 - 配置_配置WebStatFilter Druid提供了WallFilter，它是基于SQL语义分析来实现防御SQL注入攻击的。官方文档 - 配置 wallfilter 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Configurationpublic class MyConfig &#123; @Bean @ConfigurationProperties(&quot;spring.datasource&quot;) public DataSource dataSource() throws SQLException &#123; DruidDataSource druidDataSource = new DruidDataSource(); //加入监控和防火墙功能功能 druidDataSource.setFilters(&quot;stat,wall&quot;); return druidDataSource; &#125; /** * 配置 druid的监控页功能 * @return */ @Bean public ServletRegistrationBean statViewServlet()&#123; StatViewServlet statViewServlet = new StatViewServlet(); ServletRegistrationBean&lt;StatViewServlet&gt; registrationBean = new ServletRegistrationBean&lt;&gt;(statViewServlet, &quot;/druid/*&quot;); //监控页账号密码： registrationBean.addInitParameter(&quot;loginUsername&quot;,&quot;admin&quot;); registrationBean.addInitParameter(&quot;loginPassword&quot;,&quot;123456&quot;); return registrationBean; &#125; /** * WebStatFilter 用于采集web-jdbc关联监控的数据。 */ @Bean public FilterRegistrationBean webStatFilter()&#123; WebStatFilter webStatFilter = new WebStatFilter(); FilterRegistrationBean&lt;WebStatFilter&gt; filterRegistrationBean = new FilterRegistrationBean&lt;&gt;(webStatFilter); filterRegistrationBean.setUrlPatterns(Arrays.asList(&quot;/*&quot;)); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;,&quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); return filterRegistrationBean; &#125; &#125; 3、数据访问-druid数据源starter整合方式引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.17&lt;/version&gt;&lt;/dependency&gt; 分析自动配置： 扩展配置项 spring.datasource.druid 自动配置类DruidDataSourceAutoConfigure DruidSpringAopConfiguration.class, 监控SpringBean的；配置项：spring.datasource.druid.aop-patterns DruidStatViewServletConfiguration.class, 监控页的配置。spring.datasource.druid.stat-view-servlet默认开启。 DruidWebStatFilterConfiguration.class，web监控配置。spring.datasource.druid.web-stat-filter默认开启。 DruidFilterConfiguration.class所有Druid的filter的配置： 123456789101112131415161718192021222324252627282930spring: datasource: url: jdbc:mysql://localhost:3306/hotel?useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver druid: filters: stat,wall #底层开启功能，stat（sql监控），wall（防火墙） stat-view-servlet: #配置监控页 enabled: true login-username: admin login-password: admin reset-enable: false web-stat-filter: #监控web enabled: true url-pattern: /* exclusions: &#x27;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&#x27; aop-patterns: com.sirius.admin.* #监控SpringBean filter: stat: slow-sql-millis: 1000 log-slow-sql: true enabled: true wall: enabled: true 4、数据访问-整合MyBatis-配置版引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt; 配置模式: 全局配置文件 SqlSessionFactory：自动配置好了 SqlSession：自动配置了SqlSessionTemplate 组合了SqlSession @Import(AutoConfiguredMapperScannerRegistrar.class) Mapper： 只要我们写的操作MyBatis的接口标准了**@Mapper就会被自动扫描进来** 12345678910@EnableConfigurationProperties(MybatisProperties.class) ： MyBatis配置项绑定类。@AutoConfigureAfter(&#123; DataSourceAutoConfiguration.class, MybatisLanguageDriverAutoConfiguration.class &#125;)public class MybatisAutoConfiguration&#123; ...&#125;@ConfigurationProperties(prefix = &quot;mybatis&quot;)public class MybatisProperties&#123; ...&#125; 配置文件： 1234567891011spring: datasource: url: jdbc:mysql://localhost:3306/hotel?useSSL=false username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver# 配置mybatis规则mybatis: config-location: classpath:mybatis/mybatis-config.xml #全局配置文件位置 mapper-locations: classpath:mybatis/*.xml #sql映射文件位置 mybatis-config.xml: 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!-- 由于Spring Boot自动配置缘故，此处不必配置，只用来做做样。--&gt;&lt;/configuration&gt; Mapper接口： 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.sirius.admin.mapper.AccountMapper&quot;&gt; &lt;select id=&quot;getAccount&quot; resultType=&quot;com.sirius.admin.bean.Account&quot;&gt; select * from account_tbl where id=#&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 配置private Configuration configuration; 也就是配置mybatis.configuration相关的，就是相当于改mybatis全局配置文件中的值。（也就是说配置了mybatis.configuration，就不需配置mybatis全局配置文件了） 1234567# 配置mybatis规则mybatis: mapper-locations: classpath:mybatis/mapper/*.xml # 可以不写全局配置文件，所有全局配置文件的配置都放在configuration配置项中了。 # config-location: classpath:mybatis/mybatis-config.xml configuration: map-underscore-to-camel-case: true 小结: 导入MyBatis官方Starter。 编写Mapper接口，需@Mapper注解。 编写SQL映射文件并绑定Mapper接口。 在application.yaml中指定Mapper配置文件的所处位置，以及指定全局配置文件的信息 （建议：配置在mybatis.configuration）。 5、数据访问-整合MyBatis-注解版注解与配置混合搭配，干活不累： 123456789101112import com.sirius.admin.bean.City;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Select;@Mapperpublic interface CityMapper &#123; @Select(&quot;select * from city where id=#&#123;id&#125;&quot;) public City getById(Long id); public void insert(City city);&#125; 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.sirius.admin.mapper.CityMapper&quot;&gt; &lt;insert id=&quot;insert&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into city(&#x27;name&#x27;,&#x27;state&#x27;,&#x27;country&#x27;) values(#&#123;name&#125;,#&#123;state&#125;,#&#123;country&#125;) &lt;/insert&gt;&lt;/mapper&gt; 简单DAO方法就写在注解上。复杂的就写在配置文件里。 使用@MapperScan(&quot;com.lun.boot.mapper&quot;) 简化，Mapper接口就可以不用标注@Mapper注解。 123456789@MapperScan(&quot;com.sirius.admin.mapper&quot;)@SpringBootApplicationpublic class MainApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApplication.class, args); &#125;&#125; 6、数据访问-整合MyBatisPlus操作数据库MyBatisPlus是什么MyBatis-Plus（简称 MP）是一个 MyBatis的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。 创建数据库12345678910DROP TABLE IF EXISTS user;CREATE TABLE user( id BIGINT(20) NOT NULL COMMENT &#x27;主键ID&#x27;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &#x27;姓名&#x27;, age INT(11) NULL DEFAULT NULL COMMENT &#x27;年龄&#x27;, email VARCHAR(50) NULL DEFAULT NULL COMMENT &#x27;邮箱&#x27;, PRIMARY KEY (id)); 添加数据12345678DELETE FROM user;INSERT INTO user (id, name, age, email) VALUES(1, &#x27;Jone&#x27;, 18, &#x27;test1@baomidou.com&#x27;),(2, &#x27;Jack&#x27;, 20, &#x27;test2@baomidou.com&#x27;),(3, &#x27;Tom&#x27;, 28, &#x27;test3@baomidou.com&#x27;),(4, &#x27;Sandy&#x27;, 21, &#x27;test4@baomidou.com&#x27;),(5, &#x27;Billie&#x27;, 24, &#x27;test5@baomidou.com&#x27;); 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt;&lt;/dependency&gt; MybatisPlusAutoConfiguration配置类，MybatisPlusProperties配置项绑定。 SqlSessionFactory自动配置好，底层是容器中默认的数据源。 mapperLocations自动配置好的，有默认值classpath*:&#x2F;mapper&#x2F;**&#x2F;*.xml，这表示任意包的类路径下的所有mapper文件夹下任意路径下的所有xml都是sql映射文件。 建议以后sql映射文件放在 mapper下。 容器中也自动配置好了SqlSessionTemplate。 @Mapper 标注的接口也会被自动扫描，建议直接 @MapperScan(“com.sirius.admin.mapper”)批量扫描。 MyBatisPlus优点之一：只需要我们的Mapper继承MyBatisPlus的BaseMapper 就可以拥有CRUD能力，减轻开发工作。 7、数据访问-CRUD实验-数据列表展示使用MyBatis Plus提供的IService，ServiceImpl，减轻Service层开发工作。 1234567package com.sirius.admin.service;import com.baomidou.mybatisplus.extension.service.IService;import com.sirius.admin.bean.User;public interface UserService extends IService&lt;User&gt; &#123;&#125; 123456789101112package com.sirius.admin.service.impl;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import com.sirius.admin.bean.User;import com.sirius.admin.mapper.UserMapper;import com.sirius.admin.service.UserService;import org.springframework.stereotype.Service;@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123; &#125; 添加分页插件1234567891011121314151617181920212223package com.sirius.admin.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MyBatisConfig &#123; @Bean public MybatisPlusInterceptor paginationInterceptor()&#123; MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); //分页拦截器 PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(); //设置请求的页面大于最大页后操作，true调回首页，false继续请求，默认false paginationInnerInterceptor.setOverflow(true); //设置最大单页限制数量，默认500条，-1：不受限制 paginationInnerInterceptor.setMaxLimit(500L); mybatisPlusInterceptor.addInnerInterceptor(paginationInnerInterceptor); return mybatisPlusInterceptor; &#125;&#125; 前端12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;table class=&quot;display table table-bordered table-striped&quot; id=&quot;dynamic-table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;id&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;age&lt;/th&gt; &lt;th&gt;email&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody role=&quot;alert&quot; aria-live=&quot;polite&quot; aria-relevant=&quot;all&quot;&gt; &lt;tr class=&quot;gradeX odd&quot; th:each=&quot;user,stat:$&#123;page.records&#125;&quot;&gt; &lt;td th:text=&quot;$&#123;stat.count&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;user.id&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;user.name&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;user.age&#125;&quot;&gt;&lt;/td&gt; &lt;td class=&quot;center hidden-phone&quot;&gt;[[$&#123;user.email&#125;]]&lt;/td&gt; &lt;td&gt; &lt;a th:href=&quot;@&#123;/user/delete/&#123;id&#125;(id=$&#123;user.id&#125;,pn=$&#123;page.current&#125;)&#125;&quot; class=&quot;btn btn-danger btn-sm&quot; type=&quot;button&quot;&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tfoot&gt; &lt;/table&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-lg-6&quot;&gt; &lt;div class=&quot;dataTables_info&quot; id=&quot;editable-sample_info&quot;&gt;当前第 [[$&#123;page.current&#125;]] 页 总计 [[$&#123;page.pages&#125;]] 页 共 [[$&#123;page.total&#125;]] 条记录&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-lg-6&quot;&gt; &lt;div class=&quot;dataTables_paginate paging_bootstrap pagination&quot;&gt; &lt;ul&gt; &lt;li class=&quot;prev disabled&quot;&gt; &lt;a href=&quot;#&quot;&gt;← 前一页&lt;/a&gt; &lt;/li&gt; &lt;li th:class=&quot;$&#123;num == page.current?&#x27;active&#x27;:&#x27;&#x27;&#125;&quot; th:each=&quot;num:$&#123;#numbers.sequence(1,page.pages)&#125;&quot;&gt; &lt;a th:href=&quot;@&#123;/dynamic_table(pn=$&#123;num&#125;)&#125;&quot;&gt;[[$&#123;num&#125;]]&lt;/a&gt; &lt;/li&gt; &lt;li class=&quot;next&quot;&gt;&lt;a href=&quot;#&quot;&gt;后一页 &lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; 控制层123456789101112131415161718192021222324252627282930@GetMapping(&quot;/user/delete/&#123;id&#125;&quot;) public String deleteUser(@PathVariable(&quot;id&quot;) Long id, @RequestParam(value = &quot;pn&quot;,defaultValue = &quot;1&quot;)Integer pn, RedirectAttributes ra)&#123; userService.removeById(id); ra.addAttribute(&quot;pn&quot;,pn); return &quot;redirect:/dynamic_table&quot;; &#125; @GetMapping(&quot;/dynamic_table&quot;) public String dynamic_table(@RequestParam(value = &quot;pn&quot;,defaultValue = &quot;1&quot;)Integer pn, Model model)&#123; List&lt;User&gt; list = userService.list(); //分页查询数据 Page&lt;User&gt; userPage = new Page&lt;&gt;(pn, 2); //分页查询的结果 Page&lt;User&gt; page = userService.page(userPage, null); long current = page.getCurrent(); long pages = page.getPages(); long total = page.getTotal(); List&lt;User&gt; records = page.getRecords(); model.addAttribute(&quot;page&quot;,page); return &quot;table/dynamic_table&quot;; &#125; 8、数据访问-准备阿里云Redis环境导入依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--导入jedis--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; RedisAutoConfiguration自动配置类，RedisProperties 属性类 –&gt; spring.redis.xxx是对redis的配置。 连接工厂LettuceConnectionConfiguration、JedisConnectionConfiguration是准备好的。 自动注入了RedisTemplate&lt;Object, Object&gt;，xxxTemplate。 自动注入了StringRedisTemplate，key，value都是String 底层只要我们使用StringRedisTemplate、RedisTemplate就可以操作Redis。 redis环境搭建 购买阿里云按量付费redis，经典网络 申请redis的公网链接地址 修改白名单，允许0.0.0.0/0访问。 9、数据访问-Redis操作与统计小实验redis相关配置123spring: redis: url: redis://:1368921075Cpg@r-2vcxoq6x4u60k8tf2zpd.redis.cn-chengdu.rds.aliyuncs.com:6379 123456789@Testvoid testRedis()&#123; ValueOperations&lt;String, String&gt; operations = redisTemplate.opsForValue(); operations.set(&quot;hello&quot;,&quot;world&quot;); String hello = operations.get(&quot;hello&quot;); System.out.println(hello);&#125; 切换到jedis12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--导入jedis--&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; 1234spring:\tredis: url: redis://:1368921075Cpg@r-2vcxoq6x4u60k8tf2zpd.redis.cn-chengdu.rds.aliyuncs.com:6379 client-type: jedis URL统计拦截器：1234567891011121314151617181920212223242526package com.sirius.admin.interceptor;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Component;import org.springframework.web.servlet.HandlerInterceptor;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Componentpublic class RedisUrlCountInterceptor implements HandlerInterceptor &#123; @Autowired StringRedisTemplate redisTemplate; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String uri = request.getRequestURI(); //默认每次访问当前url就会+1 redisTemplate.opsForValue().increment(uri); return true; &#125;&#125; 注册URL统计拦截器：123456789101112131415161718@Configurationpublic class AdminWebConfig implements WebMvcConfigurer &#123; /** * Filter、Interceptor几乎都有相同的功能，那么用哪个？ * 1、Filter是Servlet定义的原生组件。好处：脱离Spring应用也能使用 * 2、Interceptor是Spring定义的接口。可以使用Spring的自动装配等功能 */ @Autowired RedisUrlCountInterceptor redisUrlCountInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(redisUrlCountInterceptor) .addPathPatterns(&quot;/**&quot;) .excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/css/**&quot;,&quot;/js/**&quot;,&quot;/fonts/**&quot;,&quot;/images/**&quot;); &#125;&#125; 调用Redis内的统计数据：1234567891011//去main页面 @GetMapping(&quot;/main.html&quot;) public String mainPage(HttpSession session,Model model)&#123; ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); String s = opsForValue.get(&quot;/main.html&quot;); String s1 = opsForValue.get(&quot;/sql&quot;); model.addAttribute(&quot;mainCount&quot;,s); model.addAttribute(&quot;sqlCount&quot;,s1); return &quot;main&quot;; &#125;","tags":["工作","技术","SpringBoot"],"categories":["Java技术","SpringBoot"]},{"title":"SpringBoot底层注解","path":"/2021/10/25/SpringBoot底层注解/","content":"1. @Configuration详解 基本使用 Full模式和Lite模式 示例： 1234567891011121314151617181920212223242526/** * 1、配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的 * 2、配置类本身也是组件 * 3、proxyBeanMethods：代理bean的方法 * Full(proxyBeanMethods = true)（保证每个@Bean方法被调用多少次返回的组件都是单实例的）（默认） * Lite(proxyBeanMethods = false)（每个@Bean方法被调用多少次返回的组件都是新创建的），不会检查 */@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件public class MyConfig &#123; /** * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象 * @return */ @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例 public User user01()&#123; User zhangsan = new User(&quot;zhangsan&quot;, 18); //user组件依赖了Pet组件 zhangsan.setPet(tomcatPet()); return zhangsan; &#125; @Bean(&quot;tom&quot;) public Pet tomcatPet()&#123; return new Pet(&quot;tomcat&quot;); &#125;&#125; 最佳实战 配置 类组件之间无依赖关系用Lite模式加速容器启动过程，减少判断 配置 类组件之间有依赖关系，方法会被调用得到之前单实例组建，用Full模式（默认） 2. @Import导入组件@Bean、@Component、@Controller、@Service、@Repository，它们是Spring的基本标签，在Spring Boot中并未改变它们原来的功能。 @Import({User.class, DBHelper.class})给容器中自动创建出这两个类型的组件、默认组件的名字就是全类名 1234@Import(&#123;User.class, DBHelper.class&#125;)@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件public class MyConfig &#123;&#125; 测试类： 1234567891011121314//1、返回我们IOC容器ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);//...//5、获取组件String[] beanNamesForType = run.getBeanNamesForType(User.class);for (String s : beanNamesForType) &#123; System.out.println(s);&#125;DBHelper bean1 = run.getBean(DBHelper.class);System.out.println(bean1); 3. @Conditional条件装配条件装配：满足Conditional制定的条件，则进行组件注入 用@ConditionalOnMissingBean举例说明 12345678910111213141516171819202122232425262728293031323334353637@Configuration(proxyBeanMethods = false)@ConditionalOnMissingBean(name = &quot;tom&quot;)//没有tom名字的Bean时，MyConfig类的Bean才能生效。public class MyConfig &#123; @Bean public User user01()&#123; User zhangsan = new User(&quot;zhangsan&quot;, 18); zhangsan.setPet(tomcatPet()); return zhangsan; &#125; @Bean(&quot;tom22&quot;) public Pet tomcatPet()&#123; return new Pet(&quot;tomcat&quot;); &#125;&#125;public static void main(String[] args) &#123; //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args); //2、查看容器里面的组件 String[] names = run.getBeanDefinitionNames(); for (String name : names) &#123; System.out.println(name); &#125; boolean tom = run.containsBean(&quot;tom&quot;); System.out.println(&quot;容器中Tom组件：&quot;+tom);//false boolean user01 = run.containsBean(&quot;user01&quot;); System.out.println(&quot;容器中user01组件：&quot;+user01);//true boolean tom22 = run.containsBean(&quot;tom22&quot;); System.out.println(&quot;容器中tom22组件：&quot;+tom22);//true&#125; 4. @ImportResource导入Spring配置文件比如，公司使用bean.xml文件生成配置bean，然而你为了省事，想继续复用bean.xml，@ImportResource粉墨登场。 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans ...&quot;&gt; &lt;bean id=&quot;haha&quot; class=&quot;com.lun.boot.bean.User&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;zhangsan&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;hehe&quot; class=&quot;com.lun.boot.bean.Pet&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;tomcat&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 使用方法： 1234@ImportResource(&quot;classpath:beans.xml&quot;)public class MyConfig &#123;...&#125; 测试： 123456789public static void main(String[] args) &#123; //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\tboolean haha = run.containsBean(&quot;haha&quot;);\tboolean hehe = run.containsBean(&quot;hehe&quot;);\tSystem.out.println(&quot;haha：&quot;+haha);//true\tSystem.out.println(&quot;hehe：&quot;+hehe);//true&#125; 5. ConfigurationProperties配置绑定如何使用Java读取到properties文件中的内容，并且把它封装到JavaBean中，以供随时使用 老方法： 12345678910111213public class getProperties &#123; public static void main(String[] args) throws FileNotFoundException, IOException &#123; Properties pps = new Properties(); pps.load(new FileInputStream(&quot;a.properties&quot;)); Enumeration enum1 = pps.propertyNames();//得到配置文件的名字 while(enum1.hasMoreElements()) &#123; String strKey = (String) enum1.nextElement(); String strValue = pps.getProperty(strKey); System.out.println(strKey + &quot;=&quot; + strValue); //封装到JavaBean。 &#125; &#125; &#125; Spring Boot一种配置配置绑定： @ConfigurationProperties + @Component 假设有配置文件application.properties 12mycar.brand=BYDmycar.price=100000 只有在容器中的组件，才会拥有SpringBoot提供的强大功能 12345@Component@ConfigurationProperties(prefix = &quot;mycar&quot;)public class Car &#123;...&#125; Spring Boot另一种配置配置绑定： @EnableConfigurationProperties + @ConfigurationProperties 开启Car配置绑定功能 把Car这个组件自动注册到容器中 1234@EnableConfigurationProperties(Car.class)public class MyConfig &#123;...&#125; 1234@ConfigurationProperties(prefix = &quot;mycar&quot;)public class Car &#123;...&#125;","tags":["工作","技术","SpringBoot","底层"],"categories":["Java技术","SpringBoot"]},{"title":"SpringBoot自动配置原理","path":"/2021/10/23/SpringBoot自动配置原理/","content":"自动包规则原理SpringBoot应用的启动类： 123456@SpringBootApplicationpublic class MainApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApplication.class, args); &#125;&#125; @SpringBootApplication 123456789101112131415161718@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123; ...&#125; @EnableAutoConfiguration12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; @AutoConfigurationPackage标签名直译为：自动配置包，指定了默认的包规则。 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(AutoConfigurationPackages.Registrar.class)//给容器中导入一个组件public @interface AutoConfigurationPackage &#123; String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; 利用Registrar给容器中导入一系列组件 将指定的一个包下的所有组件导入进来，也就是MainApplication所在包下。 @Import(AutoConfigurationImportSelector.class) 利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件 调用List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类 利用工厂加载 Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader);得到所有的组件 从META-INF/spring.factories位置来加载一个文件。 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories 1234567# 文件里面写死了spring-boot一启动就要给容器中加载的所有配置类# spring-boot-autoconfigure-2.3.4.RELEASE.jar/META-INF/spring.factories# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\... 虽然我们127个场景的所有自动配置启动的时候默认全部加载，但是xxxxAutoConfiguration按照条件装配规则（@Conditional），最终会按需配置。 如AopAutoConfiguration类： 1234567891011121314@Configuration( proxyBeanMethods = false)@ConditionalOnProperty( prefix = &quot;spring.aop&quot;, name = &quot;auto&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)public class AopAutoConfiguration &#123; public AopAutoConfiguration() &#123; &#125;\t...&#125; 自动配置流程总结： SpringBoot先加载所有的自动配置类 xxxxxAutoConfiguration 每个自动配置类按照条件进行生效，默认都会绑定配置文件指定的值。（xxxxProperties里面读取，xxxProperties和配置文件进行了绑定） 生效的配置类就会给容器中装配很多组件 只要容器中有这些组件，相当于这些功能就有了 定制化配置 用户直接自己@Bean替换底层的组件 用户去看这个组件是获取的配置文件什么值就去修改。 xxxxxAutoConfiguration —&gt; 组件 —&gt; xxxxProperties里面拿值 —-&gt; application.properties","tags":["工作","技术","SpringBoot","底层"],"categories":["Java技术","SpringBoot"]},{"title":"Python爬虫","path":"/2021/09/16/Python爬虫/","content":"Python爬虫1.任务介绍爬取豆瓣电影Top250的基本信息 2.爬虫初识爬虫的本质就是模拟浏览器打开网页，获取网页中我们想要的那部分数据。 3.基本流程3.1 准备工作导入包 123456import bs4 # 网页解析，获取数据import re # 正则表达式，进行文字匹配import urllib.request # 制定URL，获取网页数据import urllib.errorimport xlwt # 进行excel操作import sqlite3 # 进行SQLite数据库操作 3.2 获取数据123456789101112import urllib.request# 获取一个get请求response = urllib.request.urlopen(&quot;http://www.baidu.com&quot;)print(response.read().decode(&#x27;utf-8&#x27;)) # 对获取网页源码进行utf-8解码# 获取一个post请求import urllib.parsedata = bytes(urllib.parse.urlencode(&#123;&quot;hello&quot;: &quot;world&quot;&#125;), encoding=&quot;utf-8&quot;)response = urllib.request.urlopen(&quot;http://httpbin.org/post&quot;, data=data)print(response.read().decode(&#x27;utf-8&#x27;)) 超时处理 123456# 超时处理try: response = urllib.request.urlopen(&quot;http://httpbin.org/get&quot;, timeout=0.01) print(response.read().decode(&#x27;utf-8&#x27;))except urllib.error.URLError as e: print(&quot;Time out&quot;) 获取豆瓣数据 1234567url = &quot;https://www.douban.com&quot;headers = &#123; &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36&quot;&#125;req = urllib.request.Request(url=url, headers=headers)response = urllib.request.urlopen(req)print(response.read().decode(&quot;utf-8&quot;)) 1234567891011121314from bs4 import BeautifulSoupfile = open(&quot;./baidu.html&quot;, &quot;rb&quot;)html = file.read()bs = BeautifulSoup(html, &quot;html.parser&quot;)print(bs.title)print(bs.title.string)&#x27;&#x27;&#x27;结果：&lt;title&gt;百度一下，你就知道&lt;/title&gt;百度一下，你就知道&#x27;&#x27;&#x27; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 文档的遍历print(bs.head.contents)print(&quot;-&quot;*30)print(bs.head.contents[1])# 文档的搜索# 1.find_all()# 字符串过滤：会查找与字符串完全匹配的内容t_list = bs.find_all(&quot;a&quot;)print(t_list)# search()t_list = bs.find_all(re.compile(&quot;a&quot;))print(t_list)# 自定义一个函数，根据函数的要求来搜索# 2.kwargs 参数t_list = bs.find_all(id=&quot;head&quot;)t_list = bs.find_all(class_=True)for item in t_list: print(item)# 3.text参数t_list = bs.find_all(text=&quot;hao123&quot;)t_list = bs.find_all(text=re.compile(&quot;\\d&quot;)) # 应用正则表达式来查找包含特定文本的内容for item in t_list: print(item)# 4.limit参数t_list = bs.find_all(&quot;a&quot;, limit=3)for item in t_list: print(item)# css选择器t_list = bs.select(&#x27;title&#x27;) # 通过标签来查找t_list = bs.select(&#x27;.mnav&#x27;) # 通过类名来查找t_list = bs.select(&#x27;#u1&#x27;) # 通过id来查找t_list = bs.select(&quot;a[class=&#x27;s_tab&#x27;]&quot;) # 通过属性来查找t_list = bs.select(&quot;head &gt; title&quot;) # 通过子标签来查找for item in t_list: print(item) 3.3 解析数据正则表达式 注：建议在正则表达式中，被比较的字符串前面加上r，不用担心转义字符的问题 search方法进行比较查找 1234567891011121314import re# 创建模式对象pat = re.compile(&quot;AA&quot;) # 此处的AA，是正则表达式，用来验证其他的字符串print(pat.search(&quot;CBA&quot;)) # search字符串被校验的内容print(pat.search(&quot;ABCAA&quot;))print(pat.search(&quot;ABCAADDHHAAA&quot;)) # 只找第一个AA&#x27;&#x27;&#x27;结果：None&lt;re.Match object; span=(3, 5), match=&#x27;AA&#x27;&gt;&lt;re.Match object; span=(3, 5), match=&#x27;AA&#x27;&gt;&#x27;&#x27;&#x27; 123456789101112import re# 没有模式对象print(re.search(&quot;asd&quot;, &quot;Aasd&quot;))\t# 前面的字符串是规则（模板），后面的字符串是被校验的对象print(re.findall(&quot;a&quot;, &quot;Asdhasiohoiask&quot;))print(re.findall(&quot;[A-Z]&quot;, &quot;AsdhasEFohSDask&quot;))\t# 找到所有大写字母&#x27;&#x27;&#x27;结果：&lt;re.Match object; span=(1, 4), match=&#x27;asd&#x27;&gt;[&#x27;a&#x27;, &#x27;a&#x27;][&#x27;A&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;S&#x27;, &#x27;D&#x27;]&#x27;&#x27;&#x27; 替换 12345678import reprint(re.sub(&quot;a&quot;, &quot;A&quot;, &quot;adhsjiaaadw&quot;)) # 找到a用A替换，再第三个字符串汇总查找“A”&#x27;&#x27;&#x27;结果：AdhsjiAAAdw&#x27;&#x27;&#x27; 例：打印99乘法表，并写入excel表中 12345678import xlwtworkbook = xlwt.Workbook(encoding=&quot;utf-8&quot;) # 创建workbook对象worksheet = workbook.add_sheet(&#x27;sheet1&#x27;) # 创建工作表for i in range(0, 9): for j in range(0, i+1): worksheet.write(i, j, &quot;%d * %d = %d&quot; % (i+1, j+1, (i+1)*(j+1)))workbook.save(&#x27;student.xls&#x27;) 保存数据到Excel中 12345678910111213def saveData(dataList, savePath): workbook = xlwt.Workbook(encoding=&quot;utf-8&quot;, style_compression=0) # 创建workbook对象 worksheet = workbook.add_sheet(&#x27;豆瓣电影TOP250&#x27;, cell_overwrite_ok=True) # 创建工作表 col = (&quot;电影详情链接&quot;, &quot;图片链接&quot;, &quot;影片中文名&quot;, &quot;影片外文名&quot;, &quot;评分&quot;, &quot;评价人数&quot;, &quot;概况&quot;, &quot;相关信息&quot;) for i in range(0, 8): worksheet.write(0, i, col[i]) # 列名 for i in range(0, 250): print(&quot;第%d条&quot; % (i+1)) data = dataList[i] for j in range(0, 8): worksheet.write(i+1, j, data[j]) workbook.save(savePath)","tags":["学习","技术","Python"],"categories":["Python技术"]},{"title":"Python错误与异常","path":"/2021/09/16/Python错误与异常/","content":"错误与异常12345678910# 捕获异常try: print(&quot;------test-------1--------&quot;) f = open(&quot;123.txt&quot;, &quot;r&quot;) # 要打开的文件不存在 print(&quot;------test-------2--------&quot;) except IOError: pass # 捕获异常后，执行的代码 异常类型想要被捕获，需要一致 获取错误描述12345678910111213141516171819# 捕获异常try: print(&quot;------test-------1--------&quot;) f = open(&quot;test1.txt&quot;, &quot;r&quot;) # 要打开的文件不存在 print(&quot;------test-------2--------&quot;) print(num)except (IOError,NameError) as result: print(&quot;产生错误了！&quot;) print(result) &#x27;&#x27;&#x27;结果：------test-------1--------------test-------2--------产生错误了！name &#x27;num&#x27; is not defined&#x27;&#x27;&#x27; 捕获所有异常Exception可以承接任何异常","tags":["学习","技术","Python"],"categories":["Python技术"]},{"title":"Python文件操作","path":"/2021/09/15/Python文件操作/","content":"文件操作打开文件1f = open(&quot;test.txt&quot;, &quot;w&quot;) # 当写入文件时，若文件不存在，则会新建一个文件 如果不写清楚对文件的操作方式，则会默认以“r”模式打开，当文件不存在时，则会报错 关闭文件1f.close() 写文件12345f = open(&quot;test.txt&quot;, &quot;w&quot;)f.write(&quot;Hello,I am here!&quot;)f.close() 读文件1234567891011f = open(&quot;test.txt&quot;, &quot;r&quot;)print(f.read(5)) # 读五个字符print(f.read(5))f.close()&#x27;&#x27;&#x27;结果：Hello,I am&#x27;&#x27;&#x27; 读取文件操作中，并不一定每次都是从开始读取 read方法读取指定字符，开始时定位在文件头部，每执行一次向后移动指定字符数 一次性读取全部文件为列表，每行一个字符串元素 12345678910111213141516171819f = open(&quot;test.txt&quot;, &quot;r&quot;)content = f.readlines()i = 1for temp in content: print(&quot;%d:%s&quot; % (i, temp)) i += 1&#x27;&#x27;&#x27;结果：1:Hello,I am here!2:Hello,I am here!3:Hello,I am here!4:Hello,I am here!&#x27;&#x27;&#x27; readline()方法只能读一行 重命名12import osos.rename(&quot;test.txt&quot;, &quot;test1.txt&quot;) 删除12import osos.remove(&quot;test.txt&quot;) 创建文件夹12import osos.mkdir(&quot;张三&quot;) 获取当前目录12import osos.getcwd() 获取目录列表12import osos.listdir() 删除文件夹12import osos.rmdir(&quot;张三&quot;)","tags":["学习","技术","Python"],"categories":["Python技术"]},{"title":"Python函数","path":"/2021/09/15/Python函数/","content":"函数1 函数定义和调用123456789# 函数定义def printinfo(): print(&quot;--------------------&quot;) print(&quot; Hello World &quot;) print(&quot;--------------------&quot;)# 函数调用printinfo() 带参数的 12345def addTwoNumer(a,b): c = a + b print(c)addTwoNumer(15,36) 可以同时返回多个值 12345678def divid(a, b): shang = a//b yushu = a%b return shang,yushu shang,yushu = divid(5, 2) # 需要使用多个值来保存返回内容print(&quot;商：%d, 余数：%d&quot;%(shang,yushu)) 作业： 写一个打印一条横线的函数 写一个函数，可以通过输入的参数，打印出自定义行数的横线（需要调用1中的函数） 123456789def printLine(): print(&quot;-------------&quot;)def printMoreLine(a): while a &gt; 0: printLine() a -= 1count = input(&quot;请输入需要打印的横线行数：&quot;)printMoreLine(int(count)) 写一个函数求三个数的和 写一个函数秋三个数的平均数（调用3中函数） 12345678910def threeNumSum(a, b, c): return a+b+cdef averThreeNum(a, b, c): return threeNumSum(a, b, c)//3a = input(&quot;请输入：&quot;)b = input(&quot;请输入：&quot;)c = input(&quot;请输入：&quot;)print(&quot;三个数的平均数为：%d&quot;%averThreeNum(int(a), int(b), int(c))) 2 全局变量和局部变量声明全局变量在函数中的标识符为：global","tags":["学习","技术","Python"],"categories":["Python技术"]},{"title":"Python基本语法","path":"/2021/09/15/Python基本语法/","content":"1 循环语句1.1 for循环12345678910for i in range(5): print(i)&#x27;&#x27;&#x27;结果：01234&#x27;&#x27;&#x27; 123456789for i in range(0, 10, 3): #从0开始，到10结束，每次加3 print(i)&#x27;&#x27;&#x27;结果：0369&#x27;&#x27;&#x27; 除了数字，还可以遍历字符串 1234567name = &quot;chongqing&quot;for x in name: print(x, end=&quot;\\t&quot;)&#x27;&#x27;&#x27;结果：c\th\to\tn\tg\tq\ti\tn\tg&#x27;&#x27;&#x27; 可以遍历数组，在之后会经常使用到这个功能 12345678910a = [&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;]for i in range(len(a)): print(i, a[i])&#x27;&#x27;&#x27;结果：0 aa1 bb2 cc3 dd&#x27;&#x27;&#x27; 1.2 while循环123456789101112131415161718i = 0while i &lt; 5: print(&quot;当前是第%d次执行循环&quot; % (i+1)) print(&quot;i=%d&quot; % i) i += 1&#x27;&#x27;&#x27;结果：当前是第1次执行循环i=0当前是第2次执行循环i=1当前是第3次执行循环i=2当前是第4次执行循环i=3当前是第5次执行循环i=4&#x27;&#x27;&#x27; 例：求1-100的和 1234567n = 100Sum = 0counter = 1while counter &lt;= n: Sum = Sum + counter counter += 1print(&quot;1 到 %d 的和为：%d&quot; % (n, Sum)) while配合else使用 123456count = 0while count &lt; 5: print(count, &quot;小于5&quot;) count += 1else: print(count, &quot;大于等于5&quot;) 1.3 break和continue break语句可以跳出for和while的循环体 continue语句可以跳出当前循环，直接进行下一循环 pass是空语句，一般用作占位符，不做任何事 1234567i = 0while i &lt; 10: i = i + 1 print(&quot;-&quot;*30) # 打印30次“-” if i == 5: break # 结束整个循环 print(i) 1234567i = 0while i &lt; 10: i = i + 1 print(&quot;-&quot;*30) # 打印30次“-” if i == 5: continue\t# 结束本次循环 print(i) 2 字符串、列表、元组、字典2.1 字符串 python中的字符串可以使用单引号、双引号和三引号括起来，使用反斜杠“\\”转义特殊字符 python3源码文件默认以UTF-8编码，所有字符串都是unicode字符串 支持字符串拼接、截取等多种运算 12345678910111213141516171819word = &#x27;字符串&#x27;sentence = &quot;这是一个句子&quot;paragraph = &quot;&quot;&quot; 这是一个段落 可以由多行组成&quot;&quot;&quot;print(word)print(sentence)print(paragraph)&#x27;&#x27;&#x27;结果：字符串这是一个句子 这是一个段落 可以有多行组成&#x27;&#x27;&#x27; 123my_str = &quot;I&#x27;m a student&quot;my_str = &#x27;I\\&#x27;m a student&#x27; # 用“\\”转义特殊字符print(my_str) 12345678910111213141516171819city = &quot;chongqing&quot;print(city)print(city[0:6]) # [起始位置：结束位置]print(city[1:7:2]) # [起始位置：结束位置：步进值]print(city[5:])print(city[:5])print(city + &quot;,hello!&quot;) # 字符串连接print(city*3)&#x27;&#x27;&#x27;结果：chongqingchongqhnqqingchongchongqing,hello!chongqingchongqingchongqing&#x27;&#x27;&#x27; 123456789print(&quot;hello chongqing&quot;)print(r&quot;hello chongqing&quot;) # 加“r”，表示直接显示原始字符串，不进行转义&#x27;&#x27;&#x27;结果：hellochongqinghello chongqing&#x27;&#x27;&#x27; 2.2 列表 列表可以完成大多数集合类的数据结构实现。列表中的元素类型可以不相同，支持数字，字符串甚至可以包含列表（所谓嵌套） 列表是写在方括号[]之间、用逗号分隔开的元素列表 列表索引值以0为开始值，-1为末尾的开始位置 列表可以使用+操作符进行拼接，使用*表示重复 12nameList = [&quot;Jack&quot;, &quot;Mike&quot;, &quot;Tony&quot;, &quot;Tom&quot;]print(nameList[2]) 列表内可以存在不同数据类型的元素，照样也可以打印出来 12345678910testList = [0, &quot;张三&quot;, 12.35]print(testList[0])print(testList[1])print(testList[2])&#x27;&#x27;&#x27;结果：0张三12.35&#x27;&#x27;&#x27; 2.2.1 增 append：在末尾增加一个元素 extend：将元素逐一追加到末尾 insert：指定下标位置插入元素 123456nameList = [&quot;Jack&quot;, &quot;Mike&quot;, &quot;Tony&quot;, &quot;Tom&quot;]# 增： [append]：在末尾追加一个元素nameList.append(input(&quot;请输入添加学生的姓名：&quot;))for name in nameList: print(name) 12345678a = [1, 2]b = [3, 4]a.append(b) # 将列表当做一个元素，直接加到a列表中print(a)&#x27;&#x27;&#x27;结果：[1, 2, [3, 4]]&#x27;&#x27;&#x27; 12345678a = [1, 2]b = [3, 4]a.extend(b) # 将b列表中的每个元素，逐一追加到a列表中print(a)&#x27;&#x27;&#x27;结果:[1, 2, 3, 4]&#x27;&#x27;&#x27; 1234567a = [0, 1, 2]a.insert(1, 3) # 第一个变量表示下标，第二个变量表示元素（对象）print(a)&#x27;&#x27;&#x27;结果：[0, 3, 1, 2]&#x27;&#x27;&#x27; 2.2.2 删 del ：在指定位置删除一个元素 pop：弹出末尾最后一个元素 12345678movieName = [&quot;哈利波特&quot;, &quot;指环王&quot;, &quot;霍比特人&quot;, &quot;加勒比海盗&quot;, &quot;钢铁侠&quot;]del movieName[2] # 在指定位置删除一个元素print(movieName)&#x27;&#x27;&#x27;结果：[&#x27;哈利波特&#x27;, &#x27;指环王&#x27;, &#x27;加勒比海盗&#x27;, &#x27;钢铁侠&#x27;]&#x27;&#x27;&#x27; 12345678movieName = [&quot;哈利波特&quot;, &quot;指环王&quot;, &quot;霍比特人&quot;, &quot;加勒比海盗&quot;, &quot;钢铁侠&quot;]movieName.pop() # 弹出末尾最后一个元素print(movieName)&#x27;&#x27;&#x27;结果：[&#x27;哈利波特&#x27;, &#x27;指环王&#x27;, &#x27;霍比特人&#x27;, &#x27;加勒比海盗&#x27;]&#x27;&#x27;&#x27; 12345movieName = [&quot;哈利波特&quot;, &quot;指环王&quot;, &quot;霍比特人&quot;, &quot;加勒比海盗&quot;, &quot;钢铁侠&quot;]movieName.remove(&quot;加勒比海盗&quot;) # 直接删除指定内容的元素print(movieName) 注：在使用remove时，列表中可以出现重复的数据，而remove只会删除第一个出现的指定元素 2.2.3 改直接指定要修改的内容就可以 12345678nameList = [&quot;Jack&quot;, &quot;Mike&quot;, &quot;Tony&quot;, &quot;Tom&quot;]nameList[1] = &quot;Jerry&quot;print(nameList)&#x27;&#x27;&#x27;结果：[&#x27;Jack&#x27;, &#x27;Jerry&#x27;, &#x27;Tony&#x27;, &#x27;Tom&#x27;]&#x27;&#x27;&#x27; 2.2.4 查 in 或者 not in index count 123456findName = input(&quot;请输入要查找的学生姓名：&quot;)if findName in nameList: print(&quot;找到！&quot;)else: print(&quot;没找到！&quot;) 1234567a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;b&quot;]print(a.index(&quot;a&quot;, 1, 4)) # 在指定下标之间查找指定元素&#x27;&#x27;&#x27;结果：3&#x27;&#x27;&#x27; 注：范围区间为左闭右开，例如当下标范围是[1, 3]时，是查不出“a”元素的 123a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;b&quot;]print(a.count(&quot;b&quot;)) # 统计某个元素出现几次 2.2.5 排序12345678910a = [1, 5, 6, 3, 0, 7, 2, 8]a.sort() # 升序print(a)a.sort(reverse=True) # 降序print(a)&#x27;&#x27;&#x27;结果：[0, 1, 2, 3, 5, 6, 7, 8][8, 7, 6, 5, 3, 2, 1, 0]&#x27;&#x27;&#x27; 2.2.6 反转1234567a = [1, 5, 6, 3, 0, 7, 2, 8]a.reverse()print(a)&#x27;&#x27;&#x27;结果：[8, 2, 7, 0, 3, 6, 5, 1]&#x27;&#x27;&#x27; 2.2.7 二维数组123schoolNames = [[&quot;清华大学&quot;, &quot;北京大学&quot;], [&quot;上海交通大学&quot;, &quot;复旦大学&quot;, &quot;华东师范大学&quot;], [&quot;华南理工大学&quot;, &quot;华南师范大学&quot;, &quot;深圳大学&quot;]]print(schoolNames[1][2]) 例：一共有三间空的办公室，有八个人，将这八个人随机分配到这三间空的办公室中，每间办公室人数不限。 123456789101112131415161718192021222324252627282930313233import randomoffices = [[], [], []]names = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;]for name in names: index = random.randint(0, 2) offices[index].append(name)i = 1for office in offices: print(&quot;办公室%d的人数：%d&quot; % (i, len(office))) i += 1 for name in office: print(&quot;%s&quot; % name, end=&quot;\\t&quot;) print(&quot; &quot;) print(&quot;-&quot;*20) &#x27;&#x27;&#x27;结果：办公室1的人数：3A\tC\tH\t--------------------办公室2的人数：4B\tD\tF\tG\t--------------------办公室3的人数：1E\t--------------------&#x27;&#x27;&#x27; 2.3 元组 tuple与list相似，但是tuple中的元素不能修改。tuple写在小括号里，元素之间用逗号隔开 元组的元素不可变，但可以包含可变对象，如list 注：定义只有1个元素的tuple，必须加逗号 1234567891011121314tup1 = () # 空元组print(type(tup1))tup2 = (50)print(type(tup2))tup3 = (50,)print(type(tup3))&#x27;&#x27;&#x27;结果：&lt;class &#x27;tuple&#x27;&gt;&lt;class &#x27;int&#x27;&gt;&lt;class &#x27;tuple&#x27;&gt;&#x27;&#x27;&#x27; 1234567891011tup1 = (&quot;abc&quot;, &quot;def&quot;, 123, 456, 789, 1111)print(tup1[0])print(tup1[-1]) # 访问最后一个元素print(tup1[1:5])\t# 左闭右开，进行切片&#x27;&#x27;&#x27;结果：abc1111(&#x27;def&#x27;, 123, 456, 789)&#x27;&#x27;&#x27; 2.3.1 增（连接）12345tup1 = (12, 34, 56)tup2 = (&quot;abc&quot;, &quot;def&quot;)tup = tup1 + tup2print(tup) 2.4 字典 字典是无序的对象集合，使用键-值（key-value）存储，具有极快的查找速度。 键（key）必须使用不可变类型。 同一个字典中，键（key）必须是唯一的 1234567891011121314info = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;print(info[&quot;name&quot;])print(info[&quot;age&quot;])print(info.get(&quot;gender&quot;))\t# 通过get来查找是否有这个键，如果没有找到，则默认返回Noneprint(info.get(&quot;gender&quot;, &quot;m&quot;)) # 如果没有找到，可以设定返回的默认值&#x27;&#x27;&#x27;结果：张三18Nonem&#x27;&#x27;&#x27; 2.4.1 增1234info = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;info[&quot;id&quot;] = input(&quot;请输入新的学号：&quot;)print(info[&quot;id&quot;]) 2.4.2 删在删除指定键值对后，再次访问的话会报错 123info = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;del info[&quot;name&quot;]print(info[&quot;age&quot;]) 123info = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;info.clear() # 清空字典中所有元素print(info) 2.4.3 改123info = &#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;info[&quot;age&quot;] = 20\t# 直接修改即可print(info[&quot;age&quot;]) 2.4.4 查12345678910info = &#123;&quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;print(info.keys()) # 得到所有的键（列表）print(info.values())\t# 得到所有的值（列表）print(info.items()) # 得到所有的项（列表），每个键值对是一个元组&#x27;&#x27;&#x27;结果：dict_keys([&#x27;id&#x27;, &#x27;name&#x27;, &#x27;age&#x27;])dict_values([&#x27;1&#x27;, &#x27;张三&#x27;, 18])dict_items([(&#x27;id&#x27;, &#x27;1&#x27;), (&#x27;name&#x27;, &#x27;张三&#x27;), (&#x27;age&#x27;, 18)])&#x27;&#x27;&#x27; 12345678910111213141516171819202122232425262728info = &#123;&quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 18&#125;for key in info.keys(): print(key)print(&quot;-&quot;*20)# 遍历所有的值for value in info.values(): print(value)print(&quot;-&quot;*20)# 遍历所有的键值对for key, value in info.items(): print(&quot;key=%s, value=%s&quot; % (key, value))&#x27;&#x27;&#x27;结果：idnameage--------------------1张三18--------------------key=id, value=1key=name, value=张三key=age, value=18&#x27;&#x27;&#x27; 123456789101112# 使用枚举函数，同时拿到列表中的下标和元素myList = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]for i, x in enumerate(myList): print(i+1, x)&#x27;&#x27;&#x27;结果：1 a2 b3 c4 d&#x27;&#x27;&#x27; 2.5 集合 set与dict类似，也是一组key的集合，但是不存储value。由于key不能重复，所以在set中，没有重复的key。 set是无序的，重复元素在set中自动被过滤 2.6 小结 是否有序 是否可变类型 列表[ ] 有序 可变类型 元组( ) 有序 不可变类型 字典{ } 无序 key不可变，value可变 集合{ } 无序 可变类型（不重复）","tags":["学习","技术","Python"],"categories":["Python技术"]}]